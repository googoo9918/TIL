### 목차
- [데이터베이스 응용](#데이터베이스-응용)
  - [트랜잭션 이론](#트랜잭션-이론)
    - [트랜잭션 개념](#트랜잭션-개념)
    - [직렬가능(serializability)](#직렬가능serializability)
    - [직렬가능 시험](#직렬가능-시험)
    - [회복 가능](#회복-가능)
  - [연습문제 1장](#연습문제-1장)
    - [1](#1)
    - [2](#2)
    - [3](#3)
    - [4](#4)
    - [5](#5)
    - [6](#6)
    - [7](#7)
    - [8](#8)
    - [9](#9)
    - [10](#10)
    - [11](#11)
    - [12](#12)
  - [동시성 제어(Concurrency Control)](#동시성-제어concurrency-control)
    - [록 기반 규약](#록-기반-규약)
    - [다중 단위 크기 록킹](#다중-단위-크기-록킹)
    - [교착상태](#교착상태)
    - [입력 및 삭제 연산](#입력-및-삭제-연산)
    - [SQL 트랜잭션 고립](#sql-트랜잭션-고립)
    - [스냅샷 고립](#스냅샷-고립)
  - [연습문제 2장](#연습문제-2장)
    - [1](#1-1)
    - [2](#2-1)
    - [3](#3-1)
    - [4](#4-1)
    - [5](#5-1)
    - [6](#6-1)
    - [7](#7-1)
    - [8](#8-1)
    - [9](#9-1)
    - [10](#10-1)
    - [11](#11-1)
    - [12](#12-1)
    - [13](#13)
    - [14](#14)
    - [15](#15)
    - [16](#16)
    - [17](#17)
  - [복구](#복구)
    - [장애 및 복구](#장애-및-복구)
    - [복구 기법](#복구-기법)
    - [데이터 버퍼](#데이터-버퍼)
    - [로그 기반 복구](#로그-기반-복구)
    - [원격 백업](#원격-백업)
  - [연습문제 3장](#연습문제-3장)
    - [1](#1-2)
    - [2](#2-2)
    - [3](#3-2)
    - [4](#4-2)
    - [5](#5-2)
    - [7](#7-2)
    - [9](#9-2)
    - [10](#10-2)
    - [11](#11-2)
    - [12](#12-2)
  - [저장 장치](#저장-장치)
    - [물리적 저장 매체](#물리적-저장-매체)
    - [자기 디스크](#자기-디스크)
    - [RAID](#raid)
  - [4장 연습문제](#4장-연습문제)
    - [1](#1-3)
    - [2](#2-3)
    - [3](#3-3)
    - [4](#4-3)
    - [5](#5-3)
    - [6](#6-2)
    - [7](#7-3)
    - [8](#8-2)
# 데이터베이스 응용
## 트랜잭션 이론
### 트랜잭션 개념
- 트랜잭션은 하나의 논리적 작업을 수행하는 데이터베이스 연산의 순서임
  - 즉, 연산의 논리적 단위이며 데이터를 접근하고 갱신하는 DB 프로그램의 논리적 수행 단위임
  - ex) start transaction ~ commit
- 트랜잭션 관리
  - 다양한 시스템 장애를 극복하는 **회복 기능**
  - 다수개의 트랜잭션을 동시에 수행하였을 대 발생하는 문제점을 해결하는 **동시성 제어 기능**
- ACID
  - 원자성(atomicity)
    - all-or-nothing
    - 연산 모두가 수행되거나 어느 연산도 수행되지 않아야 함
  - 일치성(consistency)
    - 단일 트랜잭션의 수행은 데이터 무결성을 유지함
    - 트랜잭션 시작 시 무결성 제약 만족 -> 종료 시에도 무결성제약을 만족 시켜야함
    - 다만, 트랜잭션 수행 중간에는 무결성제약을 만족하지 않을 수 있음
  - 고립성(isolation)
    - 다수 개의 트랜잭션이 동시 수행되어도 사용자에게는 본인 트랜잭션만이 홀로 수행되고 있는 느낌을 줌
  - 지속성(durability)
    - 완료된 트랜잭션의 결과는 후에 시스템 장애가 발생하여도 데이터베이스 상태에 반영되어야 함
- ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/679772af-863a-4982-ae2b-ea67b57b027c)
  - 3번 라인을 수행하고 6번 라인 수행 전에 시스템 장애 발생 시 
    - 3번 라인 효과를 DB 시스템에서 제거해야함
    - 원자성에 의해!
  - 3번과 6번을 수행하고 commit까지 진행 후 DB 시스템 장애 발생 시
    - 지속성에 의해, 위 수행 라인은 데이터베이스 상태에 반영되어 있어야 함
- ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/d9961ecf-060c-4671-bc06-828761ce7a4b)
  - 이와 같은 예제는 고립성 요구사항에 위배됨
  - T2가 접근하는 데이터 A,B는 T1의 트랜잭션 중간값이기 때문
    - 실행 중간 값은 무결성 제약을 만족하지 않을 수 있고, 실제로 상기 예제는 무결성 제약을 위배하고 있음
  - 트랜잭션을 직렬실행 하면 고립성은 자연스럽게 제공되나, 현실적으로 불가능
- 트랜잭션 상태
  - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/c994518a-be96-4d75-bb22-bb4d87721183)
  - 수행(Active) -> 부분 완료(partially committed) -> 조치(ex 로그 기록) -> 완료(Committed)
  - 수행 중인 상태에서 트랜잭션의 모든 문장이 실행되면 부분 완료 상태가 됨
  - 트랜잭션 완료를 위한 조치(ex 로그에 기록) 가 성공적으로 수행되면 트랜잭션은 완료 상태가 됨
  - 만약 여러한 경우로 완료 전 트랜잭션 연산을 수행하지 못하는 상황이 발생한다면, 트랜잭션이 철회(aborted)상태가 됨
    - 이 경우, 트랜잭션 초기에 시작할 상태로 DB를 원상 복귀 시켜야 함
- 동시 실행(Concurrent Executions)
  - 시스템은 여러 개의 트랜잭션을 동시에 수행함
    - 자원 활용성 증가 및 평균 응답 시간 감소
    - 마치 운영체제에서 개별 프로세스의 동시성 수행!
  - 다만, 동시성 제어를 해줘야 함

### 직렬가능(serializability)
- 올바른 실행
  - 다수 개의 트랜잭션을 동시 수행 시, 올바른 트랜잭션 실행의 정확한 정의는 무엇인가?
  - 트랜잭션을 순차적으로 수행하는 *직렬수행* 방법은 항상 올바르다
  - 다만 현실적으로 운영 불가능
- 틀린 실행 현상(concurrency Anomalies)
  - 오손읽기(dirty read)
    - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/cf6f078e-fd04-410a-9621-54104f097fb9)
    - 완료되지 않은 값(uncommitted value, dirty value)을 읽는 연산을 뜻함
    - T1이 철회를 하면 T2 또한 철회해야함
  - 갱신 손실(lost update)
    - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/ac21de75-60b7-490c-84ef-fb97c912acc9)
    - T2가 쓴 값을 T1이 덮어쓰는 현상
    - T2의 효과는 DB에서 사라지게 됨
  - 반복불가 읽기(unrepetable read)
    - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/15d7582e-b14b-4179-b153-cfe068a16808)
    - T1이 처음에 읽는 A값과 후에 읽은 A 값에 차이가 있음
    - A 값을 읽을 때마다 다른 값이 나오는 현상!
  - 바르지 못한 실행으로 발생할 수 있는 현상은 오직 이 세 가지 뿐임
- 스케줄(역사)
  - 스케줄은 동시적으로 수행되는 다수 트랜잭션에 속하는 연산이 수행된 *시간적 순서*
  - 트랜잭션의 모든 연산이 스케줄에 나와 있어야 함
  - 트랜잭션의 마지막 문장은 commit 또는 asbort임
    - 이는 명시적으로 수행 or 암시적 시스템 수행됨
- 스케줄1
  - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/efe5aa2f-8e58-4a0c-a129-b2ec9e502ee7)
  - 초기값 A:100, B:200
  - A계좌에서 B계좌로 $50 혹은 10%을 송금함
  - 트랜잭션 수행 후에도 A+B 값의 변화는 없음
- 스케줄2
  - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/53d38fe6-8241-40fb-80a8-4c6732592866)
  - 마찬가지로 A+B 값에 변화는 없음
- 스케줄3
  - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/7d8dd289-9ef8-4a01-a5ed-5e3d68321489)
  - 직렬 스케줄은 아니지만, 그 효과가 스케줄 1과 동일함
- 스케줄4
  - ![image](https://github.com/googoo9918/YourssuAssignment/assets/102513932/0b7fc438-fe89-4172-bb90-4e0fa91494a1)
  - 스케줄 4는 올바른 스케줄이 아님
  - 초기값 A=100, B=200
  - T2 write(A)후 상태
    - A=90, B=200
  - T1 write(A)후 상태
    - A=50, B=200
      - 이때 A에서 lost update가 발생했음
  - T1 write(B)후 상태
    - A=50, B=250
  - T2 write(B)후 상태
    - a=50, B=210
  - 트랜잭션 수행 후에 A+B값에 변화가 있음
- 예제 정리
  - 스케줄 4는 올바른 수행이 아님
    - 스케줄 4의 효과가 스케줄 1 또는 스케줄 2의 효과와 모두 다르기 때문
    - 만약 직렬수행 스케줄 중 하나와 효과가 같다면, 올바른 스케줄(직렬가능 스케줄)임
- 직렬 가능(Serializability)
  - 스케줄이 직렬수행 스케줄 결과와 동일하면 이를 **직렬가능(serializable) 스케줄**이라 칭함
  - 스케줄에 관련되는 트랜잭션의 개수가 n개이면 직렬 스캐줄은 n개의 트랜잭션을 나열하는 개수와 동일함
    - 총 n!임
  - 직렬 가능 스케줄은 n!의 직렬 스케줄 중에서 적어도 하나의 직렬 스케줄과 동일한 결과를 가져야 함 
  - 앞서 스케줄 3은 직렬 스케줄 1과 동일한 결과를 보이므로, 직렬가능 스케줄임
  - 이처럼 스케줄 결과의 동일함을 정의하는 방식은 *충돌 직렬가능* 스케줄과 *뷰 직렬가능성* 스케줄이 존재
- 충돌 연산(Conflicting Instructions)
  - 동일한 데이터에 대한 연산만을 고려
  - 동일한 데이터에 대한 두 개 연산 중에서 최소한 한 개 연산이 쓰기 연산이면, 두 연산은 *충돌*함
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/612b2d6a-f949-4782-b309-a6fc4709c296)
    - 층돌연산은 연관되는 트랜잭션의 직렬실행 순서를 결정
      - 비충돌연산은 두 연산의 순서를 스케줄에서 바꿔도 연산 효과가 동일하나
      - 충돌 연산은 순서를 바꾸면 **효과가 다르게 나오기** 때문
- 충돌 직렬가능 스케줄(Conflict Serializable Schedule)
  - 비충돌 연산을 서로 바꿔 직렬 스케줄이 되면, *충돌 직렬가능 스케줄*이라 칭함
- 충돌 직렬가능 예제1
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/0360c778-b5c7-45b5-a4be-05be49fa5f25)
  - 스케줄 5에서 T2의 wirte(A)는 T1의 read(B), write(b)와 비충돌하므로 서로 위치를 바꿀 수 있음
    - 동일하지 않은 데이터에 대한 연산이기 때문
    - read(A)또한 마찬가지
  - 따라서 서로 위치를 바꾸면 결과적으로 스케줄6이 나오게 되며, 스케줄6은 직렬 스케줄임
  - 이 경우, 스케줄5는 *충돌 직렬가능 스케줄*임
- 충돌 직렬가능 예제2
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/66a01f25-68dc-44fe-8e94-a5ab31a17c6a)
  - 상호 교환되지 않으므로 충돌 직렬가능 스케줄이 아님
- 뷰 직렬가능 정의(View Serializability Definition)
  - 다음 3가지 조건을 만족해야함
  - 1. 초기 읽기
    - 스케줄에서 변수를 처음 읽는 트랜잭션이 직렬 스케줄에서도 그 변수를 처음 읽어야 함
  - 2. 최종 쓰기
    - 스케줄에서 변수를 마지막으로 쓰는 트랜잭션이 직렬 스케줄에서도 그 변수를 마지막으로 써야 함
  - 3. 값 전달
    - 한 트랜잭션 T1이 다른 트랜잭션 T2에게 변수의 값을 전달하면, 직렬 스케줄에서도 T1이 T2에게 값을 전달해야 함
- 뷰 직렬가능 예제1
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/53351076-28d0-4226-8a88-9e21184260e4)
    - 스케줄 8은 충돌연산만으로 구성되어 있으므로 충돌 직렬 가능 스케줄은 아님
    - 스케줄 8은 직렬 스케줄 `<T5,T6,T7>`과 효과가 동일한 뷰 직렬가능 스케줄임
    - T5 읽기 연산에서 보는 데이터 Q는 직렬 스케줄 `<T5,T6,T7>`의 T5 읽기 연산이 보는 데이터 값과 동일
    - 스케줄 8의 데이터 Q에 대한 마지막 쓰기 연산은 T7의 쓰기 연산인데, 이는 <T5,T6,T7>의 T7쓰기 연산과 동일함
    - 값 전달은 위 예제에서는 일어나지 않고 있음
- 충돌 직렬가능 대비 뷰 직렬가능
  - 뷰 직렬가능 스케줄 중의 일부가 충돌 직렬가능 스케줄임
  - 모든 충돌 직렬가능 스케줄은 뷰 직렬가능 스케줄임
  - 즉, 직렬가능 스케줄이 뷰 직렬가능 스케줄을 포함하고, 뷰 직렬가능 스케줄이 충돌 직렬가능 스케줄을 포함함
- 다른 직렬가능 스케줄
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/a24f5cee-292d-4b82-b863-e6a1b8e3e361)
  - 위 스케줄은 충돌 직렬가능 스케줄도 아니고, 뷰 직렬가능 스케줄도 아니지만
    - swap할 수 있는 비충돌 연산이 없음
    - 초기 읽기, 초기 쓰기 적용x
  - 직렬 스케줄 `<T1, T2>`과 동일한 결과를 보이므로, 직렬 가능 스케줄임

### 직렬가능 시험
- 충돌 직렬가능 시험
  - 주어진 스케줄이 충돌 직렬가능 스케줄인지를 판별하기 위해서는 *선행 그래프(Precedence Graph*를 사용하면 됨
  - 여기서 노드는 트랜잭션을 표현함
  - 동일한 데이터에 대해 **충돌되는 연산**이 존재 시
    - 데이터 접근에 대한 선후 관계에 따라 에지(edge)를 생성함
- 선행 그래프 예제1
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/499017fb-0f0e-4ef3-8ec8-c09bf33f24d8)
    - 스케줄 10에 대한 선행 그래프를 작성한 예제
    - 선행 그래프에 사이클이 있으므로 스케줄 10은 충돌 직렬가능 스케줄이 아님
- 선행 그래프 예제2
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/8ea500f6-d2a3-4f68-891b-77393f7ec39e)
    - 선행 그래프에 대한 관심은 사이클 존재 여부임
      - 중복되는 에지는 그래프 작성 시에 표기하지 않아도 됨
      - 또한, T5에는 write가 없으므로, 작성하지 않아도 됨
    - 스케줄 11에 의한 선행 그래프에는 사이클이 없으므로, 스케줄 11은 충돌 직렬가능 스케줄임
      - 모든 충돌연산에 대해서 에지를 그려야 함에 유의할 것!
      - 또한, 데이터 여부와 별개로 사이클을 판단할 것!
- 선행 그래프의 사이클 판별은 저렴함
  - 선행 그래프는 방향성 그래프이고, 방향성 그래프에서 사이클 존재 여부 판별은 쉬움
  - 위상 정렬의 관점에서 보자
    - 위상 정렬이란, 부분 순서를 만족시키면서 전체 노드를 정렬하는 방식
    - 스케줄 11에서 갖고 있는 부분 순서
      - T1->T3->T4
      - T1->T2->T4
    - 따라서, 5!/4!/2!임
      - 1. T5는 아무 상관이 없고, 순서 연관이 있는 4 원소 -> 5!/4!
        - T2와 T3는 변동 가능하므로 *2!
      - 2. 순서가 있는 배열이 2번 존재한다고 생각하면, 5!/4!/2!임
- 뷰 직렬 가능 시험
  - 뷰 직렬가능 시험은 NP-complete임
### 회복 가능
- 회복가능 스케줄(Recoverable Schedules)
  - 직렬 가능 스케줄 문제와는 별개로, 스케줄을 회복 관점에서도 고려해야 함
  - 아무리 직렬 가능 스케줄이어도 그 스케줄이 회복 관점에서 문제가 있으면 사용할 수 없음
- 데이터를 읽은 트랜잭션(T1)은, 그 데이터를 쓴 트랜잭션(T2) 후에 완료(commit)해야 함
  - 만약 T2가 롤백 된다면, T1도 롤백 되어야 하기 때문
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/a7c7c6ed-9e74-46f5-8b4c-e534c27d0430)
    - T9은 현재 완료되지 않은 값(A)를 읽고 있음, 그런데 먼저 커밋을 해버리니 만약 T8이 철회를하게 되면, 읽은 값이 잘못된 값이니 따라서 철회를 해야 하는데 이미 완료를 해버려서 철회를 못하는 상황이 되어버림
    - 완료를 하고도 취소를 해야되니까 Durable 성질을 위배하고, Consistency 또한 위배함
- 연쇄 철회(Cascading Rollbacks)
  - 트랜잭션 하나의 철회가 다른 트랜잭션 철회를 유도함
    - 이를 방지하려면 기본적으로 완료된 읽기만을 허용하여아 함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/dc3add47-00a8-4886-9af6-39512cea0cae)
    - 이 예제에서 T11과 T12의 read는 dirty read임
    - 읽는 값이 committed된 값이 아니므로
    - T10이 철회를 하면 T11 및 T12도 함께 철회를 해야 함
      - 이는 T11과 T12입장에서는 트랜잭션의 분리성(isolation)이 제대로 지원되지 않아 철회를 하는 꼴이 되기 때문임
    - 따라서 DBMS는 원칙적으로 연쇄 철회 현상이 발생하지 않도록 트랜잭션을 스케줄 해야 함
    - 참고로, 상기 스케줄은 회복가능 스케줄임
      - 회복 가능 스케줄은 관련 트랜잭션의 완료 순서에만 제약을 주기 때문
- 연속적인 철회가 필요 없는 스케줄(Cascadeless Schedules, Avoids cascading aborts(ACA))
  - 연속적인 철회가 필요 없는 스케줄 또는 연속 철회를 방지하는 스케줄은 기본적으로 완료된 데이터 읽기만을 허용함
  - 즉, 읽으려고 하는 데이터에 대해 데이터를 마지막으로 쓴 트랜잭션이 완료(commit)하기를 요구하는 스케줄임
- 스케줄 관계
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/7170a61f-fc96-43b9-8860-5fc7ce3c1528)
  - RC(recoverable)
    - 회복가능 스케줄, 데이터를 읽은 트랜잭션이 데이터를 쓴 트랜잭션 후에 완료(commit)하면 됨
  - ACA(avoids cascading aborts)
    - 연쇄 철회를 방지하는 스케줄, 트랜잭션이 커밋되기 전에 다른 트랜잭션들이 해당 트랜잭션에 의해 변경된 데이터를 *읽지* 못하게 함
  - ST(strict)
    - 제한적인 스케줄, 트랜잭션이 데이터를 변경하면 이 트랜잭션이 커밋되기 전까지 다른 어떤 트랜잭션도 그 데이터 항목을 *읽거나 쓸 수* 없음
  - SR(conflict serializable)
    - 충돌 직렬 가능 스케줄, 비충돌 연산을 서로 바꾸어 직렬 스케줄이 되는 스케줄
  - DB 시스템이 지원하는 스케줄은 충돌 직렬가능 스케줄과 ACA 스케줄(혹은 회복가능 스케줄)의 교집합 부분
- ST가 아닌 ACA 스케줄
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/05b2615f-d4a0-43a5-a013-eac5e07faf30)
  - T2는 T1이 쓴 데이터 X를 overwrite하지만, 읽는 것은 완료(commit) 이후에 진행하고 있음
- 동시성 제어(Concurrency Control)
  - 우리가 원하는 스케줄은 충돌 직렬가능 스케줄임과 동시에 회복 가능(RC) 또는 연쇄철회를 방지(ACA)하는 스케줄임
  - 트랜잭션을 우선 실행 한 후 판별 여부는 가능하나, 이미 수행한 후이므로 의미가 없음
  - 우리가 원하는 것은 위 규약을 준수하면서 트랜잭션을 수행하면, 우리가 원하는 스케줄이 나오게 하는 것임
    - 이를 **동시성 제어 규약**이라 칭함
  - 다음 장에서 동시성 제어 규약인 록킹(locking)에 대해 살펴볼 것
- 요약
  - isolation 관점에서의 판단 기준은 conflict serialization(직렬 가능)과 view serialization(뷰 직렬 가능)
  - 회복 관점에서는 recoverable, cascadeless, strict 존재
  - 각 차이점 명확히 인지할 것

## 연습문제 1장
### 1
- Explain the ACID properties of transactions
  - Atomicity(원자성)
    - All-or-Nothing
    - 연산 모두가 실행되거나, 어느 연산도 수행되지 않아야 함
  - Consistency(일치성)
    - 단일 트랜잭션의 수행은 데이터 무결성을 유지해야함
      - 다만, 트랜잭션 수행 중간에는 무결성제약을 만족하지 않을 수 있음
  - Isolation(독립성)
    - 다수 개의 트랜잭션이 동시 수행되어도 사용자에게는 본인 트랜잭션만이 홀로 수행되고 있는 느낌을 줌
  - Durability(지속성)
    - 트랜잭션 완료 후 시스템에 오류가 생겨도, 데이터베이스 상태에 반영되어야 함
### 2
- Consider a file system in Unix
- What are the steps involved in creation and deletion of files, and in writing data to a file(파일과 생성과 삭제, 파일에 데이터를 쓰는 과정에 관련된 단계를 설명하라)
  - 파일 시스템에서 파일에 저장 영역이 할당되고, 파일에 고유한 i-number(파일 디스크립터)가 주어지며 i-list에 i-node 항목이 삽입됨
  - 파일의 삭제는 정확히 반대의 단계를 포함함
- Explain how the issues of atomicity and durability are relevant to the creation and delection of files and to writing data to files(원자성과 지속성 문제가 파일의 생성 및 삭제, 파일에 데이터를 쓰는 것과 어떻게 관련이 있는가?)
  - 유닉스 파일 시스템의 *사용자*에게 지속성은 중요하지만, 파일 시스템이 트랜잭션을 지원하지 않기 때문에 원자성은 일반적으로 관련이 없음
  - 그러나 파일 시스템을 *구현하는 사람*에게는 내부 파일 시스템 동작의 많은 부분이 트랜잭션 의미 체계를 가져야함
    - 파일의 생성/삭제에 관련된 모든 단계는 원자적이어야 함
    - 그렇지 않으면 파일 시스템에서 참조할 수 없는 파일이나 사용할 수 없는 영역이 생길 것

### 3
- Database-system implementers have paid much more attention to the ACID properties than have file-system implementers. Why might this be the case?(DB 시스템 구현자들은 파일 시스템 구현자들보다 ACID에 더 많은 주의를 기울였는데, 왜 그런지 설명하라)
  - 데이터베이스 시스템은 원자적이고 지속적인 효과가 필요한 중요한 작업을 주로 수행
  - 그 결과는 영구적인 방식으로 실제 세계의 영향을 미침
    - ex) 금전거래, 좌석 예약
  - 따라서 ACID 속성을 보장해야함
  - 반면, 대부분의 파일 시스템 사용자들은 ACID 속성을 지원하는 데 필요한 비용(돈, 시간, 디스크 공간 등)을 지불하려고 하지 않을 것임
    - 파일 수정과 같은 일상적인 작업이 비교적 ACID가 덜 중요하단 소리임
### 4
- Explain the distinction of the terms serial schedule and serializable schedule. Explain why the serial schedule is always correct too.(직렬 스케줄과 직렬 가능 스케줄이라는 용어의 구별에 대해 설명하고, 직렬 스케줄이 항상 올바르다는 것에 대해서도 설명하라)
  - 직렬 스케줄
    - 하나의 단일 트랜잭션에 속한 모든 명령이 함께 나타나는 스케줄
  - 직렬 가능 스케줄
    - 특정 직렬 스케줄과 결과 값이 동일해야함
  - 충돌 직렬가능과 뷰 직렬가능성은 동등성에 대한 두 가지 정의
  - 직렬 스케줄은 모든 트랜잭션의 연산이 연속적으로 실행되고, 다른 트랜잭션의 연산에 의해 방해 받지 않기 때문에 항상 올바름

### 5
- why do we emphasize conflict serializability rather than view serializability?(우리는 왜 뷰 직렬가능성보다 충돌 직렬가능성에 더 강조하는가?)
  - 대부분의 동시성 제어 프로토콜(직렬 가능한 스케줄만 생성되도록 보장하기 위한 프로토콜)은 충돌 직렬 가능성을 기반으로 사용되고, 충돌 직렬 가능성 스케줄의 부분 집함만 허용함
  - 뷰 직렬가능성은 일반적으로 테스트하는데 굉장히 까다로우며, 동시성 제어를 위해 매우 제한된 형태만이 사용됨
  - 즉, 충돌 직렬 가능성이 보다 효율적으로 사용되기 떄문에 프로토콜 및 시스템 구현에 더 적합하고, 뷰 직렬가능성은 테스트 및 구현이 복잡하기 때문에 제한적으로 사용됨

### 6
- What do you think about the following statement. Justify the answer.
- Concurrent execution of transactions is more important when data must be fetched from(slow) disk or when transactions are long, and is less important when data is in memory and transactions are short(트랜잭션이 동시에 실행되는 것은 데이터가(느린) 디스크에서 가져와야 할 때나 트랜잭션이 길 때 더 중요하고, 데이터가 메모리에 있고 트랜잭션이 짧을 때는 덜 중요하다)
  - 트랜잭션이 매우 길거나, 느린 디스크에서 데이터를 가져올 때는 완료하는 시간이 오래 걸리기 때문에 동시성이 없는 경우 다른 트랜잭션이 더 오랜 시간 기다려야 하고 평균 응답시간이 증가함
  - 또한 트랜잭션이 디스크에서 데이터를 읽을 때, CPU는 idle 상태가 됨
    - 따라서 리소스가 제대로 활용되지 않고, 오버헤드가 크기 때문에 동시 실행이 중요해짐
  - 그러나 트랜잭션이 짧거나 데이터가 메모리에 있을 때는 이런 문제가 발생하지 않아 동시성의 중요성이 상대적으로 줄어듬

### 7
- What is a recoverable schedule? Why is recoverability of schedules important?(회복 가능한 스케줄이 뭐고, 왜 스케줄의 회복 가능성이 중요한가?)
  - 회복 가능한 스케줄은 T1과 T2 두 트랜잭션이 있을 떄, T2가 T1에 의해 쓰여진 데이터 항목을 읽는 경우, T1의 완료(커밋) 작업이 T2의 커밋 작업 이전에 나타나는 스케줄을 의미함
    - 즉, 데이터를 읽은 트랜잭션의 커밋 시점은 데이터를 쓴 트랜잭션 커밋한 후임
  - 중요한 이유는, 회복 가능하지 않으면 시스템을 rollback할 수 없는 불일치 상태가 될 수 있기 때문임

### 8
- Consider the precendence graph of Figure 1. Is the corresponding schedule conflict serializable?(선행 그래프를 봤을 때, 해당 스케줄은 충돌 직렬 가능 스케줄인가?)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/f04ef7ed-0cf4-41dd-9f36-047517cee0bb)
    - 비순환적 그래프기 때문에 충돌 직렬화 가능한 스케줄이 존재함
    - 위상 정렬에 의해, `<T1, T2, T3, T4, T5>`, `<T1, T2, T4, T3, T5` 가능

### 9
- ![image](https://github.com/googoo9918/TIL/assets/102513932/ec647118-3f38-4eb7-bc01-b37728bca56b)
  - Is the history recoverable and/or cascadeless?(회복가능 여부, 연속적 철회 필요 없는 스케줄 여부)
  - 회복가능성
    - 한 트랜잭션이 다른 트랜잭션에 의해 수정된 데이터 항목을 읽은 경우, 데이터를 읽은 트랜잭션이 더 늦게 commit 되어야 한다는 사실은 이미 알고있었음
    - 그렇다면 abort에서는 어떻게 적용되는가?
      - abort의 경우, 데이터를 쓴 트랜잭션인 경우 회복 가능하지 않음
      - 위 스케줄의 경우, T2에서 write(B) 연산이 철회되므로, T3의 read(B)가 잘못된 연산이 되어버림.. 근데 commit을 진행했으니 회복 불가능함
  - 연속적 철회가 필요 없는 스케줄 여부
     - 연속적 철회가 필요 없으려면 완료된 값만을 읽어야함
     - 그래서 아님, 커밋되지 않은 값 읽는중

### 10
- ![image](https://github.com/googoo9918/TIL/assets/102513932/83775807-c767-41be-bcf8-e7a71f74d355)
  - (A) Draw a precendence graph for T1, T2, T3 and T4 for the schedule. Label each edge with the data item that is accessed
  - (b) is the schedule conflict serializable?(충돌 가능 스케줄인가?), if yes give all conflict-equivalent serial schedules(맞다면 직렬 가능한 스케줄 나열)
    - ![KakaoTalk_20231003_192009602](https://github.com/googoo9918/TIL/assets/102513932/b0f6c56f-4a70-482c-9ef5-c6ea09f62128)


### 11
- ![image](https://github.com/googoo9918/TIL/assets/102513932/b94d5ea4-92b5-414e-a156-c16cba9d1b3d)
  - 상기 스케줄에 대한 선행 그래프를 작성하고, 충돌 직렬 가능성을 판별하라, 만약 맞다면 동등한 serial schedule을 모두 구할 것
  - 상기 스케줄의 view serializable 여부를 판정하고, 이유를 기술할 것
  - ![KakaoTalk_20231003_185951924](https://github.com/googoo9918/TIL/assets/102513932/6bf32bf2-f599-4516-86e8-e85cfe6ad8fb)


### 12
- 다음 문장의 참/거짓을 명시하고, 거짓일 경우 그 이유를 설명하라
  - view serializable한 스케줄은 항상 confilict serializable 하다
    - 거짓, Conflict serializable한 스케줄은 항상 view serializable 함
  - view serializable한 스케줄 판발연 precedence graph를 사용하며 polynomial time에 가능하다
    - 거짓, view serializable 스케줄 판단은 NP-complete 문제임

## 동시성 제어(Concurrency Control)
### 록 기반 규약
- 록 규약은 트랜잭션의 동시성 제어를 위하여 개발했음
  - 스케줄을 제한하여 원하는 트랜잭션 스케줄만을 생성
- 록 모드는 2개
  - X mode
    - 데이터를 *읽거나 쓸 때* 사용하는 록
    - 다른 록 모드와 호환되지 않음
  - S mode
    - 데이터를 *읽을 때* 사용하는 록
- 록 기반 규약(Lock-based Protocols)
  - 트랜잭션은 모든 읽기/쓰기 연산에 대해 연산을 시작하 전에 적절한 록을 보유해야함
    - 록을 보유하지 않으면, 록을 보유할 때까지 기다려야 함(충돌 록이 해제될 때까지 기다려야 함)
  - 읽기 록은 동시의 다수의 트랜잭션에게 부여 가능
    - 한 데이터를 여러 트랜잭션에서 읽을 수는 있다는 얘기(물론, 이 데이터가 X mode로 lock이 걸려있으면 안됨)
  - 쓰기 록은 반드시 한 개의 트랜잭션에만 부여 가능
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/4eed16b4-6a86-4afc-bdd1-53ef674b1c2b)
    - 모든 데이터베이스 연산을 locking과 unlocking이 감싸는 형태
    - 이를 well-formed schedule이라 칭함
    - 다만, 이는 트랜잭션 직렬가능 스케줄을 보장하진 않음
- 2단계 록킹 규약(Two-phase Locking Protocol)
  - 2단계 록킹 규약은 2단계로 구성됨
  - 록이 증가하는 단계(growing phase), 록이 감소하는 단계(shrinking phase)
  - 록을 풀기 시작하면 감소 단계로 들어간 것이므로, 새로운 록을 잡을 수 없음
  - 2단계 록킹은 직렬 가능성을 보장하나, 이 규약을 이용하여 생성하지 못하는 충돌 직렬가능 스케줄이 존재함
- 2단계 록킹 규약에서 중간에 록을 해제하는 경우
  - write한 데이터에 대한 록을 해제하면, 타 트랜잭션이 해당 값을 읽을 수 있음
  - 그런데 write한 트랜잭션이 롤백되는 경우, 타 트랜잭션도 롤백되어야 하고 이는 연속철회 스케줄에 해당함
  - 이를 방지하기 위해, 2단계 록킹 규약의 변형으로 두 가지가 존재
  - 엄격(strict) 2단계 록킹
    - write한 트랜잭션이 종료할 때까지 쓰기 록을 보유하는 방식
    - 이 경우, 타 트랜잭션이 완료된 값만 읽게 되므로 연속 철회를 방지할 수 있음
  - 엄증(rigorous) 2단계 록킹
    - 쓰기 록 뿐 아니라 읽기 록까지도 트랜잭션 종료 시까지 유지하도록 함
- 록 변환
  - 트랜잭션이 데이터에 대한 록을 요구할 때, 동일 데이터에 대한 록을 기존에 할당받아 보유하고 있으면 기존 록에 대한 모드만 변환함
  - 다만, 2단계 록킹 방식에서는 록 변환에 대한 제한이 있음
    - s->x 변환은 증가단계에서만 가능
    - x->s 변환은 감소단계에서만 가능
- 2PL 정확성 증명
  - 2PL 록킹 방식은 항상 충돌 직렬가능 스케줄을 생성하며, 트랜잭션의 록 포인트 순서대로 직렬화가 됨
    - 선행 그래프에서 T1->T2 에지가 있으면 반드시 A1 < A2임
      - A1은, T1이 마지막 lock을 얻는 시간을 뜻함
      - 즉, A2가 A1보다 나중에 lock을 얻는다는 소리임 
    - T1->T2 에지가 있다는 것은, 특정 동일 데이터에 대해 두 개의 트랜잭션이 충돌 연산을 갖고 있고, T1이 T2보다 데이터에 먼저 접근한다는 의미임
    - T1이 충돌 데이터에 대해 해당 록을 갖고 먼저 접근하고 있음
    - 따라서 T1이 연산을 마치고 록을 해제해야 T2가 록을 배당 받고 해당 연산을 하게 됨
    - 이는 T1은 이미 shrinking phase에 들어감을 의미하고, 그러므로 Ai < Aj 관계식이 성립함
    - 만약 2PL 방식이 아니라면, A1 < A2 관계식이 항상 성립하진 않음
  - 2PL 록킹 방식에서는 growing phase에서 록 하향변환을 허용하지 않아 X mode 록을 S mode 록으로 변환할 수 없음
    - 만약 growing phase에서 록의 하향 변환을 허용하면 상기 증명에서 어떤 문제점이 생기는가?
    - 만약 하향 변환을 허용한다면, 트랜잭션은 X 록을 S 록으로 변환한 후, 다른 트랜잭션에 의해 그 자원에 X록이 설정될 수 있게 됨
      - 이 경우, 트랜잭션은 이 자원에 대해 더 이상 exclusive한 접근 권한이 없으므로, 트랜잭션의 중간 결과가 다른 트랜잭션에 의해 변경될 수 있게 됨
      - 이는 트랜잭션의 일관성에 위배됨
    - 순환 대기 상태 발생
      - 두 트랜잭션이 서로 다른 순서로 록을 획득하고 그 중 하나가 하향 변환을 수행하면, 두 트랜잭션은 서로가 소유한 록을 기다리게 되어 교착 상태에 빠질 수 있음
- 자동 록 획득
  - 록에 대한 획득/철회는 시스템 내부에서 자동으로 운영
    - 사용자가 직접적으로(explicitly) 록을 요구 및 해제하지 않음
    - 사용자 관점에서는 데이터에 대한 접근만 할 뿐, 록 운영은 DBMS의 고유 영역임
  - 읽기 록 획득 과정
    - 읽기 록은 호환이 가능하므로, 다른 트랜잭션이 해당 데이터 항목에 대해 쓰기 록을 먼저 기다리고 있지 않았다면, 록이 즉시 허용됨
  - 쓰기 연산에 대한 록 획득 과정
    - 쓰기 록은 호환성이 없으므로 반드시 배타적으로 록을 획득해야함
    - waiting queue에 의해 록이 부여
- 록 구현
  - 록을 담당하는 프로세스를 독립적으로 구성할 수 있음
  - 록을 담당하는 록 매니저는 록 테이블을 관리하며 록 처리를 수행
  - 록 테이블은 주기억장치에 상주, 빠른 접근을 위해 데이터 항목 이름으로 해쉬 색인 구성
- 록 테이블
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/b06fee50-39c2-4872-a357-1d6d5712c4f2)
    - 데이터 항목은 해쉬 값으로 접근함
    - 왼쪽에 위치하는 네모 모양 박스는 해쉬 버킷을 의미함
      - 데이터 항목 I7과 I23은 동일한 해쉬 값을 갖고 있음(동일 해쉬 버킷)
    - I7은 T23에 록이 허용되어 있고, 록을 기다리는 트랜잭션은 없음
    - I23 데이터 항목은 T1, T8에 록이 허용되어 있고(S 모드겠지) I23 데이터 항목을 기다리는 트랜잭션 T2가 존재함(T2가 요구하는 록 모드는 쓰기 모드임)
    - 트랜잭션 T23은 데이터 항목 I7, I912에 대한 록을 갖고 있지만, I4에 대해서는 록을 기다리고 있음
- 교착상태
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/f14a4a8a-ccf2-4af3-af22-ddf889e3ada1)
  - 록을 사용하는 동시성 제어에는 교착상태가 발생할 수 있음
    - 2개 이상의 트랜잭션이 서로 무한정 기다리는 상태
- 기아상태(Starvation)
  - 특정 트랜잭션이 록을 획득하지 못하고 필요 이상으로 록을 기다리는 형상
  - 록 획득은 선착순으로 배정되어야 하는데, 배분 정책 이상으로 특정 트랜잭션이 록을 획득하지 못하고 기다리는 현상
  - 기아상태는 없어야 되며, 교착 상태는 왕왕 발생
- 그래프 기반 규약
  - 록킹 상태는 크게 2단계 록킹 규약과 그래프 기반 규약으로 나눌 수 있음
  - 그래프 규약은 록을 걸려고 하는 데이터에 대해 부분 순서가 있어야 한다는 가정을 요구함
  - 이러한 가정은 일반 데이터에는 적용하기가 불가능하고, 색인을 구성하는 데이터의 경우 무리 없이 적용 가능함
- 트리 기분 규약
  - 그래프 기반 규약의 한 종류
  - 록 해제는 제약 없이 가능하며, 록을 해제하고도 다시 록을 요구할 수 있음
  - 다만 한 번 록을 획득하고 해제한 데이터 항목에 한해서는 다시 록을 잡을 수 없음
  - 2단계 록킹 규약과 차이점을 잘 알아두자
- 트리 기반 규약 예제
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/a0dbdf16-b430-498e-9fdd-2a5819e04113)
    - 그래프 기반 규약의 가장 큰 장점은 **교착 상태가 발생하지 않는**다는 것임
      - 데이터 간에 순서를 정한 후에 한 쪽 방향으로만 록 요구를 허용하기 때문
    - 다만, 그래프 기반 규약은 회복이 불가능한 스케줄을 생성하기도 하고, 연속 철회 스케줄을 생성하기도 함
      - 이를 해결하기 위해서는 commit 연산과의 관계성을 고려해야함
    - 또한, 데이터 항목에 대한 록을 그래프 기반 규약상의 이유로 획득하여야 함

### 다중 단위 크기 록킹
- 다중 단위 크기 록킹
  - 록킹을 거는 데이터 항목에 대한 설명
    - DBMS는 록킹이 적용되는 데이터 크기를 다양하게 지원하며, 이를 MGL(multiple granularity locking)이라 칭함
    - 데이터를 크기에 따라 계층적으로 표현이 가능
      - 임의 노드에 대해 명시적(explicitly) 록을 잡으면 그 하위 노드에 대해서도 묵시적(implicitly) 록을 잡는 효과가 있음
- 다중 단위 크기 계층 예제
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/321d2fba-ff43-4a5f-b789-cae994f811c6)
  - DB 내에 다수개의 관계(relation)가 존재
    - 관계 대신 file 사용 가능
    - 관계 내에 다수개의 page가 존재
    - 페이지 내에 다수 개의 터플(record)가 존재
- 의도 록 모드
  - 하위 노드에 대한 구체적인 미래 록 노드를 현재 노드에 표시
  - ex
    - 임의 노드에 IS(Intention-shared) 록을 요구하는 것은 하위 노드 중 하나에서 S 모드 록을 후에 걸겠다는 의도
    - 임의 노드에 IX(Intention-exclusive) 록을 요구하는 것은 하위 노드 중 하나에서 S모드 또는 X모드 록을 후에 걸겠다는 의도
  - SIX 모드 록은 S 모드 록과 IX 모드 록을 함께 표시하는 것
    - 즉, 해당 노드 전체에 대해 읽기 연산을 하고, 그 중 *일부* 데이터에 대해 후에 X록을 걸겠다는 의도
    - 트랜잭션이 테이블전체를 읽으면서 그 중 조건이 맞는 몇 개 레코드 값을 변경하고자 하는 연산에서 적합
- 의도 록 모드 호환성 행렬
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/67ee728e-b122-4ff9-ab82-bfc1d295d84e)
    - IS와 IS 호환 가능
    - IS와 IX
      - 현재 노드에서는 호환 가능하나, 추후에 하위 노드에서 S와 X를 동시에 걸려고 하면 호환이 안될 것임
    - IS와 S
      - 안될게 없지?
    - IS와 SIX
      - IS와 S, IS와 IX로 분리해서 생각할 것
      - 현재 노드에서는 당연히 호환 가능
    - S와 IX는 호환안됨!
    - X는 무엇과도 호환이 안됨
    - SIX는 IS만 호환 가능 주의
    - IX와 IX
      - X모드는 상호 호환이 안되나, 현재 노드에서는 호환 가능
      - 동일 하위 노드에 대해 X모드를 동시에 걸려고 하면 해당 노드에서는 호환 불가능
    - 행렬을 잘 기억하라! 대칭적임
- 다중 단위 크기 록킹 방법
  - 다중 단위 크기 록킹도 2단계 록킹 규약을 준수함
    - 임의 노드에 SIX 록을 갖고 있으면, 하위 노드에 대해 IX 또는 X록을 획독할 수 있음
    - 상위 노드에서 SIX록을 갖고 하위 노드에서 SIX록을 요구하는 것은 올바르지 않음
      - 상위 모드에서 S모드 록을 갖는데 하위 노드에 중복하여 S 모드 록을 요구하기 떄문
- MGL 예제 1
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/a584affd-bc83-4bcc-89e7-7a077bfc0e9c)
  - 두 트랜잭션 간 록 충돌이 없음
  - 두 르랜잭션이 동일 테이블의 다른 터플을 접근하는 경우, 두 트랜잭션이 동시적으로 수행됨
- MGL 예제 2
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/82c4f3a2-74e0-4a4e-b83e-4d4d6d8668e7)
  - 마찬가지로 록 충돌이 없음
- MGL 예제 3
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/809cfda5-4c11-46ca-9b32-956c805aca13)
  - T2가 R1 테이블에 SIX 록을 요구할 때 T1이 R1테이블에 대해 IX록을 갖고있으므로 록 충돌 발생
  - T2는 그 시점에서 록 해제를 기다려야 함
  - T1이 R1에 대한 록을 해제하면, 록 매니저가 T2를 깨워서 연산을 진행시킴

### 교착상태
- 교착상태 예제
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/6acd7844-2d88-4ccc-84f7-d903594515b4)
  - 위 그림의 경우, 교착상태에 빠지는 가장 대표적인 예시임
- 교착상태 처리
  - 타임아웃 방식
    - 일정시간 이상 트랜잭션이 록을 기다리지 않게 하는 방식
    - DB의 정확한 상태 정보를 수집하기 어려운 분산 환경에서 사용
  - 교착상태 방지 방식
    - 교착상태를 발생하지 않게 하는 방식
    - ex) 그래프 기반 록킹 규약 사용
    - 실효성 없음
  - 교착상태 감지 및 해결방식
- Wait-die 및 Wound-wait 방식
  - 첫 단어(Wait, Wound)는 먼저 생성된 트랜잭션이 취하는 형태를 의미
  - 두번째 단어(die, wait)은 후에 생성된 트랜잭션이 취하는 형태를 의미
  - 트랜잭션 생성 시점에 고유한 타임스탬프가 부여됨
    - 특정 트랜잭션 T1이 데이터 항목 X에 접근하려고 시도하고, X가 이미 다른 트랜잭션 T2에 의해 잠겨 있는 경우
      - T1의 타임스탬프가 T2보다 오래되었으면, T1은 wait
        - T1은 T2가 X의 잠금을 해제할 때까지 기다림
      - T1의 타임스탬프가 T2보다 크다면(비교적 최신의 것이라면), T1은 "Die"
        - T1은 중단되거나 롤백됨
    - 특정 트랜잭션 T1이 록을 요청하고, 그 록이 다른 트랜잭션 T2가 보유하고 있을 때, T1과 T2의 타임스탬프 비교
      - T1이 T2보다 오래된 경우, T1은 T2를 wound
        - 이는 T2를 중단시키고 록을 해제하는 것을 의미함, 이후 T1은 요청한 록을 얻게 됨
      - 반대로, T2이 T1보다 오래된 경우, T1은 대기(wait)상태로 들어감 
    - 모든 행동은 T1이 하는 행동임을 기억하라
- 교착상태 감지
  - 대기 그래프를 이용
    - 대기 그래프에서 노드는 트랜잭션을 표현, 에지는 트랜잭션 간 대기 상태를 의미
      - 방향 그래프에서 사이클 감지는 간단하므로, 교착상태 감지는 간단함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/43ffeeb5-855a-4689-919a-52c7f8c13abc)
    - 좌측 그림처럼 임의 트랜잭션이 두 개 이상의 트랜잭션을 기다릴 수도 있음
    - 왼쪽 그래프는 사이클이 없으므로 교착 상태가 아니고, 오른쪽 그래프는 사이클이 존재하여 T2, T3, T4가 교착상태임
- 교착상태 해결
  - 감지는 간단하나 해결은 간단하지 않음
  - rollback의 오버헤드가 존재
    - current blocker를 철회하는 방식이 널리 쓰임
    - current blocker
      - 대기 그래프에서 사이클을 완성하는 대기를 제공하는 트랜잭션
      - 위 그림에서, T3에서 T4로 가는 에지가 첨가되어 시스템이 교착상태가 되었음
        - current blocker는 T3이 되고, T3을 철회함
### 입력 및 삭제 연산
- 입력되는 새로운 터플과 제거되는 터플에 대해, 트랜잭션은 쓰기 록을 가져야 함
  - 쓰기 록은 배타적이고, 다른 트랜잭션은 새로운 터플 또는 제거되는 터플을 인식하지 못함
  - 따라서 터플 레벨 록킹을 지원하는 시스템에서는 **팬텀 현상**이 발생할 수 있음
- 팬텀 현상 예제
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/cc7ecf28-a5ac-487f-ba19-b576204199b3)
    - T1은 Account 테이블 전체를 읽고, Assets 테이블에 있는 total 값이 맞는지 확인하는 연산을 진행
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/027eab95-7410-4810-a8e8-404f890bbb20)
    - T1은 입장에서는 첫 read와 두번째 read에서 Busan 계좌에 합이 맞지 않다고 생각하는 오류가 발생
    - 이를 팬텀 현상이라 칭함
      - 팬텀 현상은 터플 레벨 록킹 때문에 발생함
      - 만약 테이블 록킹만을 하게 되면, T1이 Acoount 테이블에 대해 읽기 록을 갖게 되고, T2가 쓰기 록을 요청할 때 T2는 록 해제를 기다려야 함
        - 즉, 삽입 연산이 발생하지 않음 
      - 또한 상기 실행은 직렬가능 실행이 아님
- 팬텀 현상 처리
  - 팬텀현상은 테이블 록킹만을 사용하면 발생하지 않으나, 테이블 록킹은 트랜잭션의 동시 실행도가 현저히 나빠짐
  - 해결책으로 색인 록킹이 사용됨
    - 색인에 록킹을 적용
    - T1 트랜잭션이 색인에 록을 갖고 있으면, T2 트랜잭션이 새로운 터플 입력 불가
      - 새 터플을 입력하기 위해서 색인도 함께 입력해야 하는데, T1이 색인에 대해 록을 갖고 있으므로 T2에 록이 부여될 수 없음
- 색인 구조에 대한 2단계 록킹 규약
  - 색인에 적용하기에 2PL 방식은 비효율적임
  - 데이터 간의 순서가 자연적으로 발생하므로, 그래프 기반 록킹 규약을 사용함
- 색인 구조에 대한 동시성 제어
  - 동시성 제어를 2PL 방식으로 하면 저하를 유발
  - 내부 노드에 대한 록을 미리 해제하는 제어 방식이 다수 제안되어 있음
- 색인 구조에 대한 크래빙(crabbing)
  - B+-tree에서 루트 노드에 대한 록을 잡고
    - 그 후에 자식 노드에 대한 록을 잡고
    - 부모 노드에 대한 록을 해제하는 방식
  - 록을 잡고 풀고를 반복하면 B+-tree를 탐색함
    - 그러나 split 또는 merge로 부모 노드에 구조 변화가 필요하면
    - 부모 노드에 록을 다시 요청함
    - 교착 상태가 많이 발생할 수 있음(단점)
### SQL 트랜잭션 고립
- SQL 언어 트랜잭션
  - SQL 트랜잭션은 DML 문장이 나오면 암시적으로 시작
    - commit 또는 rollback을 통해 종료
    - auto commit을 통해 문장 하나하나를 각 트랜잭션으로 구성할 수 있음
    - 트랜잭션은 DML의 sequence로 이뤄져야 하며, DDL을 내포할 수 없음
    - DDL이 성공적으로 수행되면 그 시점에 트랜잭션이 자동 commit함
  - set transaction
    - 트랜잭션에 관한 변수 설정
  - savepoing, rollback to savepoint
    - 트랜잭션 rollback 시 트랜잭션 처음으로 롤백하지 않고, 트랜잭션 중간 시점까지 롤백하는 기능 제공
- 완화된 일치성 레벨
  - 완전환 고립도가 요구되지 않는 경우가 있음, 일치성보다 *성능*이 중요하기 때문
- 이단계 일치성
  - 완화된 일치성 중 보편적으로 지원하는 형식이 이단계 일치성임
  - 이단계 일치성에서는 읽기 록을 제한 없이 해제할 수 있음
    - 직렬가능성 스케줄이 보장되지 않음
  - 커서 안정 방식
    - 이단계 일치성 중 하나
    - 커서가 위치하는 동안에만 읽기 록을 잡고 있는 방식
      - 커서가 위치한 데이터는 타 트랜잭션에 의해 변경될 수 없음
- SQL 트랜잭션 고립
  - 상용 DBMS는 사용자 트랜잭션을 비직렬가능 실행할 수 있음
  - 즉, 사용자 요구에 의해 트랜잭션 고립도가 완화될 수 있음
  - serializable
    - 직렬가능
    - 모든 동시성 문제가 방지됨
  - repetable read
    - 직렬가능 X
    - lost update, dirty read, repeatable read
    - phantom read는 방지 못함
      - 한 번 읽은 값은 트랜잭션 끝까지 유지가 되나, 트랜잭션 중간에 생기는 새로운 터플은 인지하지 못할 수 있음
  - read committed
    - 직렬가능 X
    - 일반적으로 기본값으로 설정됨
    - lost update, dirty read 방지
    - Unrepeatable read 방지 못함
      - 타 트랜잭션이 두 번의 read 사이에 데이터를 변경할 수 있음
    - 또한, read 시 록을 집고 읽은 후에 즉시 록을 풀기 떄문에, read와 write 사이에 다른 트랜잭션이 값을 변경하려고 할 수도 있음
  - read uncommitted
    - 직렬 가능 X
    - 읽기 연산에서 록을 잡지 않음
      - 읽은 데이터에 신빙성 X
    - lost update가 일어나지 않음
      - 쓰기 록은 트랜잭션 마지막까지 보유하고 있기 때문에, 타 트랜잭션이 overwrite할 수 없음

### 스냅샷 고립
- 다중버전 기법
  - 각 데이터에 대해 다수개의 버전을 유지/관리하며 동시성 제어를 수행
  - multiversion timestamp odering 방식, multiversion two-phase locking 방식으로 구분
  - timestamp는 date + time 형식을 가짐
    - 시간의 흐름에 따라 항상 값이 증가
    - 엔티티의 id값으로 생각할 것
- multiversion timestamp odering 기법
  - 트랜잭션(Ti)는 트랜잭션이 시작된 타임스탭프 값을 가짐
    - 이를 TS(Ti)로 표시
    - 쓰기 타임스탬프 값은 해당 버전을 생성한 트랜잭션 또는 해당 버전에 새로운 값을 쓴 트랜잭션의 타임스태프 값
    - 읽기 타임스탬프 값은 해당 버전 값을 읽은 가장 최근 트랜잭션 타임스태프 값
  - 쓰기 연산 시행시에는 아래 조건 만족 시, 연산을 시도하는 트랜잭션이 롤백함
    - TS(Ti) < R-timestamp(Qk)
      - 쓰기 연산 시점이 너무 늦은 경우
      - 트랜잭션 Ti가 다른 트랜잭션이 이미 읽은 버전 값을 다른 값으로 갱신하려고 하는 경우
        - 갱신을 허용하지 않고 Ti가 록백함
  - 읽기 연산은 항상 기다림 없이 진행됨
    - 읽기 연산이 대기 상태에 빠지는 것을 방지
  - 단점
    - 읽을 시 R-timestamp 값을 갱신해야함
    - 트랜잭션 간 충돌을 항상 롤백으로 해결해야함
    - 데이터 버전 관리를 위해 데이터 공간 오버헤드가 증가
- 스냅샷 고립
  - OLAP(online analytic processing)는 대용량 data를 조회하는 연산
  - OLTP(online transaction processing)은 일상적인 transaction 처리, 수행시간 짧음
    - 록킹 방식은 긴 읽기 전용 트랜잭신이 갱신 트랜잭션의 수행을 오랫동안 막게 되어, 성능상 좋지 않음
  - 따라서 다중버전 동시성제어 기법으로 스냅샷 고립을 주로 사용함
  - 트랜잭션이 시작되는 시점의 데이터베이스 *스냅샷*을 해당 트랜젝션에게 제공
    - 이때 스냅샷은 커밋된 값으로만 구성됨
  - 트랜잭션은 해당 스냅샷에 대해서만 읽기/쓰기 작업을 수행함
  - 트랜잭션이 데이터 갱신 시(혹은 완료 시), 타 트랜잭션과의 출돌 여부를 판단하는 검증과정을 거침
  - 검증 과정 완료 시, 트랜잭션의 갱신 내용이 DB에 반영됨
- 스냅샷 읽기 예제
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/4e02e1ae-2f28-47fe-a4da-7c991c6204dc)
  - 각자의 스냅샷에 대해 읽기와 쓰기가 진행되는 것을 볼 수 있음
- 스냅샷 고립 예제
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/dfca82a6-ccea-4d29-8fb0-3b2fda2125d1)
    - 스냅샷에서 갱신 연산이 커밋되기 위해서는 검증 작업이 필요함
    - 갱신 내용은 검증이 끝날 때까지 해당 트랜잭션의 고유 workspace에 유지됨
    - 검증이 끝나면 갱신 내용을 DB에 반영함
    - 상기 예제에서 T2가 commit을 요구하면 갱신 연산을 검증함
      - 이미 동일 데이터 X에 대해 T3가 갱신하고 커밋을 했으므로, T2는 롤백됨
- 첫번째 커밋승(First-committer-wins) 대비 첫번째 갱신승(first-writer-wins)
  - 첫 번째 커밋승 방식에서는 6번 연산이 허용되지 않으므로, T2가 롤백함
  - 첫 번째 갱신 승 방식에서는 4번 연산이 허용되지 않으므로, T1이 롤백함
- 스냅샷 고립의 장점
  -  읽기 연산이 기다림 없이 수행되는 것임
  -  읽기를 위한 록 요청이 없으므로, 록 모드 충돌에 의한 타 트랜잭션 기다림 또는 없음
  -  단점
     -  간혹 직렬가능하지 않은 스케줄을 생성함
- 스냅샷 고립의 비직렬가능 수행
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/b7af1068-7972-4159-b2ce-c6e17926ab67)
  - 스냅샷 고립 방식은 상기 스케줄을 성공적으로 수행
    - T1과 T2가 상이한 데이터에 대해 쓰기 연산을 하기 때문
    - 상기 스케줄에 대한 스케줄 작성 시, T1과 T2에 대한 사이클이 만들어짐
      - 따라서 직렬가능 스케줄이 아님
    - 또한, `<T1, T2>`, `<T2,T1>` 중 같은 결과를 갖는 직렬 스케줄이 없음
  - 위와 같이 두 트랜잭션이 동일한 데이터 집합을 읽지만, 각 트랜잭션이 읽은 데이터를 기반으로 데이터를 수정한 후 서로의 변경사항을 인지하지 못하게 되면, 데이터의 일관성이나 무결성이 손상될 수 있음
  - 이를 쓰기 치우침(write skew)라고 칭함
- 스냅샷 고립 변형
  - 스냅샷 고립으로 비직렬가능 수행을 하는 경우(write skew)는 상이한 데이터를 갱신하는 경우임
  - 이에 대한 해결 방법으로, 트랜잭션 분리도를 조정하거나, 특정 문장을 사용할 수 있음
  - `select ... for update`
    - 이 경우 DBS가 select하는 데이터를 갱신하는 데이터로 취급하므로, 해결할 수 있음

## 연습문제 2장
### 1
- 2단계 록킹 규약은 항상 충돌 가능 스케줄을 생성함을 증명하라
  - 2단계 록킹 규약이 충돌 가능성을 보장하지 않는다 가정하자
  - 2PL을 준수하며, 비충돌가능한 스케줄을 생성하는 트랜잭션 집합 T0,T1,...,Tn이 존재한다 할 때
  - 비충돌가능한 스케줄이란, 선행 그래프의 순환을 야기하므로 선행 그래프에 다음과 같은 순환이 존재한다 가정
    - T0->T1->....->Tn-->T0
    - 이때 Ai는 Ti가 마지막으로 록을 획득하는 시점
  - 모든 트랜잭션에 대해, Ti->Tj인 경우, Ai < Aj가 성립
    - Ti가 연산을 마치고 록을 해제하면, shirinking phase에 들어가는 것이므로
  - 따라서 순환에 대해 A0 < A1 < .... < An < A0이다
  - 그러나, A0 < A0은 모순이므로, 이러한 순환은 존재할 수 없다
  - 따라서 2PL은 충돌가능하지 않은 스케줄을 생성할 수 없다.
- 그렇다면 growing phase에서 록 하향변환을 허용하면 상기 증명에서 어떤 문제점이 발생하는가?
### 2
-  ![image](https://github.com/googoo9918/TIL/assets/102513932/d2960360-2a01-4f53-ab7d-522bb41b40db)
  - 트랜잭션 T1과 T2에 록과 언록 명령을 추가하여 두 단계 록킹 프로토콜을 준수하도록 만들 것
    - 추가적으로, 이 실행이 데드락을 초래할 수 있는가?
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/d595b51c-1cab-4aea-81c9-c4fc9158446e)

### 3
- What benefit does rigorous two-phase locking provide? How does it compare with other forms of two-phase locking?
  - 엄증한 두 단계 록킹이 어떤 이점을 제공하고, 이것은 다른 형태의 두 단계 록킹과 어떻게 비교되는가?
  - 그냥 2단계 록킹은 쓰기 록을 수정 후에 해제하지만, 이는 연쇄 철회 문제점이 남아있음
  - strict 2단계 록킹은 쓰기 록을 트랜잭션 끝까지 보유하고
  - rigorous 2단계 록킹은 읽기 록까지 트랜잭션 끝까지 보유함
    - 또한 strict는 단순히 직렬 가능성만 보장하지만
    - rigorous는 커밋 순서가 직렬화 가능한 순서와 같음을 보장함

### 4
- Show by example that there are schedules possible under the tree protocol that are not possible under the two-phase locking protocol, and vice versa.
  - 트리 프로토콜 아래에서 가능한 스케줄 중에서 두 단계 록킹 프로토콜에서는 불가능한 스케줄이 있다는 것과 그 반대의 경우를 예시를 통해 보여라
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/9520a68f-f549-4297-802d-84e5a1517e16)
    - 트리 프로토콜에서는 가능하지만 2PL에서는 불가능한 스케줄 예시
      - 2PL에서는 unlock을 하고 다시 lock을 할 수 없기 때문에 불가능(감소 단계)
    - 2PL에서는 가능하지만 트리 프로토콜에서는 불가능한 스케줄 예시
      - 트리 프로토콜에서 lock(B)를 하기 위해서는 lock(A)가 선행되어야 하기 때문에 불가능

### 5
- In multiple-granularity locking, what is the difference between implicit and explicit locking?
  - 다중 단위 크기 록킹에서, implict와 explict locking의 차이점은 무엇인가?
  - 트랜잭션이 한 노드를 명시적으로(explict) lock하면, 노드의 하위 항목도 동일한 모드로 암시적(implicT)으로 잠김
  - 트랜잭션에서는 하위 노드들을 명시적으로 잠글 필요가 없음

### 6
- Although SIX mode is useful in multiple-granularity locking, an exclusive and intend-shared (XIS) mode is of no use. Why is it useless?
  - 다중 단위 크기 록킹에서 SIX 모드는 유용하나, XIS 모드는 쓸모가 없다. 왜인가?
  - X(배타적 록)은 다른 모든 록 유형과 호환되지 않기 떄문
    - 한 번 노드가 X모드로 록되면, 모든 트랜잭션은 어떤 모드에서도 해당 노드의 하위 항목에 접근할 수 없음
    - 따라서 의미가 없음

### 7
- ![image](https://github.com/googoo9918/TIL/assets/102513932/abbe7884-4807-4b52-a604-ce5ba0bb6d55)
  - SIX-lock 을 설정하기 위해서는, 상위 노드에 IX 록을 걸어야 함

### 8
- Explain the reason for the use of degree-two consistency. What disadvantages does this approach have?
  - 2단계 일치성의 사용 이유를 설명하고, 이 접근법에서 생기는 단점을 설명하라
  - 2단계 일관성은 cascading abort를 방지하고, 읽기 록을 제한 없이 해제함으로써 동시성을 즐가시킴
  - 단점은 직렬화를 보장하지 않는다는 것임

### 9
- Explain the phantom phenomenon. Why may this phenomenon lead to an incorrect concurrent execution despite the use of the two-phase locking protocol?
  - 팬텀 현상에 대해 설명하라, 왜 이 현상은 2PL을 사용함에도 불구하고 잘못된 동시 실행을 초래할 수 있는가?
  - 팬텀 현상은 다수 개의 트랜잭션이 삽입 또는 삭제 되는 터플에 의해 충돌이 발생하는 현상
  - 관계 내의 튜프플 뿐 아니라 인덱스, 메타 데이터도 있기 때문에 인덱스나 메타데이터에도 잠금을 수행해야 하고, 이렇게 하면 팬텀 현상을 피할 수 있음

### 10
- SQL 표준에서 정하는 read-committed isolation level로 트랜잭션을 수행하는 경우, 생성되는 스케줄은 cascading aborts 현상이 발생 가능한가? (yes/no)  그 이유를 반드시 명시하시오. 
  - read-comitted isolation level은 트랜잭션이 오직 커밋된 데이터만 읽도록 보장
  - 트랜잭션 Ti는 아직 커밋되지 않고 동시 실행중인 트랜잭션 Tj에 의해 수정된 데이터 항목을 읽을 수 없음
  - 따라서 트랜잭션 간 독립성이 보장되고, cascading aborts 현상이 발생하지 않음

### 11
- ![image](https://github.com/googoo9918/TIL/assets/102513932/47b5a243-9f2a-4c77-8beb-ba865fbae6e3)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/1cfeac60-b610-445d-9caf-b86940878bc5)
  - T4를 유의깊게 관찰할 것

### 12
- ![image](https://github.com/googoo9918/TIL/assets/102513932/8652c974-2be9-437e-9b1d-df7e018be405)
  - No, 감소 단계(Shrink phase)에서 lock(B)를 하였음
  - No, 노드 C에 대해 록을 잡기 전에 B에 대해 록을 먼저 잡아야 함

### 13
- ![image](https://github.com/googoo9918/TIL/assets/102513932/10efcf52-35cb-43ad-a329-2277aece8d2a)
  - T1이 old, T2가 new
    - 따라서 T1이 wait, T2는 계속 실행
    - 따라서 false
  - T2가 old, T3가 new
    - 따라서 T2가 wound, T3가 wait
    - 따라서 true, T2는 T3의 실행을 종료시키고 록을 가짐(록 기다림 없이 진행함)
  - no, restart하는 transaction은 항상 원래 timestamp를 갖고 실행해야 함

### 14
- ![image](https://github.com/googoo9918/TIL/assets/102513932/4f257e9f-e910-4208-b9b5-d770b0f483b2)
  - (a) T1 트랜잭션이 T3가 갖고있는 데이터를 요청하는 경우, 록 충돌이 생김 wait-die 형식에서, T3는 abort 되자않고 실행되는가?
    - T1이 old T3가 new
    - 따라서 T1은 wait, T3의 실행이 끝나면 록을 얻게됨 
    - 따라서 yes
  - (b) T2 트랜잭션이 T3가 갖고있는 데이터를 요청, wound-wait 형식에서 T2는 abort 되지않고 실행하는가?
    - T2가 old, T3가 new
    - 따라서 T2는 wound, T3의 실행을 종료시키고 록을 얻게 됨
    - 따라서 yes
  - (c) T1이 T2 트랜잭션을 기다리고, T3가 T2 트랜잭션을 기다리는 경우 wait-for graph를 그려라, 또한 이 그래프는 T1, T2, T3간의 deadlock을 보이는가?
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/ed1474e1-ece8-4968-865f-7d7c7bcf615e)
    - 화살표 방향을 잘 기억할 것

### 15
-  ![image](https://github.com/googoo9918/TIL/assets/102513932/e584decd-0a84-4429-8379-4d3a4afcd7a7)
   -  (a) 결과가 이렇게 나왔는데, 어떤 레벨에서 이런 결과가 나올 수 있는지?
      -  현재 avg와 sum 사이에서 동시성 이슈가 발생했음
      -  이는 unrepeatable read임
      -  따라서 이를 방지할 수 없는 **read comitted, read uncommitted**에서 발생 가능함
   - (b) 그렇다면, 어떤 level에서 밑 결과가 같은지?
     - **serializable, repeatable read**
     - 터플이 삽입/삭제 되는 상황이 아니므로, phantom 현상은 일어나지 않음

### 16
- ![image](https://github.com/googoo9918/TIL/assets/102513932/05089678-7758-4a42-9d62-92677fbd92d8)
  - 다중 버전 타임스탬프 순서 지정 방식은 직렬가능성을 보장하나, 스냅샷 고립은 직렬가능성을 보장하지 않는다
    - 이 차이를 초래하는 프로토콜 간 주요 차이점은 무엇인가?
  - 타임스탬프 검증 단계는 트랜잭션 간 공통으로 작성된 데이터 항목의 존재를 확인하나,
    - 스냅샷 고립 프로토콜에서는 읽기와 쓰기에 대한 검증이 없음
    - 따라서 스냅샷 고립에서는 write skew 문제가 발생
      - 반면 다중 버전 타임스탬프 순서 지정은 트랜잭션 T1이 
      - 더 높은 타임스탬프를 가진 트랜잭션(new, T2)이 읽은 값을 다른 값으로 갱신하는 경우,
      - 허용하지 않고 T1을 록백함  
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/9172b71e-27ef-4557-ac8c-a2b2a783e480)
    - 여기에 multiversion timestamp-ordering protocol을 적용해 보자
    - T1 timestamp: 110, T2 timestamp: 120
    - data A 
      - value:10, R-timestamp: 5 -> 110 -> 120, W-timestamp: 5
    - data B
      - value: 20,  10 R-timestamp: 3-> 110 -> 120    120, W-timestamp: 3   120
    - T1 write(A) 시점에서 A R-timestamp 값이 T1 timestamp 값보다 크므로, T1 aborts
    - T2 write(B) 시점에서 B의 새로운 version이 생성됨
      - 즉, snapshot isolation의 write skew 문제가 multiverstion timestamp ordering 방식에서는 발생하지 않음
### 17
- ![image](https://github.com/googoo9918/TIL/assets/102513932/0ef9b4b5-1510-4938-b87f-85bb1378cb6a)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/1da4330c-ca9f-4cb3-bf50-fcdfb8bd08dc)
  - 5, 6, 9 자세히 살펴볼 것!

## 복구
### 장애 및 복구
- 장애 분류
  - DB 시스템이 처리하는 장애는 세 가지
  - 트랜잭션 장애
    - 트랜잭션 내부 논리 오류, 사용자의 명시적 요구, 시스템 내부 결정에 의해 발생 가능
    - 교착상태에 있는 트랜잭션 중 하나의 트랜잭션은 철회되어야 함
      - 철회되는 트랜잭션에게 장애가 발생하는 것
  - 시스템 장애
    - 휘발성 기억 장치인 메모리에 문제가 발생, 메모리 내용이 사라짐
      - 정전, 운영체제 오류, 하드웨어 결함등
  - 디스크 장애
    - 하드웨어 및 소프트웨어 결함으로 디스크 내용이 사라짐
  - 장애는 예고 없이 발생함
- 복구 알고리즘
  - 정상 상태에서 시스템 복구를 대비하기 위해 수행하는 연산
  - 장애가 발생했을 때 복구하기 위해 수행하는 연산
- 저장 장치 분류
  - 휘발성과 비휘발성으로 구분
  - 안정 저장 매체(Stable storage)
    - 어떠한 장애가 발생하여도 저장 내용이 상실되지 않는 가상적인 저장매체
      - 현실적으로는 다수 개의 하드디스크에 체계적으로 중복 분산 복사 및 유지
    - 복구 기법을 설명하기 위한 기본 가정 중 하나
  - 안정 저장 매체 구현
    - 디스크 오류가 발생하지 않는 저장 장치
    - 디스크 읽기, 쓰기 연산에서 오류가 발생하지 않음
    - 기본적으로 동일 블록을 중복적으로 저장 및 관리하는 방식 사용
    - 중복 장소에 동일 블록 쓰기 연산이 성공적으로 종료해야 쓰기 연산이 완료된 것
    - RAID 저장 시스템 사용
      - 4장에서 자세히 설명
- Disk I/O는 원자성을 가져야 함
  - 디스크 I/O는 페이지 단위로 이루어지고, 모든 디스크 I/O는 원자성을 가져야 함
  - 쓰기 연산이 일부분만 수행되면 안되기 때문
  - 운영체제 단독으로 지원은 실제로 불가능, RAID에서는 하드웨어 지원(ex battery-backup memory)으로 원자성 I/O 지원
- 데이터 위치
  - 데이터베이스 시스템에서는 동일 데이터가 3군데 위치에 존재 가능
  - 디스크 블록, 메인 메모리 상에 데이터 버퍼 블록, 트랜잭션 프로세스 메모리 영역
    - 데이터 버퍼와 프로세스 메모리 영역은 메인 메모리 내에 존재
      - 메인 메모리가 고장이 나는 경우에는 데이터 손실, 디스크에 존재하는 데이터는 손상 X
    - 프로세스 고유 영역에서 버퍼 블록으로 데이터 이동은  `read()`, `write()` 등의 DBMS 혹은 사용자 요청에 따라 이뤄짐
    - 데이터 버퍼에서 디스크로 데이터 이동은 `input()`, `output()`등의 운영체제의 결정에 따라 이뤄짐
    - 사용자가 데이터 쓰기를 완료하는 것은 데이터 버퍼에 데이터 쓰기임
      - 쓰기 완료 후에 시스템 장애 발생 시, 디스크에는 데이터 갱신이 반영되지 않았을 수 있음
- ![image](https://github.com/googoo9918/TIL/assets/102513932/38f1386f-164d-4b5f-8665-e77ed12f115e)
  - 데이터는 기본적으로 disk에 존재
  - 각 위치별 연산을 인지할 것
  - 사용자가 데이터 갱신을 하는 경우, 시스템 버퍼에 존재하는 값과 사용자 영역에 존재하는 값이 상이함
    - write를 이용해 시스템 버퍼에 복사, output을 통해 디스크에 복사 가능
  - 세 군데 존재하는 데이터 값이 모두 상이할 수 있음
    - 가장 정확한 데이터 값은 사용자 영역에 존재하는 데이터 값임
### 복구 기법
- 복구 기법
  - 복구 기법에서는 DB에 변화가 일어나기 전 변화에 대한 정보를 안전저장장치에 미리 기록해야 함
  - shadow-paging(그림자 기법)
    - 요즘은 사용되지 않는 기법
    - 데이터 클러스터를 제공하지 못함
    - 동시 트랜잭션이 많은 경우, 그림자가 많이 생성되어 문제 발생
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/7a6f7c29-ec89-488d-8cbd-3579b2cdcf02)
      - 실제 데이터를 변경하는게 아닌, 새 복사본을 생성하고 pointer를 가리킴
  - log-based recovery
    - Normal Processing(정상 처리)
      - 로그는 안전저장장치에 기록, 여러 가지 상황으로 인해 손실되는 경우가 없게 함
      - 연산 전의 값과 연산 후의 값을 기록
      - 디스크와 메인메모리 간 데이터 이동은 디스크 블록 단위로 이뤄짐
        - 로그 블록도 블록 단위로 데이터 저장
      - 엄격 2PL 동시성 제어(트랜잭션 종료 시에 쓰기 록 해제)를 가정
      - 트랜잭션은 동시에 다수가 실행, 로그 블록 하나 내에는 다수 개의 트랜잭션 로그 레코드가 저장됨
        - 모든 트랜잭션은 단일 디스크 버퍼와 단일 로그를 공유함
    - CheckPoint(검사점)
      - 주기적으로 검사점 연산을 수행, 장애 시 복구를 빠르게 수행
      - 검사점 연산
        - 주기억장치에 존재하는 모든 로그 레코드와 변경된 데이터 페이지를 디스크에 반영
          - 디스크에 저장되어 있는 데이터베이스 상태와 주기억 장치에 저장되어 있는 데이터베이스 상태를 동일하게 함
        - 검사점 연산 정상 수행 시, 검사점 로그를 안전 저장 장치에 기록
        - 검사점 로그는 검사점 시점 기준으로 동작 중인 트랜잭션 목록 기록
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/e1cb72a4-4c05-4e90-b0ab-eab28d0ceb3a)
        - checkpoint로 인해 T1은 이미 디스크에 반영되어 있으므로, 더 이상의 복구 연산이 필요 없음
        - T2, T3는 필요에 따라 재연산(REDO)을 수행해야함
        - T4는 수행한 연산을 되돌려 주는 연산(UNDO)를 수행해야 함
    - Recovery
      - 아주 간단한 로깅 방식 예시
      - 시스템 장애 발생 시, 로그와 디스크에 저장된 데이터만 존재함
        - 1: 로그를 분석
          - 마지막 검사점 이후 진행한 트랜잭션 중
          - 완료하였으나 디스크에 반영되지 않아 재연산해야 하는 트랜잭션(REDO)
          - 완료되지 않은 트랜잭션(UNDO)으로 분류
        - 즉, 장애 시 진행되고 있던 트랜잭션은 UNDO, 장애 전 checkpoing 이후 완료한 트랜잭션은 REDO
    - **로깅 예제**
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/0a9eb418-c130-43fc-a34c-8488f5855a59)
      - T0은 checkPoint 전에 커밋(완료) 되었으므로 상관 X
      - 에러 시점에서 커밋(완료)되지 않았으므로 T1과 T2는 UNDO
        - UNDO는 checkpoint와 상관없음, 커밋과 연관
      - T3는 checkpoint 이후에 커밋되었으므로 REDO

### 데이터 버퍼
- 버퍼 관리
  - 디스크에 존재하는 데이터 처리를 하기 위해 메인 메모리로 데이터를 읽어와야함
  - 디스크 접근은 비싼 연산, 가능하면 디스크 접근 횟수를 줄이는 것이 좋음
  - 데이터 요청 시, DBMS는 데이터가 버퍼에 존재하는지 확인 후 있으면 반환, 없으면 디스크에서 읽어와서 반환
  - 모든 버퍼 블록이 사용중인 경우, 사용 중인 블록 중 하나 선택 후 변경사항을 디스크에 적용한 이후 새로운 데이터를 위한 공간으로 확보할 수 있음
  - DBMS 버퍼는 운영체제 버퍼와 독립적으로 운영 가능
  - DBMS가 독단적으로 데이터 버퍼를 운영할 수도 있음
- 버퍼 교체 정책
  - 버퍼에 더 이상 가용한 블록 공간이 없을 때 이미 존재하는 블록을 선택
    - 선택된 버퍼는 더 이상 공간을 차지하지 않고, 블록 내용이 변경되었다면 디스크에 내용을 반영해야 함
    - LRU(Least Recently Used) 주로 이용
      - 가장 오랫동안 사용되지 않은 블록 선택 제거
    - toss-immediate strategy
      - 버퍼에 저장된 블록 중 변경되지 않은 블록를 버림
    - MRU(Most Recently Used)
      - 가장 최근에 사용된 블록을 교체 대상으로 선택
      - 순차적으로 한 번씩 접근되는 패턴에서 효과적
    - 복구 기능 지원을 위해 forced output 기능 제공
      - DBMS가 원하는 시점에 특정 블록을 디스크에 즉시 쓰는 기능(flusing)을 제공 
      - 커밋 되기 전 모든 변경사항이 디스크에 저장되도록 강제함
- 데이터 페이지 버퍼링
  - DBMS는 데이터 페이지를 버퍼링함
  - pinned block
    - 특정 트랜잭션이 블록을 독점적으로 접근 할 때 발생
      - ex) 디스크에 블록 flush, 블록을 read, 블록에 write
    - 이때 해당 블록에는 갱신 연산이 수행되지 않아야 함
      - 이를 위해 latch, semaphore를 사용, 블록을 pin함 
      - 래치는 운영체제가 지원하는 기능
      - 래치 유지 시간은 데이터베이스 록 유지 시간보다 짧음
      - 래치에 의해 교착 상태가 발생하지 않도록 사용해야 함
      - 데이터베이스 록은 DBMS가 관리하는 동시성 제어 방식
      - 다수의 록 모드 존재(latch는 일반적으로 배타 모드로 사용)
      - 록에 의해 시스템이 교착 상태에 빠질 수 있음
      - 록은 운영체제의 latch를 사용해 구현
  - 구현 방식
    - 메인 메모리 영역에 데이터베이스 버퍼 구현 가능
    - 가상 메모리 영역에 데이터베이스 버퍼 구현 가능
  - Dual paging
    - 메모리 공간을 확보하기 위해 DB의 데이터 블록을 디스크의 swap 영역에 저장하는 경우
    - DBMS가 블록을 다시 사용하려고 할 때 swap영역에서 다시 메모리로 input해야 사용할 수 있음
    - 이후 DBMS는 이 블록을 다시 디스크에 output해야하고, 이러한 과정은 성능을 저하시킴
    - 따라서 디스크의 swap영역 대신, 데이터 블록을 output 하는 방식을 취해야 함
- 슬롯 페이지 구조
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/461e6e98-c0ee-4ae0-bb78-f106cac40210)
    - 가변길이 레코드를 지원
    - 페이지 헤더, 정해진 수의 slot이 나옴
      - 각 slot에는 페이지에 저장되는 레코드 주소를 가짐
      - 페이지 헤더에는 페이지 메타데이터 저장
    - 레코드는 페이지 끝에서부터 저장
      - 페이지 중간에는 미사용 공간 존재
    - 페이지 내에서 레코드 이동은 자유로움
      - 레코드 물리적 위치 변경 시, slot 번호는 동일
      - slot에 들어가는 페이지 주소만 변경
      - 외부에서는 페이지 고유 번호와 slot 번호만 갖고 레코드 접근 가능
    - 일반적으로 페이지 크기보다 큰 레코드는 지원하지 않음
    - clob, blob 필드는 별도로 저장 및 관리
      - 포인터 값만 페이지에 저장
- Steal/Force 방식
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/ec8f0c37-811c-4086-834b-0ae1d4274914)
  - 대충 구조가 어떤식으로 생겼는지는 봐둘 필요가 있음
### 로그 기반 복구
- 로그 블록 버퍼
  - 로그 레코드를 저장하는 로그 블록도 데이터 블록처럼 버퍼링을 진행
  - LRU는 데이터 블록에만 적용, 로그 블록에는 적용되지 않음
  - 로그 블록이 안전 저장 장치로 내려가는 시기
    - 트랜잭션 커밋
      - 트랜잭션 완료 시점에는 모든 관련 로그 블록이 안전저장장치에 쓰기 연산이 이뤄져야 함
      - 다만, 다수개의 로그 레코드가 로그 블록에 찰 때까지 기다렸다가 쓰기 연산 가능
        - 다수개의 트랜잭션 동시 완료 효과, 이를 그룹 완료 기법이라 칭함
    - 로그 블록이 full 되었을 때
    - 구체적인 로그 블록 쓰기에 대한 요구가 있을 때
  - 로그 레코드(기록) 버퍼링 시 규칙
    - 로그 기록 순서가 유지되어야 함
    - 트랜잭션 T1은 커밋 로그 기록이 안정 저장 장치에 저장된 이후 커밋이 가능
    - 버퍼에 있는 데이터 블록을 디스크로 output하기 전, 블록에 관련된 모든 로그 기록이 안정 저장 장치에 output 되어야 함
      - 이를 Write-Ahead Logging(WAL) 규칙이라 칭함
- 복구 알고리즘
  - 롤백(철수) 시
    - Undo 작업 수행
      - Commit 되지 않은 모든 트랜잭션 취소
      - <T1, X, 3, 4>로그 레코드를 Undo(X에 3을 write), <T1, X, 3> 형태의 로그 레코드 작성
      - 이러한 undo 작업 로그를 CLR(compensation log record)이라 칭함
      - Undo 작업에 대해 로그 레코드가 발생하는 것에 대해 주의할 것
      - <T1 start> 레코드를 찾게 되면 로그 스캔 중단, <T1 abort> 레코드를 작성함
  - Redo
    - 가장 마지막 checkpoint에서 시작, 모든 로그 레코드를 Redo
    - <checkpoint L> 레코드를 찾고, undo-list를 L로 설정
      - Redo List가 아닌 Undo List임에 주의하라
    - <T1, X, 3, 4> 형태의 레코드가 발견될 때마다 4를 X에 다시 쓰면서 Redo
    - <T_i start> 로드 레코드가 발견 시
      - T_i를 undo-list에 추가
    - <T_i commit> 또는 <T_i abort> 로그 레코드 발견시 T_i를 undo-list에서 제거
  - Undo 단계는 Redo 단계에서 작성한 undo 리스트에 속한 모든 트랜잭션을 undo함
    - Undo 단계는 로그 파일의 역순으로, Redo 단계는 순차적으로 진행
  - 예제
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/0a9eb418-c130-43fc-a34c-8488f5855a59)
  - repeating history
    - abort하는 트랜잭션도 Redo 단계에서 다시 수행함
      - 낭비처럼 보일 수 있으나, 복구 과정을 크게 단순화시킴
        - 모든 작업을 재실행함으로써, 복잡한 조건 분기나 상태검사를 수행할 필요 없음
        - 모든 변경사항을 DB에 일관되게 적용 가능
        - 따라서 위 방법이 더 신뢰성 있고 예측 가능하게 만드는 방법임
  - 예제
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/39cca5bc-424f-4e85-8118-48179792e5b3)
      - Checkpoint(4)로 돌아감 -> T0과 T1이 Undo list
      - 5, 6 redo -> 6에서 T1은 commit 했으니 Undo list에서 제외
      - 7 -> T2 Undo list에 포함 {T0, T2}
      - 8, 9 ,10 redo -> 10에서 T0이 undo list에서 제외 {T2}
        - 9는 abort연산 시작이고, 10은 abort 연산 수행완료임
      - 11 redo
      - 역순(Undo) 시작
        - 11 undo, 8 undo, 7 undo
        - <T2 abort> 레코드 작성 시작(CLR(보상 로그))
          - <T2,C,600>(11의 undo), <T2,A,500>(8의 undo), <T2 abort> (7의 undo)
            - 12, 13, 14가 복구 시 생성됨
  - 퍼지 검사점(fuzzy checkpointing)
    - 검사점이 진행되는 동안 모든 DB연산을 정지시키지 않고 일반 DB 연산이 수행하도록 허용하는 검사점
    - 검사점 로그 레코드를 안정 장치에 기록, 변경된 버퍼 리스트(디스크에 쓰기 연산해야 하는 블록 리스트)를 만든 후에는 일반 DB 연산을 허용함
    - 물론, 블록을 디스크에 쓸 때는 WAL 원칙을 준수해야 함
      - 버퍼에 있는 데이터 블록을 디스크로 output하기 전, 블록에 관련된 모든 로그 기록이 안정 저장 장치에 output 되어야 함
    - 검사점 레코드 로그 위치를 안정 저장 매체의 정해진 위치에 저장해야 함
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/6ea86341-84fd-431d-818d-cdf74384335d)
      - 퍼지 검사점 방식에서 장애 발생 시
        - 안정저장 매체의 last checkpoint에 저장되어 있는 checkpoint log record 이후부터 처리하면 됨
        - 이전의 로그 레코드는 이미 디스크에 반영됨
  - 비활성 저장장치 장애 복구
    - 디스크 덤프 방식 사용
      - 디스크의 전체 내용을 다른 저장 장치로 복사
      - 최근에 dump된 DB 상태로부터 이후에 Commit된 트랜잭션을 redo, 장애시의 DB 상태로 복구

### 원격 백업
- 원격 백업 시스템
  - 주 사이트에 재난이 발생하여도 백업 사이트가 계속 수행, 시스템 가용성을 증가
    - 시스템 장애 시간을 최소화 하게 하는 가용성이 높은 시스템을 요구함
    - 주 사이트 장애를 원격 백업 시스템에서 반드시 감지하여야 함
      - 이를 위해 다수개의 통신 링크를 유지/관리
      - 주 시스템은 지속적으로 heart-beat message를 발송
  - 제어 이관
    - 로그 레코드를 갖고 복구 연산을 하여 주 시스템 상태와 동일하게 만듬
    - 백업 시스템이 주 시스템 역할을 할 수 있음
  - 높은 가용성
    - 재난 시 빠른 회복 시간이 중요함
    - 빠르게 제어권을 갖기 위해 로그를 받는 즉시 적용하여 빠른 회복시간을 지원할 수 있음
      - hot-spare 설정
    - 동일 데이터를 분산적으로 다수 장소에 저장하는 분산 데이터베이스 방식도 사용 가능
      - 구현 및 관리 관점에서 고비용을 요구하나, 주로 더 높은 가용성을 제공함
  - 완료 시간
    - 트랜잭션의 지속성을 보장하기 위해 원격 시스템에 트랜잭션 완료 로그가 기록되어야 해당 트랜잭션이 완료할 수 있음
      - 다만, dealy를 줄이기 위해 완화된 기준을 제공할 수 있음
      - One-safe
        - 트랜잭션의 커밋 로그 레코드가 주(Primary) DB에 기록되는 즉시 트랜잭션을 커밋
        - 문제점
          - 백업 DB가 주 DB를 대체하기 전에 주 DB의 업데이트가 백업에 도착하지 않을 수 있음
          - 즉, 백업 서버가 최신 상태가 아닐 수 있음
      - Two-very-safe
        - 트랜잭션의 커밋 로그 레코드가 주 DB와 백업 DB 모두에 기록 될 때만 트랜잭션을 커밋
        - 문제점
          - 가용성 감소
          - 주 DB나 백업 DB중 하나라도 실패하면 트랜잭션이 커밋되지 않음
      - Two-safe
        - 주 DB와 백업 DB가 모두 활성 상태일 때
          - Two-very-safe 전략을 따름
        - 주 DB만 활성 상태일 때
          - One-Safe 전략으로 전환
            - 백업 DB가 실패하거나 접근할 수 없는 상황에서도 시스템이 계속 작동
            - 가용성을 높임
## 연습문제 3장
### 1
- When the system recovers from a crash, it constructs an undo-list and a redo-list. Explain why log records for transactions on the undo-list must be processed in reverse order, while those log records for transactions on the redo-list are processed in a forward direction.
- 시스템이 충돌에서 복구될 때, 실행 취소(undo) 목록과 재실행(redo) 목록을 구성합니다. 실행 취소 목록에 있는 트랜잭션의 로그 레코드는 역순으로 처리되어야 하는 반면, 재실행 목록에 있는 트랜잭션의 로그 레코드는 순방향으로 처리되는 이유를 설명하라
  - 예를 들어 하나의 데이터 항목이 여러 번 업데이트 되는 경우, (1->2, 2->3) undo 로그 레코드를 순방향으로 처리하면 데이터의 최종 값이 2로 설정됨 반면 역순으로 처리하면 값이 올바르게 1로 설정됨 마찬가지로 redo도 역방향으로 처리하면 최종값이 2로 잘못 설정되기 때문에 순방향으로 처리해야함

### 2
- Stable storage cannot be implemented.
  - 안정 저장 장치는 실제로 구현할 수 없음
(a) Explain why it cannot be.
  - 모든 저장 장치는 하드웨어로 만들어져 있고, 모든 하드웨어는 기계적이나 전자적 결함이 생길 수 있기 때문
(b) Explain how database systems deal with this problem.
  - 분산 시스템으로 이를 근사하게 구현
    - 데이터를 동시에 여러 저장 장치에 기록
    - 만약 한 장치에 문제가 생겨도, 다른 장치에 있는 데이터로 백업이 가능

### 3
- Explain how the buffer manager may cause the database to become inconsistent if some log records pertaining to a block are not output to stable storage before the block is output to disk.
- 버퍼 관리자가 블록과 관련된 일부 로그 레코드를 안정 저장 장치에 output 하기 전에 블록을 디스크에 출력하는 경우 DB가 일관성을 잃게 될 수도 있는 이유에 대해 설명하라 
  - 데이터 항목 x가 로그 레코드가 안정 저장 장치에 기록되기 전에 디스크 상에서 수정되면, x의 이전 값에 대한 유일한 기록은 주 메모리에 있게 되는데, 이는 시스템에 crash가 나는 경우 손실됨
    - 만약 트랜잭션이 crash시점에 아직 commit되지 않았다면, 복구할 수 없는 일관성 문제가 생김
    - 따라서 WAL 원칙을 엄격하게 준수해야함
      - 버퍼에 있는 데이터 블록을 디스크로 output하기 전, 블록에 관련된 모든 로그 기록이 안정 저장 장치에 output 되어야 함

### 4
- Outline the drawbacks of the no-steal and force buffer management policies.
- no-steal 정책과 force 정책의 단점
  - no-steal 정책의 단점
    - 이 정책에서는 트랜잭션이 완전히 끝날 때까지 디스크에 저장하지 않음
      - 따라서 많은 수의 업데이트를 수행하는 트랜잭션에서 적합하지 않음
        - 버퍼를 가득 채울 수 있기 때문
  - force 정책의 단점
    - 트랜잭션이 커밋 하기 전에 모든 변경사항을 바로 디스크에 저장하도록 강제함
      - 이 과정에서 디스크 I/O에 대한 시간이 오래 걸림

### 5
- Disk space allocated to a file as a result of a transaction should be not released even if the transaction is rolled back.
- 트랜잭션 결과로 파일에 할당된 디스크 공간은 트랜잭션이 rollback되어도 해제되지 않아야 함
  - 다른 트랜잭션이 같은 페이지에 레코드를 저장했을 수 있기 때문

### 7
- ![image](https://github.com/googoo9918/TIL/assets/102513932/b4598263-9e96-4c8c-a4c9-cadd43f5c07b)
  - 풀어볼 것!

### 9
- Expalin the difference between a system crash and a disaster
  - 시스템 충돌에서는 CPU가 다운되고, 디스크가 충돌될 수 있지만 안넌 저장 장치는 시스템 충돌을 견뎌낼 것임
  - 그러나 disaster에서는 모든 것이 파괴됨, 따라서 안전 저장 장치는 disatster를 견뎌내기 위해 분산되어야 함

### 10
-  For each of the following requirements, identify the best choice of degree of durability in a remote backup system.
- 다음 각 요구 사항에 대해 원격 백업 시스템에서 최적의 내구성 정도를 식별하라
(a) Data loss must be avoided but some loss of availability may be tolerated.
- 데이터 손실은 피해야 하지만 일부 가용성 손실은 용인될 수 있음
  - Two very Safe가 적합, 가용성이 낮지만 primary와 backup DB가 모두 활성 상태일때만 동작하기 때문에 안정성 보장
(b) Transaction commit must be accomplished quickly, even at the cost of 	loss of some committed transactions in a disaster.
- 트랜잭션 커밋은 신속하게 이루어져야 하며, 재해 시 일부 커밋된 트랜잭션의 손실이 발생하더라도 그렇게 해야 함
  - One safe가 적합, 백업 사이트에 로그가 도달하기를 기다릴 필요가 없음
(c) A high degree of availability and durability is required, but a longer running time for the transaction commit protocol is acceptable.
-  높은 정도의 가용성과 내구성이 요구되지만 트랜잭션 커밋 프로토콜의 더 긴 실행 시간은 허용
   -  Two Safe가 적합
      -  트랜잭션이 커밋되기 전, 트랜잭션에 의해 변경된 모든 데이터는 주 시스템의 로그에 기록됨
      -  백업 시스템 활성 상태라면, two very safe처럼 동작
      -  백업 시스템 가동 X면, One safe처럼 동작

### 11
- Standard buffer managers assume each block is of the same size and costs the same to read.  Consider a buffer manager that, instead of LRU, uses the rate of reference to objects, that is, how often an object has been accessed in the last n seconds. Suppose we want to store in the buffer objects of varying sizes, and varying read costs (such as Web pages whose read cost depends on the site from which they are fetched).  Suggest how a buffer manager may choose which block to evict from the buffer.  
- 표준 버퍼 관리자가 각 블록이 동일한 크기이고, 읽는 데 동일한 비용이 든다고 가정하는 것과 달리, 객체의 참조 빈도를 사용하는 버퍼 관리자에 대해 고려한다. 버퍼에 다양한 크기의 객체와 읽기 비용이 다른 객체를 저장하려는 경우를 상정, 버퍼 관리자는 버퍼에서 어떤 블록을 제거해야되는가?
  - 우선 순위 큐를 사용
    - 우선 순위(p)는 재읽기 비용을 예상하는 기준에 따라 정해짐
    - 과거 접근 빈도(f)는 객체가 마지막 n초 동안 얼마나 자주 접근되었는지를 나타냄
    - 재읽기 비용(c)는 객체가 다시 읽어야 할 때 드는 비용
    - 크기(s)는 객체의 크기임
    - p = f*c/s
      - f(접근 빈도)가 높으면 우선 순위가 높아져(커져) 버퍼에서 제거되지 않을 가능성이 높아짐
      - 반면 크기(s)가 크거나 재읽기 비용(c)가 높은 경우, 우선 순위가 낮아져(작아져) 먼저 제거될 가능성이 높아짐

### 12
- 트랜잭션 수행 시에 발생하는 로그 레코드는 해당 데이터 페이지가 안전 저장 장치로 flush(write)된 후에 안전 저장 장치로 flush(write)되어야 한다.
  - F, 로그 레코드가 먼저 flush 되어야 함
- 트랜잭션이 commit 하려면 트랜잭션이 생성한 모든 로그 레코드가 stable storage에 flush하여야 함
  - T
- 트랜잭션이 생성하는 log record는 DBMS에서 buffering을 하며, 이에 대한 page replacement policy는 LRU 알고리즘을 사용한다.
  - F, Buffer replacement policy에서는 주로 LRU를 이용
    - page replacement policy에서는 사용하기도, 안하기도..
- No steal 방식의 회복 기법을 지원하는 경우, DBMS가 관리하는 데이터 버퍼 전체 크기는 회복기법 기능과 무관하다.(즉, 전체 데이터 버퍼 용량이 크던 작던 회복기법 기능과는 무관하다)
  - F, No steal 방식에서 데이터페이지 버퍼 크기는 매우 광대해야 함
- Steal 방식의 버퍼 관리 환경에서, 아직 완료되지 않고 수행 중인 트랜잭션이 갱신한 페이지는 필요에 따라 디스크에 flush(write) 될 수 있다.
  - T, 버퍼 공간 관리 방법 중 하나임
- WAL(write-ahead logging)은 데이터 페이지를 메모리 버퍼에서 수정하기 전에 해당 log record를 메모리 버퍼에 먼저 생성해야 하는 것을 의미한다.
  - F, WAL은 데이터 페이지가 *디스크*에 반영되기 전에 해당 log record가 먼저 디스크에 반영되는 것을 의미함
- STEAL/FORCE 정책을 사용하는 회복 알고리즘은 REDO/UNDO 연산을 모두 지원해야 함
  - F, UNDO 연산만 지원하면 됨
- remote backup system에서 One-safe commit 방식에서는 트랜잭션 완료 로그 레코드가 backup site에 항상 반영된다.
  - F, primary site에는 항상 반영, backup site에는 반영되지 않을 수 있음
- Slotted page 구조에서 페이지 내의 레코드 크기 변화로 인해 레코드 위치 이동이 가능하고, 이 경우 레코드 id 값은 변경하지 않는다.
  - T

## 저장 장치
### 물리적 저장 매체
- 분류
  - 데이터 접근 속도, 저장 비용, 신뢰성 등으로 구분
  - 휘발성(Volatile), 비휘발성(Non-volatile)으로 구분 
- 캐시, 메인 메모리
  - 메인 메모리 용량은 기가 바이트 단위, 데이터 접근 속도는 나노초 단위
    - 10s to 100s of nanosecons
- 플래시 메모리
  - 비휘발성 메모리
  - 읽기는 메인메모리 수준과 유사하나, 쓰기/지우기는 마이크로초 단위
  - 쓰기와 지우기 횟수는 제한이 있음
    - 일반적으로 백만번 이하
- NAND 플래시 메모리
  - 비용적인 이유로 NOR보다 NAND 널리 사용
  - 블록 단위로 데이터를 읽음
  - NOR 플래시 메모리는 단어(word) 단위로 읽음
  - 지우기는 밀리초 단위로 이뤄짐
    - 일정횟수 이상 이뤄지면 더 이상 사용 불가(횟수 제한)
    - 자주 지우는 데이터와 자주 지우지 않는 데이터를 구분 및 저장
      - 지움 연산을 골고루 평등하게 분포하고자 함
      - 평등화작업(wear leveling)이라 지칭
  - 플래시 메모리는 기존 하드 디스크를 일부 대치하고자 사용되기도 함
    - 이를 SSD라 지칭
    - 전송 속도는 20MB/s, 기존 HDD(하드디스크)보다 늦음
    - 이를 보완하기 위해 다수의 플래시 디스크를 병렬도 배치
  - 자기 디스크(Magnetic Disk)
    - 온라인으로 장기간 데이터를 저장하는 주된 매체
    - 순차접근이 아닌 직접 접근
  - 광디스크(Optical Disk)
    - ex) CD와 DVD
      - digital versatile disk라고도 지칭
    - 기본적으로 쓰기 한 번 읽기 다수 번 구조
      - 쓰기를 다수 번 지원하는 형태도 있음
    - 광디스크 장치는 읽기 및 쓰기 속도는 자기 디스크보다 낮으나, 대용량 데이터 저장 측면에서는 비용 경쟁력이 있음
    - 헤드는 하드 디스크에 비해 무겁고 이동이 느림
      - seek time이 약 100 millisecond 정도 소요됨
  - 마그네틱 테이프
    - 백업 데이터 저장용으로 널리 사용
    - 속도는 느리고 순차 접근만을 허용
    - 대용량 데이터 저장이 저렴한 비용으로 가능
      - 다만 데이터를 읽고 쓰기 위한 드라이브의 비용은 상당히 높음
  - 저장 장치 계층
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/38f26a30-ec4c-4b77-ba58-c2554651d2b0)
      - primary storage
        - cache, main memory
          - 가장 빠르나, 휘발성
      - secondary storage(on-line storage)
        - flash memory, magnetic disk
          - 비휘발성
      - tertiary storage(off-line storage)
        - optical storage, magnetic tape
          - 비휘발성


### 자기 디스크
- ![image](https://github.com/googoo9918/TIL/assets/102513932/1d6f0a19-e045-4913-ad91-bbb37a91fcb4)
  - 다수개의 디스크 판(platter)이 일정 속도로 회전함
  - 읽기 쓰기 헤드가 이동하여 원하는 트랙 및 섹터에 위치하면, 자기적으로 데이터를 읽고 씀
  - 다수의 동심원(트랙)으로 구성
    - 트랙은 다수 개의 섹터로 구성
  - 동일한 반지름을 갖는 트랙을 상하로 연결한 가상적인 공간을 실린더라고 함
    - 데이터 쓰기는 실린더 기준으로 발생
    - 하나의 실린더에 데이터 쓰기 완료 시, 다음 실린더로 이동하여 쓰기가 계속됨
    - 이는 디스크 암을 이동시키는 탐색시간을 줄이기 위함
      - 연속된 실린더에 데이터를 쓰면 디스크 암의 움직임이 줄어듬
- 디스크 컨트롤러
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/7f4986cd-68a9-449e-98e4-a2f7ad4e15e9)
    - 디스크 하드웨어와 컴퓨터 시스템을 연결하는 인터페이스를 제공
      - 데이터 읽기/쓰기 명령을 수행
      - 디스크 하드웨어를 제어
      - 체크섬을 이용해 데이터 검증
      - 손실된 섹터 재배치 등의 기능 수행
- 디스크 연결
  - 컴퓨터 시스템에 직접 연결(DAS, directed attached storage)하거나 고속 네트워크에 연결할 수 있음
  - 네트워크 연결 방식
    - SAN(Storage Area Networks)
      - 다수의 디스크가 네트워크를 통해 다수 서버에 연결
      - 다수 사용자에 의해 공유 가능
      - 서버와 디스크 간 SCSI, SAS, Fiber channel 인터페이스 등 사용
    - NAS(Network Attached Storage)
      - NFS(Network File System), CIFS(Common Internet File System)과 같은 원격 화일 시스템 인터페이스 제공
      - 서버는 디스크를 접근할 때 원격화일 시스템 규약을 사용하여 접근
- SAN(Storage Area Networks)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/044175c7-a547-4e8f-be72-5151dd78afd0)
    - 서버 뒤에 존재하는 네트워크
      - 사용자들이 인지하는 서버 두에 숨어있는 저장장치 연결을 위한 네트워크
      - 사용자 커퓨터가 연결되어 있는 LAN, 그 뒤에 저장 장치를 연결하는 SAN 존재
    - 특수화된 고속 네트워크
    - 원격 저장 장치를 서버에 연결하는 아키텍처
    - 여러 컴퓨팅 서버에 의해 공유될 수 있음
    - 네트워크를 통해 어떤 요소와도 연결될 수 있음
    - 파일 수준의 추상화를 제공하지 않음
      - 오직 블록 수준의 연산만을 지원
- NAS(Network Attached Storage)
  - NAS는 컴퓨터 서버에 직접 저장 장치를 연결하는 DAS(direct attached storage)와 대비되는 저장 장치
  - NAS는 자체 CPU, 메모리를 가지며, NAS 기능을 제공하는 최적화된 운영체제를 운영
  - 화일 중심의 규약(NFS)등을 지원
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/50f7c043-70f1-4335-b5b1-d9adeac2163a)
    - LAN이 packet 단위의 데이터 전송, SAN은 block 단위의 데이터 전송을 함
- 디스크 성능 평가
  - 접근시간은 탐색시간(Seek time)과 회전지연시간(rotational latency)로 구분
  - 평균 접근시간은 15-20 밀리초
    - 탐색시간 4 ~ 10, 회전지연시간 4 ~ 11
  - 메인메모리 접근시간보다 대략적으로 백만 배 늦음
  - 메인메모리에서 연산 성능 개선보다, 연산에 요구되는 디스크 접근 횟수를 줄이는 것이 시스템 성능에 더욱 효과적임
  - 데이터 전송 속도는 일반적으로 십만 ~ 백만 MB 사이
    - MB(megabytes), Mb(megabits)
  - 평균 고장 시간(MTTF, Mean time to failure)은 장애 없이 디스크를 지속적으로 사용할 수 있는 평균시간
    - 시간 흐름에 따라 급속히 감소, 자기 디스크의 평균 사용 연한은 3~5년으로 알려져 있음
  - 성능 향상
    - 자기 디스크는 접근 속도가 늦으므로, 이를 극복하기 위해 자체적으로 다양한 기법을 지원함
    - 블록 단위 데이터 접근
    - 디스크 암 스케줄에 엘리베이터 알고리즘 적용
      - 디스크 암 움직임 최소화
    - 데이터 집약화(clustering)
      - 논리적으로 가까운 데이터를 물리적으로 근접한 위치에 저장하는 방식
    - 비활성 RAM에 쓰기 연산을 우선, 쓰기 연산에 따른 기다림을 없애는 방식
      - NVRAM(non-volatile RAM)을 활용하는 RAID

### RAID
- Redundant Arrays of Independent Disks
  - 다수개의 디스크를 큰 용량의 단일 디스크처럼 보이게 하는 디스크 구축/관리 기술
  - 대용량, 빠른 접근시간, 고신뢰성 제공
    - 데이터 중복에 의한 신뢰성 향상, 다수 디스크 병렬 처리에 의한 고성능을 제공
- 중복에 의한 신뢰성 향상
  - 100개의 disk, 각각 MTTF가 100,000이라 할 때
    - 디스크 한 개의 MTTF는 100,000/100 = 1,000(42일)임
    - 이는 그리 긴 시간은 아님
    - 만약 데이터에 대해 하나의 복사본만 존재하면, 디스크 실패로 인한 데이터 손실 가능성이 높음
    - 따라서 중복을 사용하여 데이터 손실 가능성을 줄여야 함
  - 디스크 거울화(mirroring)
    - 모든 디스크를 복사, 하나의 logical disk는 두 개의 physical disk로 나눠짐
    - write는 두 디스크 모두에 적용되어야 하고, 읽는건 어디서 읽든 상관 없음
    - 두 디스크 모두에서 fail(시스템 repair 되기 전)해야 data loss가 발생함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/6fadf2b0-4ef3-43f6-b323-abdabb200fd7)
    - MTTDL(Mean Time to Data Loss)는 디스크의 Mean Time to Failure(MTTF)와 Mean Time to Repair(MTTR)에 의존함
    - MMTF가 100,000 MTTR이 10시간인 경우
      - MTTDL = MTTF^2 / 2*MTTR
      - 즉, MTTDL = 100,000^2 / 2 * 10 = 500,000,000 시간(57000년) 
      - 독립 고장 모델을 기반으로 했을 때임
- 병렬에 의한 성능 향상
  - 다수개의 디스크에 데이터를 분산, 데이터 전송 속도를 향상 시킬 수 있음
    - 비트 단위 스트라이핑은 사용되지 않음, 블록 단위 스트라이핑(striping)은 널리 사용됨
      - 데이터를 블록 단위로 나누고, 각 블록은 RAID에 포함된 다른 디스크로 순차적으로 저장됨
      - 여러 디스크에 동시에 읽기/쓰기 작업 수행 -> 입출력 성능 향상
- RAID 수준 0
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/de8abf0a-e7c3-438a-84a5-6302e0f684a0)
    - 중복성 없이 블록단위 스트라이핑만을 지원
- RAID 수준 1
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/65b71199-4b0a-4467-93bb-197a91f11c05)
  - 거울화 디스크에 블록단위 스트라이핑을 지원
    - 당연히 거울화 디스크와 같이 에러가 생기면, data loss가 발생함
  - 미러링과 스트라이핑을 RAID Level 1+0 또는 RAID Level 10으로 표기하기도 함
  - 스트라이핑이 없는 미러링을 RAID Level 1으로 표기하기도 함
- RAID 수준 5
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/26aca888-ab2d-4704-904b-8e96c0317e2c)
    - 패리티(오류 검출 및 수정 정보)를 전체 디스크에 분산
    - N+1 디스크에 데이터와 패리티를 저장함
      - 디스크 중 하나는 패리티를 저장, 다른 N개의 디스크는 블록을 저장
    - 동일 디스크에 데이터 블록과 블록을 위한 패리티를 함께 저장할 수 없음
      - 모두 손실되면 복구 불가
    - 두 개 이상의 드라이브가 동시에 실패할 경우 데이터를 잃을 수 있음
      - 패리티 정보는 오직 한 개의 드라이브의 데이터만 복구할 수 있기 때문
- RAID 수준 6
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/923bbdca-2ce7-4d8f-9bce-12385f92e1b5)
    - 패리티를 사용하지 않고, 대신 Reed-Solomon 코드와 같은 에러 정정 코드를 사용함
    - 2개 이상의 디스크 오류시에도 데이터 복구가 가능함
- RAID 수준 결정
  - 수준 0, 1, 5, 6을 주로 사용
  - RAID 레벨 1이나 5는 단일 디스크 실패에 대비하여 설계됨
    - latent sector 실패 발견 시 이를 복구하기 위해 거울화 디스크나 패리티 정보를 사용
    - 이 기간동안 시스템은 취약해지며, 거울화 디스크나 다른 디스크에 에러가 생기면 data loss가 발생할 수 있음
  - 수준 1은 디스크 거울화로 인해 데이터 저장 공간이 절반으로 축소되는 단점 존재
  - 수준 5는 패리티 저장으로 인한 저장 공간 축소가 미비
    - 다만, 데이터 갱신 시 2번 읽기 및 2번 쓰기(패리티 디스크)를 하므로 수준 0에 비해 접근시간이 더 소요됨
  - 수준 0은 데이터 보호가 필요 없는 환경에서, 수준 5는 데이터 갱신이 적으며 대용량 데이터 저장이 요구되는 환경에서, 그 외에는 수준1이 주로 사용됨
- 소프트웨어/하드웨어 RAID
  - RAID 기능은 소프트웨어 또는 하드웨어로 구현 가능
  - 소프트웨어적 제공
    - 하드웨어 장치 불필요, 운영체제 수준에서 지원
    - 비용 측면에서는 유리
      - 운영체제 성능에서는 불리, 모든 RAID 레벨을 지원하지 않음, SW 업그레이드에 대한 호환성 문제
  - 하드웨어적 제공
    - 특별 하드웨어 필요
      - 컴퓨터 확장 보드 장착 + 디스크가 확장보드에 연결하거나
      - 외부 디스크에 구현
- 하드웨어 이슈
  - 하드 디스크에 대한 몇 가지 이슈
    - Latent failure
      - 디스크 드라이브 내 숨겨진 결함
      - RAID 배열에서 한 드라이브가 실패하고 복구 과정이 진행될 때 잠재적인 문제가 되어 추가적인 데이터 손실을 일으킬 수 있음
    - Data scrubbing
      - 백그라운드에서 주기적으로 드라이브를 검사하여 데이터 무결성 확인
    - Hot swapping
      - 고장난 하드디스크를 시스템 중단 없이 교체할 수 있는 기능
      - RAID 시스템 내에 다수개의 예비 디스크를 구비하게 하고, 운영 중인 디스크에 장애 발생 시 즉시 예비 디스크를 사용하는 기술

## 4장 연습문제
### 1
- ![image](https://github.com/googoo9918/TIL/assets/102513932/c3dad88f-1a0f-4632-9cec-8e1c9900c9ba)
  - 실린더 -> 트랙 -> 섹터 -> 레코드 순서로 저장됨
  - 각 섹터에는 512/128 = 4, 4개의 레코드가 저장될 수 있음
  - 현재 20,000개 레코드이기 때문에, 총 5,000 섹터가 저장되어야 함
    - 5,000 섹터는 125 track에 저장됨
    - 125 track은 11.36 cylinders, 즉 12개의 cylinders에 저장되어야 함

### 2
- ![image](https://github.com/googoo9918/TIL/assets/102513932/65dc2e48-fab8-4cbd-b4cf-560bd03ad5d2)
  - 현재 P1은, B1~B4의 패리티를 저장함
    - 여기서 문제점은, P1과 B_4i-3이 같은 디스크에 위치한다는 것임
    - 오류가 발생했을 때, B1 데이터 블록과 P1을 모두 잃게 되고, B1 데이터 블록을 복구할 수 없게 만듬

### 3
- 4.3 A power failure that occurs while a disk block is being written could result in the block being only partially written. Assume that partially written blocks can be detected. An atomic block write is one where either the disk block is fully written or nothing is written (i.e., there are no partial writes). Suggest schemes for getting the effect of atomic block writes with the following RAID schemes. Your schemes should involve work on recovery from failure. 
- 전력 장애로 인해 디스크 블록이 부분적으로만 쓰여지는 상황에서, 부분적 쓰기를 감지할 수 있을 때 RAID 레벨1과 RAID 레벨5에서 어떻게 되는가?
	a. RAID level 1 (mirroring)
  - 원자성을 확보하기 위해, 첫 번째 물리적 블록에 정보를 쓰고 첫 번째 쓰기가 성공적으로 완료되면 동일한 정보를 두 번째 물리적 블록에 씀
    - 두 번째 쓰기가 성공적으로 완료되면 쓰기 작업을 완료한 것으로 선언
  - 복구 중에는 각각의 물리적 블록 쌍을 검사
    - 한 블록이 부분적으로 쓰여졌다면, 다른 블록의 내용으로 교체
    - 복구 중 모든 상응하는 블록 쌍을 비교할 수는 없기에, 비 휘발성 RAM을 사용하여 진행 중인 블록 쓰기를 추적함
      - 복구 시에는 진행 중이던 쓰기 작업이 있는 블록만 비교
	b. RAID level 5 (block interleaved, distributed parity)
  - 정보 블록을 먼저 쓰고 패리티 블록을 씀
  - 복구 시
    - 특정 블록이 부분적으로 쓰여졌으면, 그 내용을 다른 블록을 사용하여 재구성
    - 부분적으로 쓰여진 블록이 없지만 패리티 블록의 내용과 정보 블록의 내용이 일치하지 않는 경우, 패리티 블록의 내용을 재구성

### 4
- RAID systems typically allow you to replace failed disks without stopping access to the system. Thus, the data in the failed disk must be rebuilt and written to the replacement disk while the system is in operation. Which of the RAID levels yields the least amount of interference between the rebuild and ongoing disk accesses? Explain your answer
  - RAID 시스템에서 하드 디스크가 실패했을 때, 시스템을 중단하지 않고도 해당 디스크를 교체할 수 있는 기능(Hot swapping)을 하고자 할 때, 디스크 액세스와의 간섭이 가장 적은 RAID 레벨은?
    - RAID 레벨 1이 간섭을 최소화함
      - RAID 1에서 재구축은 단지 실패한 디스크의 복사본에서 데이터를 복사하면 되기 때문
      - 이 과정이 다른 디스크의 정상적인 작업에 미치는 영향이 가장 적음
        - 다른 RAID 레벨에서는 재구축 과정이 모두 다른 디스크의 전체 내용을 읽어야 하는 작업을 포함함
        - 예를 들어, RAID 5에서는 하나의 디스크 실패 시, 나머지 디스크에서 데이터와 패리티 정보를 모두 읽어서 손실된 데이터를 재구축 해야함
        - 이 과정은 더 많은 디스크 읽기 작업을 필요로 하고, 더 많은 간섭을 초래함

### 5
- Explain RAID 1 and RAID 5 in brief. Is the following statement true? “For applications that has low data update and requires large amount of space to store databases, RAID 5 is better than RAID 1”
- 데이터 업데이트가 적고 데이터베이스를 저장하기 위해 많은 양의 공간이 필요한 응용 프로그램의 경우, RAID 5가 RAID 1보다 낫다
  - 맞음, RAID 5는 하나의 디스크만을 추가적으로 사용하지만 RAID 1은 같은 수만큼의 디스크를 필요로 하기 때문에 RAID 1보다 더 많은 사용 가능한 저장 공간을 제공함
  - 또한, 데이터 업데이트가 적다면 RAID 5의 쓰기 성능 저하 문제는 크게 중요하지 않게 됨
    - 추가적으로, RAID 1과 RAID 5 모두 쓰기 작업이 2번 일어나지만 RAID 5의 쓰기 성능이 더 낮음
      - RAID 1은 두 디스크의 동일하게 쓰여지기 때문에, 오버헤드가 적음
      - 반면 RAID5의 쓰기 작업은 기존의 데이터와 패리티 블록을 먼저 읽고 계산한 후 써야 하기 때문에 오버헤드가 높음

### 6
- If you have data that should not be lost on disk failure, and the data are write intensive, how would you store the data?
- 디스크 장애 발생 시 데이터 손실이 없어야 하며, 데이터 쓰기 작업이 많은 환경에 대해 데이터를 어떻게 저장할 것인가?
  - 비활성 RAM에 쓰기 연산을 우선, 쓰기 연산에 따른 기다림을 없애는 방식
      - NVRAM(non-volatile RAM)을 활용하는 RAID를 사용

### 7
- In earlier generation disks the number of sectors per track was the same across all tracks. Current generation disks have more sectors per track on outer tracks, and fewer sectors per track on inner tracks (since they are shorter in length). What is the effect of such a change on each of the three main indicators of disk speed?
- 이전 세대의 디스크 드라이버들은 모든 트랙에서 섹터의 수가 동일했지만, 현재 세대의 디스크들은 외부 트랙에 더 많은 섹터를, 내부 트랙에는 더 적은 섹터를 갖고 있음. 이러한 변화가 디스크 속도의 세 가지 주요 지표에 어떤 영향을 미치는가?
  - 안쪽 트랙에 더 적은 섹터가 있는 이유는, 데이터 전송률이 바깥쪽 트랙이 안쪽보다 더 높기 때문임
    - 디스크는 일정한 속도로 회전하고, 외부 트랙에 있는 동안 더 많은 섹터가 읽힐 수 있음
      - 즉, 외부 트랙의 데이터 전송률이 더 높음

### 8
- 4.8 저장 장치를 구성하는 방법 DAS, NAS, SAN을 비교 설명하시오.   각 방법에서 사용하는 대표적인 규약을 2개 이상 명시하시오.  
  - DAS : direct attached storage (컴퓨터에 저장장치를 직접 연결)
	- NAS : network attached storage
		. 저장장치를 컴퓨터 네크워크에 단독 실체로 연결하
		. file-based protocol(예를 들면, NFS, SMB/CIFS, AFP Apple filing protocol 등)를 사용하여 데이터 전송을 한다.  
	- SAN : Storage Area Networks
		. 데이터 전송을 위한 독립적인 네트워크를 구성하여 저장장치를 연결하고
		. 블록 전송 프르토콜(예를 들면, SCSI, ATA, Fiber channel 등)을 사용하여 데이터를 전송한다. 
