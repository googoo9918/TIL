## 목차
- [인공지능](#인공지능)
  - [Introduction to Artificial Intelligence](#introduction-to-artificial-intelligence)
    - [What is Intelligence?](#what-is-intelligence)
    - [Examples](#examples)
  - [Unimformed Search Methods](#unimformed-search-methods)
    - [Search Problems](#search-problems)
    - [State Space Graphs \& Search Trees](#state-space-graphs--search-trees)
    - [Search Strategies](#search-strategies)
    - [Depth-First Search](#depth-first-search)
    - [Depth-Limited Search](#depth-limited-search)
    - [Iterative Deepening Depth-First Search(IDS)](#iterative-deepening-depth-first-searchids)
    - [Breadth-First Search(BFS)](#breadth-first-searchbfs)
    - [DFS vs BFS](#dfs-vs-bfs)
    - [Uniform Cost Search](#uniform-cost-search)
  - [Informed Search Methods](#informed-search-methods)
    - [Heuristics](#heuristics)
    - [Greedy Search(Best-Frist Search)](#greedy-searchbest-frist-search)
    - [A\* search(UCS + Greedy)](#a-searchucs--greedy)
    - [Problems](#problems)
  - [Graph Search](#graph-search)
    - [Optimality](#optimality)
    - [Example](#example)
  - [Game Search](#game-search)
    - [Game Tree Pruning](#game-tree-pruning)
    - [Example](#example-1)
  - [Search under Uncertainty](#search-under-uncertainty)
    - [Monte Carlo Tree Search(MCTS)](#monte-carlo-tree-searchmcts)
    - [Example](#example-2)
  - [Optimization Methods](#optimization-methods)
    - [Finding Best Parameters](#finding-best-parameters)
    - [Local Search Method](#local-search-method)
    - [Hill-climbing Search](#hill-climbing-search)
    - [Optimization](#optimization)
    - [Gradient Descent Method](#gradient-descent-method)
    - [Example](#example-3)
  - [Non-Derivative Unconstrained Optimizations](#non-derivative-unconstrained-optimizations)
    - [Downhill Simplex Method](#downhill-simplex-method)
    - [Grnetic Algorithm](#grnetic-algorithm)
    - [Example](#example-4)
  - [Deep Neural Network](#deep-neural-network)
    - [Neural Networks(NN)](#neural-networksnn)
    - [Neural Networks for Machine Learning](#neural-networks-for-machine-learning)
  - [Backpropagation](#backpropagation)
    - [Training Nerual Networks](#training-nerual-networks)
    - [Backpropagation Algorithm](#backpropagation-algorithm)
    - [Examples](#examples-1)
    - [Gradient Vanishing Problem](#gradient-vanishing-problem)
  - [Specialized Architectures](#specialized-architectures)
    - [Convolutional Neural Networks](#convolutional-neural-networks)
  - [Training the Neural Networks](#training-the-neural-networks)
    - [Setting hyperparameters](#setting-hyperparameters)
    - [Model selection](#model-selection)
    - [Activation function](#activation-function)
    - [Weight initialization](#weight-initialization)
    - [Hyperparameter search](#hyperparameter-search)
  - [Generalization](#generalization)
    - [Data Augmentation](#data-augmentation)
# 인공지능
## Introduction to Artificial Intelligence
### What is Intelligence?
- 유동 지능(Fluid Intelligence)
  - 새롭고 추상적인 문제를 해결하는 능력
    - 동작성 지능
    - 빠진 곳 찾기, 모양 맞추기, 차례 맞추기 등
    - 추론, 작업 기억, 주의 조절, 억제 조절
    - 학습 지식이나 경험을 통해 얻은 지식에 의존하지 않음
- 결정 지능(Crystallized Intelligence)
  - 세상의 법칙이나 그 법칙을 알아내기 위해 필요한 절차에 관한 정보
    - 언어적 지능
    - 상식, 어휘, 이해, 공통성 등과 관련
    - 학습에 의해 축적됨
- 결국 AI란, 지능적 행위를 자동화시키려는 행위임
- Rational Decisions
  - 합리적이라는 것은, 사전에 정의된 목표를 최대한 달성하는 것
  - Utility, 내가 모델링 할 목적 함수에 따라 결정됨
    - 즉, 합리적이라는 것은 Utility를 극대화 하는 행동임(내 목표에 맞춰 최적화!)
- Turing Test
  - 사람처럼 행동하는지? 에 대한 테스트
  - Rational과는 무관하다
- Strong/Weak AI
  - Strong AI
    - 인간을 완벽하게 모방한 인공지능
  - Weak AI
    - 유용한 도구로써 설계된 인공지능
      - 사람의 지능적 행동을 흉내 내는 수준
      - Turing Test
- Symbolic/Subsymbolic AI
  - Symbolic AI
    - 인간의 사고 과정을 모방하는데 중점
    - 명확한 규칙과 심볼을 통해 문제 해결
    - ex) 알고리즘 
  - Subsymbolic AI
    - 데이터에서 패턴 학습하여 결정 내리는 기계학습과 신경망에 의존
    - ex) 딥러닝
### Examples
- Coneceptual and algorithm O/X questions
  - is Turing test acting rationally?
  - Strong AI? Symbolic AI?

## Unimformed Search Methods
### Search Problems
- search problem consists of
  - state space
  - successor function(with actions, costs)
  - start state and a goal test
- Problem
  - Initial state
  - Possible actions
  - Goal test
  - Path cost
- Search Problems(Traveling in Romania)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/c2dbfdfe-fea4-4a04-b265-e5e8e1a907a3)
  - State space
    - cities
  - Successor funtion
    - Roads: go to adjacent city with cost(==distance)
  - Start state
    - Arad
  - Goal test
    - Is_state == Bucharest?
### State Space Graphs & Search Trees
- State Space Graphs
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/996e4947-a3c8-49cf-8064-2b51ac7f43c9)
  - 모든 state를 다 node로 표현함
  - 각각의 state는 중복 없이 하나씩만 존재함
- Search Trees
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/5c2c148c-7e53-49bf-aab0-af2744b38c71)
  - 각 노드는 상태 공간 그래프에서 하나의 전체 경로임
- State Space Graphs vs Search Trees
  - 상태 공간 그래프의 노드는 problem state임
    - 추상적 상태를 지님, 후속 상태를 가지며 목표 상태가 아닐 수 있고 선행 상태를 가질 수 있음
  - 검색 트리의 노드는 plans임
    - 일련의 행동(계획)을 나타냄
    - 한 개의 부모, 경로 길이, 깊이 및 비용을 가짐
    - 당연히 같은 state가 반복될 수도 잇음
    - state graph에 사이클이 있는 경우, search tree는 무한히 확장될 수도 있음
    - *fringe*는, 현재 진행할 수 있는 노드를 의미함
- Searches in state space graph
### Search Strategies
  - Completeness
    - 유한한 시간 내에 답을 찾을 수 있는가?
  - Optimality
    - 항상 최소 비용의 해결책을 찾는가?
      - 최적 알고리즘에 의해 찾아진 첫 번째 해결책은 최소 비용의 해결책일 것임
  - Time complexity
  - Space complexity 
  - b, d, m
    - b
      - 이웃 노드의 최대 수
    - d
      - 최적의 솔루션 depth
    - m
      - Maximum depth
### Depth-First Search
- Properites
  - Complete?
    - No, depth가 무한하거나, 루프가 있는 공간에서는 실패
    - 유한 공간에서는 complete함
  - Optimal?
    - 깊이 우선 탐색이기에, 최적이 아닌 목표를 먼저 찾게될 수 있음
  - Time?
    - O(b^m)
    - m이 d보다 큰 경우 매우 나빠짐
  - Space?
    - O(b^m)

### Depth-Limited Search
- Stack 사용
- 깊이 제한 l이 있는 깊이 우선 탐색임
  - 깊이 l에서의 노드는 후속 노드가 없는 것처럼 취급합
- Complete?
  - `l<d`인 경우, 완전하지 않음
- Optimal?
  - `l>d`라고 하더라도, 최적이지 않음
- Time?
  - O(b^l)
- Space?
  - O(b^l)
- Example
  - is depth-limited search optimal?

### Iterative Deepening Depth-First Search(IDS)
- limit, l을 한 개씩 늘리면서 진행함
  - 생각보다 오버헤드가 크지 않음
- Complete?
  - b가 무한하지 않은 경우를 제외하면 완전함
- Optimal?
  - 각 단계를 진행함으로써 발생하는 비용이 0보다 클 때(즉, 무료로 이동할 수 있는 경로가 없는 경우) Optimal함
- Time?
  - O(b^d)
- Space?
  - O(bd)

### Breadth-First Search(BFS)
- Queue 사용
- Comlete?
  - b가 유한하다면, 그렇다
- Optimal?
  - 가장 얕은 목표 노드가 최적일 경우만 Optimal하다
    - 노드의 깊이에 따라 비용이 증가하지 않는 경우
    - ex) 모든 단계의 비용이 1인경우
- Time?
  - 1 + b + b^2 + … + b^(d-1) + b^d = O(b^(d+1)) 
- Space?
  - O(b^d)

### DFS vs BFS
- When will BFS outperform DFS?
  - 최단 경로를 찾아야 할 때
    - 시작 노드로부터 가장 가까운 노드로부터 차례대로 탐색, 최단 경로 또는 최소 단계 요구 문제에 적합함
  - 균일 비용 탐색이 필요할 때
    - 모든 이동의 비용이 같고, 가장 낮은 비용의 해결책을 찾아야 하는 경우
- When will DFS outperform BFS?
  - 해결책의 깊이가 깊을 것으로 예상되는 경우
  - 답을 찾는 것이 중요하고, 답이 최단 경로일 필요가 없는 경우
  - 특정 조건을 만족하는 모든 해결책을 찾아야 하는 경우
- Properties of search methods
  - DFS vs BFS?
  - Complete?
    - what is the major problem?

### Uniform Cost Search
- 최소 비용 노드를 먼저 확장하는 탐색 전략
  - 우선순위 큐를 가장자리(fringe)로 사용
  - 기본적으로 BFS를 따름, 만약 모든 단계의 비용이 같다면 BFS와 동일하게 작동함
- Complete?
  - 모든 비용이 양수이고, 해결책의 총 비용이 유한하다면 그렇다
- Optimal?
  - UCS는 비용이 점점 증가하는 순서대로 상태를 탐색하기에, 최소 비용이 보장됨
- UCS는 경로 비용에 의한 탐색이기 때문에, 이동 단계 기반 깊이를 생각할 수는 있으나, 총 비용이 더 중요한 역할을 함
- 단점
  - 모든 방향으로 옵션을 탐색하기에, 목표 위치에 대한 정보가 없는 경우 비효율적일 수 있음
- Uniformed Search [heurastic search Methods]
  - Depth/ Breadth first search
  - Depth-limited search and IDS
  - UCS
- ![image](https://github.com/googoo9918/TIL/assets/102513932/e70461e3-d31a-4047-8c9e-9bf6a0506b65)

## Informed Search Methods
### Heuristics
- 목표에 얼마나 가까운지 추정하는 함수
- 특정 검색 문제를 위해 설계됨
- 예를 들어, 8 Puzzle에서 Heuristic이 잘못 배치된 타일의 갯수라 했을 때, admissible한가?
  - 너무 낙관적인 케이스(실제 비용은 훨씬 크다)
- 실제 비용 휴리스틱으로 사용하는 것은 어떠한가?
  - 가능성은 있지만, 최적의 해결책을 찾는데 도움이 되진 않음
  - 실제 비용을 정확히 안다면, 탐색할 필요가 없기 때문
  - 휴리스틱이 실제 비용에 가까워질 수록 더 적은 노드를 확장하지만, 휴리스틱 자체 계산을 위한 작업량이 많아짐
- 8 퍼즐 분석 및 각 탐색 방법의 장단점
  - DFS
    - DFS는 메모리 효율이 좋고, 깊이가 무한인 경우를 제외하고 간단한 해결책을 찾을 때 유용함
    - 그러나 최적의 해를 보장하진 않음
  - BFS
    - 최단 경로를 보장하지만, 메모리 사용량이 매우 큼
  - UCS
    - BFS가 각 이동의 비용을 고려하지 않는 반면, UCS는 이동 비용을 고려하여 탐색함
    - 최적 경로 보장
    - 다만, 메모리 사용량이 크고 탐색 속도가 느릴 수 있으며, 휴리스틱이 없음
      - 특정 방향이 더 유리한지에 대한 사전 정보가 없음
  - 그리디 탐색(best-first)
    - 가장 가까운 것으로 보이는(휴리스틱이 제일 낮은) 노드를 우선적으로 확장함
    - 빠르게 해를 찾을 수 있지만, 최적의 해를 보장하진 않음
  - A*
    - UCS와 그리티 탐색의 장점 결합
    - 최적의 해를 찾을 수 있으며, 휴리스틱 함수를 사용하여 탐색 효율성을 높임
    - 메모리 사용이 큼
      - MBA(Memory Bounded A*)로 해결 가능
- 휴리스틱의 효과성
  - 잘못 배치된 타일 수
    - 간단하고 계싼하기 쉽지만, 최적 경로의 비용을 과소평가할 수 있음
  - 이동해야 할 타일의 수(맨해튼 거리)
    - 각 타일을 올바른 위치로 옮기는 데 필요한 최소 이동 횟수 추정, 보다 정확한 휴리스틱 제공
      - 보다 효과적
- 최단 경로 문제와의 차이
  - 트리 탐색은 각 상태를 한 번만 방문하는 것을 가정함
  - 그래프 탐색은 루프나 반복 상태가 가능함
  - 8퍼즐과 같은 문제는 그래프 탐색을 통해 중복 상태를 피하는 것이 좋음 
### Greedy Search(Best-Frist Search)
- 목표 상태에 가장 가까운 것 같은 노드를 확장
  - 휴리스틱을 통해 가장 목표에 가깝다고 생각되는 노드를 선택하여 확장
- 단, 항상 최적의 해를 보장하진 않음
  - 휴리스틱의 추정이 완벽하지 않을 수 있음
  - 잘못 설계된 DFS처럼 작동할 수 있음
- ![image](https://github.com/googoo9918/TIL/assets/102513932/74e58e6d-e39b-4df4-bbce-6a01b141242c)
  - 직접 그려볼 수 있어야 함
  - UCS는 비용을 기준으로, Greedy는 휴리스틱을 기준으로 진행됨을 명심하라
### A* search(UCS + Greedy)
- UCS와 Greedy를 합쳐서 진행!
- ![image](https://github.com/googoo9918/TIL/assets/102513932/e505e5a6-4157-4817-a17d-e888c7a0987a)
  - 다만, Uniform-cost는 경로비용 g(n)에 의해 순서가 정해짐
  - Greedy는 휴리스틱 h(n)에 의해 순서가 정해짐
  - A* 검색은 합계에 의해 순서가 정해짐
    - 너무 비관적이면 안됨(추정치가 실제 비용보다 작아야 함)
- Admissibility
  - 비관적(Inadmissible) 휴리스틱은 최적성을 깨트림
    - 실제 비용보다 높게 추정되는 휴리스틱은 좋지 않음
    - 비관적 휴리스틱도 특정 상황에서 탐색 속도를 높이는 데 도움이 될 수 있음
  - 낙관적(Admissible) 휴리스틱은 실제 비용을 결코 초과하지 않음
    - 너무 낙관적이면 탐색 과정을 불필요하게 길어지게 만들 수는 있음
      - 너무 낙관적이면, 0값이 돼버리고 UCS와 똑같아 지겠지
- 휴리스틱 h는 가장 가까운 목표까지의 실제 비용인 경우, 낙관적으로 간주됨
  - 즉, 모든 노드 n에 대해 h(n)이 실제 최소 비용보다 작거나 같아야 함(비용을 과대평가 하지 않아야 함)
- Properties of A*
  - Complete?
    - f(n) <= f(G)인 무한히 많은 노드가 있는 경우를 제외하고, 그렇다
      - f(n)은 노드 n에서의 경로 비용의 추정치
      - f(G)는 목표 노드 G에서의 추정치임
      - 즉, 탐색 공간이 무한대로 확장될 수 있으면 완전하지 않다는 것임
  - Optimal?
    - 만약 f가 가능성(admissible)하면 그렇다
      - 실제 비용을 과대평가 하지 않는 경우
      - f(n)은 n에서 목표까지 가는 데 필요한 실제 최소 비용보다 작거나 같아야 함
  - Time?
    - O(b^d)
  - space?
    - 모든 생성된 노드를 메모리에 유지함
    - A*에 주요 단점
- Simple Memory Bounded A*Search
  - 메모리가 가득 차면, 가장 큰 f(n) 값을 가진 노드를 삭제함
  - 물론 루트에서 목표까지의 단일 경로가 메모리에 맞지 않으면 해결책을 나올 수 없음
  - 여태 본 탐색 알고리즘 중 최선임
- UCS vs A*
  - UCS는 모든 방향으로 균등하게 확장함
    - 등심원
  - A*은 주로 목표를 향해 확장하지만, 최적성 보장을 위해 배팅을 분산시킴
    - 타원
### Problems
- Optimistic(낙관적) vs Pessimistic(비관적) Heuristics
- 
- Infromed Search
  - Greedy & A* search
  - 정의, 차이점

## Graph Search
- 중복 상태를 감지하지 못하면, 더 많은 작업을 초래할 수 있음
  - state graph는 cycle이 있을 수 있고, search tree는 반복된 state가 나올 수 있음
  - 이 경우, DFS는 complete하지 않게 되고, BFS는 작업량이 너무 많아지게 됨
- 닫힌 집합을 사용해야함
  - 트리 탐색에 set을 사용, 중복 상태 확장을 방지
  - 결국 이게 그래프 탐색인거임!
- 그래프 탐색
  - 상태를 두 번 확장하지 않음
  - 트리 탐색과 함께 closed set 사용
  - 완전성
    - 완전성을 유지함
  - 최적성
    - 사용된 탐색 전략과 휴리스틱이 최적성을 보장하는 경우, 최적의 해결책을 찾을 수 있음
    - A*등을 이용하는 경우 
- ![image](https://github.com/googoo9918/TIL/assets/102513932/c5e5bcda-50a9-444a-8efe-76352f91c855)
  - Admissibility, 즉 가능성은 휴리스틱 비용이 실제 목표까지의 비용보다 작거나 같을 때 가능성이 있다고 얘기함
    - 여태까지 이것만 따졌음
  - Consistency, 즉 일관성을 따져야 Optimal을 보장할 수 있음
    - A에서 C로 가는 실제 비용에 대해 휴리스틱이 일관적이라는 것은
    - A의 휴리스틱 비용에서 C의 휴리스틱 비용을 뺀 값이 A에서 C로 가는 실제 비용보다 작거나 같다는 것을 의미함
      - 따라서 그림에서 휴리스틱 비용은 4가 아닌 2가 되어야 Optimality를 보장할 수 있음

### Optimality
- 트리 탐색
  - A*은 휴리스틱이 admissible 할 때 최적임
  - UCS는 휴리스틱이 0인 특별한 경우임
- 그래프 탐색
  - A*은 휴리스틱이 consistnet할 때 최적임
  - UCS는 최적임(h=0은 일관성 있음)
  - 그래프 탐색은 중복 상태를 방지하는 추가 매커니즘이 있기에, 일관성 있는 휴리스틱은 삼각 부등식을 통해 휴리스틱 값이 점차 증가하도록 보장함
- 일반적으로 대부분의 자연스러운 admissible한 휴리스틱은 consistent한 경우가 많음, 특히 relaxed problems에서 유도된 경우 그러함

### Example
- Graph Search
  - Tree vs Graph Search
  - 트리 탐색
    - 탐색 과정에서 생성되는 모든 노드를 트리 구조로 확장
    - 같은 상태가 여러 번 나타날 수 있음
  - 그래프 탐색
    - 중복 상태를 방지하기 위해 이미 방문한 상태를 기록
    - 이를 다시 확장하지 않음(closed set)
  - 정의, 차이점
- Tree vs Graph Search
  - w.r.t optimally


## Game Search
- Types of Games
  - agent가 둘 이상인 경우를 게임이라 함
  - Deterministic(결정론적) vs Stockhastic(확률론적)
    - 상태 변화가 미리 결정되어 있는지(체스), 우연의 요소가 포함되어 있는지(주사위)
  - 제로섬
    - 한 플레이어의 이득이 반드시 다른 플레이어의 손실을 의미하는지
    - 한 플레이어가 이기면 다른 플레이어는 반드시 짐
- Games vs Search Problems
  - Adversarial search(적대적 탐색)
    - 에이전트의 목표가 충돌하는 경쟁 환경을 다룸
      - 몇 수 앞을 볼 수 있어야 함
    - 시간제한이 존재, 목표를 찾는 것이 불가능 할 수 있음 --> approximate(근사치)를 찾아야 함
    - 상대방이 예측할 수 없는 경우(확률론적), 근사치를 사용해야 함
- 단일 에이전트 트리(Single-Agent Trees)에서의 상태 가치(Value of a State)
  - 상태의 가치(Value of a State)
    - 특정 상태에서 시작하여 도달할 수 있는 최선의 결과(Utility)를 의미함
  - Non-Terminal States
    - 게임이나 결정 과정이 끝나지 않은 상태
  - Terminal States
    - 게임이나 결정 과정이 끝남, 종단 상태에서는 상태의 가치가 해당 상태의 유틸리티와 동일함
    - 내가 진 경우 -1, 비기면 0, 이기면 +1 등의 값을 부여할 수 있음
- 적대적 게임 트리(Adversarial Game Trees)에서의 상태 가치 및 미니맥스(Minimax)
  - State Under Agent's Control
    - 우리 에어전트가 행동 결정, 최대 유틸리티를 달성하기 위한 선택
  - State Under Opponent's Control
    - 상대가 행동 결정, 우리 에이전트가 받을 유틸리티를 최소화하려고 함
  - Minimax
    - 최악의 경우(상대방이 최적으로 움직인 경우)에도 우리 에이전트가 보장받을 수 있는 최선의 결과를 의미함
- Adversarial Search (Minimax)
  - Ddterministic, zero-sum games
    - 결정론적 제로섬 게임은 모든 게임의 결과가 정확하게 예측될 수 있음
    - 한 플레이어의 이득이 반드시 다른 플레이어의 손실을 의미하게 됨
      - ex) 틱택토, 체스
    - 한 플레이어는 유틸리티를 최대화하려 하고, 다른 플레이어는 유틸리티를 최소화 하려 함
  - 미니맥스 탐색(Minimax Search)
    - 게임의 가능한 모든 수를 포함하는 탐색 트리를 구성함
    - 플레이어는 번갈아가며 턴을 진행
      - 이성적이고 최적으로 행동하는 상대방에 대항하여 달성할 수 있는 최선의 유틸리티
    - Bottom부터 Top까지 재귀적으로 올라가야 함
- Minimax Search
  - 게임 트리에서, 미니맥스 탐색을 통해 최적 전략을 찾음
  - MAX는 나, MIN은 상대를 의미함
  - n이 종단 노드인 경우, 이 노드의 미니맥스는 노드의 유틸리티(해당 상태의 결과 수치화)임
  - n이 max노드(내가 플레이할 차례)라면, 이 노드의 미니맥스 가치는 후속 노드들의 미니맥스 가치 중 최대값임
  - n이 MIN노드(상대방 차례), 이 노드의 미니맥스 가치는 후속 노드들의 미니맥스 가치중 최소값
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/a9ddd90c-b352-4777-ab5d-5fa211cc2589)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/9380711d-5a6c-4160-83f1-17c8e258b460)
- Properties of Minimax
  - Complete?
    - 트리가 유한하다면 그렇다
      - 게임 트리의 DFS를 수행함
  - Optimal?
    - 최적의 상대에 대해서는 최적의 결과를 보장함
  - Time?
    - O(b^m)
      - DFS와 동일
  - Space?
    - O(b^m)
      - DFS와 동일
  - 단, 미니맥스 알고리즘은 모든 미래의 움직임이 최적(Optimal)일 것이라 가정하고, 합리적인(rational) 플레이어와 합리적인 상대를 가정한 것임
### Game Tree Pruning
- Minimax Pruning
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/89c3aa3b-8427-4a16-9871-86df12d754c8)
    - bottom -> Top임을 기억하라 
    - 왼쪽부터 search가 진행될 때, 상대방(역삼각형, min)은 3, 12, 8 중 3을 고를 것이다
    - 중간에서 처음에 2가 나온 순간, 더 search를 할 필요가 없어진다
    - 어차피 **MAX**에서 선택되지 않을 것이기 때문에!!
    - 마지막은 2가 제일 마지막 노드에 있기 때문에 search를 계속하는 것 뿐임
- Alpha-Beta Pruning
  - 알파는 MAX를 위해 지금까지 발견된 가장 높은값, 초기는 -무한대
  - 베타는 MIN을 위해 지금까지 발견된 가낭 낮은겂, 초기는 +무한대
  - 알파와 베타 사이 범위를 재귀적으로 좁힘
    - 최대화 과정에서는 알파를 높은 값으로 재설정, 최소화 단계에서는 베타를 더 낮은 값으로 재설정
  - MIN 노드의 자식 노드에서의 가지치기
    - 특정 MIN 노드에서 자식 노드들의 값을 평가 시, 자식 노드들의 최소값 추정치가 떨어져고 있다고 가정해보자
    - 이때 MAX 플레이어는 그 노드 값이 자신이 이미 찾아놓은 선택(알파값)보다 나쁘다면, 그 경로를 선택하지 않을 것임
    - 따라서, 현재 평가 중이 노드의 가치가 알파 값보다 나빠지면, 더 이상 그 노드의 다른 자식 노드를 고려할 필요가 없어짐
  - MAX 노드의 자식 노드에서의 가지치기는 완전히 위와 대칭적임
- 주요 특성
  - Pruning은 최종 결과에 영향을 주지 않음
    - 탐색 시간을 줄이지만, 최적의 수는 변하지 않음
  - 중간 노드의 값이 잘못될 수 있음
    - 필요하지 않은 노드를 탐색하지 않기 때문에
  - 좋은 자식 노드 순서가 Pruning 효과를 높일 수 있음
- Resource limit
  - 현실적 게임 환경에서는 모든 가능한 수 탐색이 불가능함
    - 깊이 제한 탐색(Depth-limited search)과 같은 전략이 사용됨
  - 이를 위해 비종단 노드에 대한 평가 함수(evaluation function)을 사용하게됨
  - 최적의 플레이 보장 상실
    - 깊이 제한 탐색 사용 시, Optimal을 보장할 수 없게됨
    - Evalutaion Function의 정확도에 크게 의존하게 됨
  - 반복 심화(iterative deepening)을 사용
    - 깊이 제한 탐색을 여러 번 수행하되, 매번 깊이를 점진적으로 증가시킬 때 사용
    - 제한된 시간 안에 최선의 수를 찾을 때 유용
      - 언제든지 중단할 수 있음
  - 평가 함수(Evaluation function)
    - 해당 포지션의 가치를 수치로 나타냄
    - 각 포지션의 전략적 가치를 정확하게 반영하고자 함
      - 이상적인 평가 함수는 minimax value를 반환
      - 실제로는, 평가 함수로 추정함
    - 비종단 노드에서 가장 좋은 이동을 결정하는 데 필수적임
- Depth Matters
  - 평가 함수는 기본적으로 불완전함
    - 모든 가능성을 반영할 수 없기 때문에 불가피하게 근사치(approximation)이 됨
  - 깊이의 중요성
    - 더 깊은 위치에서 평가 함수를 사용할 수록 영향은 상대적으로 줄어듬
    - 즉, 더 깊은 부분에서 평가 수행 시 잠재적 오류의 영향을 줄일 수 있음
  - 특성 복잡성(feature complexity)과 계산 복잡성(computation complexity)사이 트레이드 오프 존재
    - 더 많은 특성 고려 시 상태를 더 정확하게 반영할 수 있지만, 계산 복잡성이 증가함
- Synergies between Evaluation Function and Alpha-Beta
  - 알파 베타 Fruning에서는 노드 확장 순서가 중요한 영향을 미침
    - Evaluation Function이 이 확장 순서를 최적화 하는데 도움을 줄 수 있음
    - 마치 A* 탐색에서 사용되는 Heuristic과 비슷한 역할을 함
  - 즉, 평가 함수가 제공하는 정보를 통해 더 많은 Fruning을 수행할 수 있고, 탐색 효율성을 향상시킴
### Example
- Definition of AI, categories
  - search properties, actual search and evaluation
- Game Search
  - minimax Search and Alpha-Beta Pruning
- Deteministic & optimal adversarial search methods
  - optimization(alpha-beta)
  - what is the problem?
- Approximation of evaluation(value-function)
  - probabillity(e.g. Expertimax)
  - Estimating evaluatin function
  - Relationship wiht search(e.g complexity tradeoff)

## Search under Uncertainty
- Expectimax Search
  - 특정 행동의 결과를 정확히 예측할 수 없는 경우 존재
  - 명시적 무작위성
    - 주사위 굴리기 같이 순수 확률에 의해 결정되는 경우
  - 예측 불가능 상대
    - 상대방의 행동이 무작위적이거나 예측하기 어려운 경우
  - 행동 실패
    - 실행한 행동이 예상대로 이뤄지지 않는 경우
- 이러한 불확실성을 고려, Expectimax(기대값 최대화) 탐색이 도입
  - 최악의 경우를 고려하는 Minimax(미니맥스) 탐색과 달리, 평균적 결과를 예측하기 위함임
- 탐색 방법
  - Max 노드
    - 최선의 행동을 선택
  - Chance 노드
    - Min노드와 유사하지만, 결과가 확실하지 않은 노드를 의미함
    - 가능한 결과에 대한 expected utilites(기대 유틸리티, 예상 가치)를 계산함
    - 우리가 제어할 수 없는 결과들을 나타냄
      - 상대방이 어떤 상태에서 어떻게 행동할지에 대한 확률 모델 사용
    - 균일 분포일 수도 있고, 복잡한 분포 일 수도 있음
- Why not minimax?
  - 미니맥스 알고리즘은 너무 보수적임
    - 실제로 모든 상황이 최악으로 흐르지 않고, 때로는 더 낙관적 결과가 있을 수 있음
    - 따라서 평균적인 사례 추론이 필요
      - 과도한 낙관도, 과도한 비관도 위험
- Utilities
  - 유틸리티는 특정 상태 또는 결과의 가치를 나타내는 함수
  - 에이전트는 유틸리티를 최대화하는 행동을 선택해야함
  - worst-case minimax reasoning
    - 터미널 상태의 유틸리티 값의 크기가 중요하지 않음
    - 상태 간 순서만 올바르면, 그것으로 충분함
      - 중요한 것은 상태 간 상대적 순서임
  - average-case expectimax reasoning
    - 기대값 최대화 추론에서는 상태의 유틸리티 값의 크기가 의미를 가짐
    - 단순한 순서를 나타내는 것 이상의 정보를 담고있기 때문임
### Monte Carlo Tree Search(MCTS)
- 몬테 카를로 트리 탐색(MCTS)은 바둑과 같이 분기 인자(branching factor)가 매우 높아 전형적인 탐색이 비효율적인 경우 효과적임
  - 불확실성을 다루고, 가능한 모든 미래의 시나리오를 탐색함
- 롤아웃에 의한 평가
  - 현재 상테에서 게임이 종료될 때까지 무작위로 게임을 여러 번 플레이하는 과정
    - 실제 게임에서 사용할 만큼 정교하지 않아도 됨
    - 탐색 과정을 가속화
    - 특정 상태의 가치를 평과
  - 롤아웃 과정
    - 각 롤아웃은 현재 상태에서 게임이 종료될 떄가지 계속됨
    - 게임의 최종 결과를 기록
    - 승리 비율을 통해 해당 포지션의 가치를 추정
- 선택적 탐색
  - MCTS는 전체 게임 트리를 균등하게 탐색하지 않음
  - 루트에서의 결정을 개선하는 데 도움이 될 트리의 특정 부분을 선택적으로 탐색
    - 깊이에 상관없음
- MCTS 버전 0
  - 초기 버전에서는 루트의 각 자식 노드에서 N(예: 100)번의 롤아웃을 수행
  - 각 롤아웃에서 승리의 비율을 기록하고, 이 비율이 가장 높은 노드를 선택하는 간단한 접근 방식을 사용
  - 각 노드를 동등하게 탐색하며, 가장 성공적인 결과를 보인 노드를 선택
- MCTS 버전 0.9
  - 롤아웃을 더 유망한 노드에 할당하는 방식으로 발전
  -탐색을 더 효율적으로 만들며, 성공 가능성이 더 높은 노드에 더 많은 계산 자원을 집중시킴
- MCTS 버전 1.0
  - 유망한 노드뿐만 아니라 불확실성이 높은 노드에도 롤아웃을 할당
  - 이는 "유망함"과 "불확실함"이라는 두 가지 기준을 사용하여, 탐색 과정에서 정보 획득을 극대화
  - 여기서 불확실성은 주로 탐색이 적게 이루어진 노드에서 높게 나타남
    - 이러한 노드는 아직 충분히 탐색되지 않았기 때문에, 더 많은 정보를 제공할 가능성이 높음
- MCTS 버전 2.0
  - 시간이 허용하는 한 탐색을 반복
  - 현재 탐색 트리를 바탕으로, 버전 1.0의 접근 방식을 재귀적으로 적용하여 아직 완전히 확장되지 않은 리프 노드까지 확장
  - 선택된 리프 노드에 새로운 자식 노드를 추가하고, 해당 자식 노드에서 롤아웃을 실행한 후, 그 결과를 루트까지 업데이트
- Min이나 Max를 사용하지 않는 이유
  - 노드의 가치는 노드의 자식들의 값에 대한 가중 평균으로 계산됨
  - 횟수가 무한대에 가까워질 수록, 점점 최적의 자식 노드를 선택하게 되고 가중 평균은 MIN이나 MAX에 수렴하게 됨
    - 즉, 알고리즘은 미니맥스 수를 선택하게됨

### Example
- Search under Uncertainty
  - Expectimax
  - Monte Carlo Tree Search
- Monte Carlo Tree Search(MCTS)
  - How to approximate evaluation?

## Optimization Methods
### Finding Best Parameters
- 미분을 통한 최적화
  - 도함수는 기울기를 나타냄
  - 최저점 조건
    - 기울기가 0이 되는 점을 찾는 것이 필수적
- 편미분
  - 여러 변수에 대한 함수를 미분할 때, 각 변수에 대한 도함수로 구성된 벡터를 그래디언트라고 함
- 최소 제곱 예제
  - 선형 회귀(Linear Regression)
    - 데이터 포인트마다 출력을 예측, 데이터를 가장 잘 대표하는 직선을 찾는 과정
    - 오차를 최소화하는 직선의 기울기와 절편을 위해 최소 제곱법 사용
    - θ_1은 직선의 기울기, θ_2는 절편을 나타냄
### Local Search Method
- Tree Search는 탐색되지 않은 대안들을 fringe(경계)에 유지하여 완전성을 보장함
  - 즉, 모든 가능한 후보를 고려하여 문제의 해결책을 찾음
  - 이로써 완전성을 보장하지만, 메모리와 계산 비용이 많이 듬
- Local Search(지역 탐색)
  - 지역 탐색은 현재 해에서 시작, 점진적으로 개선하는 방식
  - 메모리 사용이 적고 계산 속도가 빠름
  - 그러나 지역 최적해에 갇힐 위험이 있고, 전역 최적해를 보장하지 않음
    - 즉, 얻은 해가 최선의 해가 아닐 수 있음(incomplete, suboptimal)
### Hill-climbing Search
- 시작점
  - 임의의 시작점에서 시작할 수 있음
- 반복 과정
  - 현재 상태의 이웃 중 최선의 상태로 계속 이동함
    - 이웃이란, 현재 상태에서 작은 변화로도 도달할 수 있는 상태
- 종료 조건
  - 현재 상태보다 더 좋은 이웃이 없는 경우
    - 즉, 현재 상태에서 어떤 이동도 상황을 개선하지 못할 경우 탐색 중단
- Steepest Ascent
  - 최대 상승, 각 단계에서 가능한 최고의 개선을 추구
- Greedy LocalSearch
  - 선택이 향후 결과에 어떤 영향을 미칠지 고려하지 않음
  - 장기적 계획보다는, 단기적 이익 추구
- 장점
  - 구현 간단, 메모리 요구사항이 낮음
- 단점
  - 지역 최적해에 갇힐 위험이 큼
  - 이웃 간 성능 차이가 거의 없는 경우 효율적이지 않음

### Optimization
- 최적화
  - 함수 최적화(continuout optimization)
    - 연속적인 값들을 다루는 최적화 문제
    - 함수의 기울기(그래디언트) 계산, 최소점을 찾음
    - ex) f(x1,x2) = (x1-1)^2 + x_2^2
      -  편미분 시 x1=1, x2=0
      -  이는 주어진 함수의 최소점임
  - 조합 최적화(discrete optimization)
    - 이산적 값, 명확히 구분되는 값을 다루는 최적화 문제
    - ex) 유전 알고리즘과 같은 기법을 사용할 수 있음

### Gradient Descent Method
- 그래디언트 강하법
  - 함수의 최소값을 찾기 위해 사용되는 반복적 최적화 알고리즘
  - 세상에서 가장 간단한 알고리즘, 가장 효율적 방법은 아닐 수 있음
  - 마이너스 도함수에 주목하라
- ![image](https://github.com/googoo9918/TIL/assets/102513932/78ce00e0-3c86-4341-ac69-6f2a72a4b2e0)
  - arg min θ는 θ에 대해 손실 함수를 최소화하는 값을 찾는 것을 의미함
  - 알고리즘
    - L(θ)이 감소하는 방향 v를 찾음
    - θ+av를 θ로 업데이트함
      - 이때 a는 학습 시 필요한 소요시간, 스탭 사이즈라 함
        - 스탭사이즈란, Gradient Desecnt의 각 반복 단계에서 파라미터를 업데이트할 때 얼마나 멀리 이동할 것인지를 결정하는 값
      - 이때 스탭사이즈가 너무 작으면 수렴에 오랜 시간이 걸리고, 너무 크면 최소값을 지나칠 수 있음
        - 너무 작으면 파라미터가 아주 조금씩만 업데이트 됨
        - 너무 크면 정확한 최소값에 도달하기 힘듬
- Gradent Descent vs Hill-climbing search
  - 경사 하강법은 주변 기울기(미분값)을 이용, 가장 낮은 지점(최소값)을 찾아 내려가는 방법
    - 연속적인 파라미터 값을 가진 함수 최적화 시 사용
  - 언덕 오르기 탐색
    - 모든 이웃 상태를 살펴보고, 비용이 가장 낮은 상태로 이동하는 것을 반복
    - 더 이산적인 상태 공간을 가진 문제에 대해 적합함 즉, 조합 최적화
- loss surface
  - 파라미터 공간에 대한 함수 값의 그래픽 표현
- convexity
  - 그래프 아래의 모든 지점에서 선분을 그렸을 때, 선분이 그래프 위에 있는 경우
    - 단일 글로벌 최소값을 갖기 때문에, 최적화가 쉬움
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/3650c5f2-d846-45f3-a19e-39fc7fbc36af)
### Example
- Local Search Method
  - Hiill-climbin Search
  - Optimizations
  - Gradient Descent Method
- Hill-climbing in TSP?
- Properites of optimization methods
  - Discrete or coninuous? Combinatorial? Optimal? Parameter-dependent properties
    - Optimize 방법에서 정할 수 있는 것들이 많음(step size, selection 방법 등)

## Non-Derivative Unconstrained Optimizations
### Downhill Simplex Method
- 함수에서 최소점을 찾으려고 시도하는 휴리스틱 탐색 방법
  - Simplex 사용
    - N차원 입력에 대해 N+1개의 점을 사용
    - ex) 1D에서는 구간, 2D에서는 삼각형 등, 3차원에서는 사면체 등
- ![image](https://github.com/googoo9918/TIL/assets/102513932/9cd8f4ab-57c9-49dc-954c-c967d33f79ed)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/bf081570-e4d7-414a-9dc1-3a96a67a8e40)
  - reflect
    - 목적 함수가 높은 점을 반대쪽으로 '반사'시켜서 더 낮은 목적 함수 값을 찾음
  - Expansion
    - 반사를 통해 얻은 새로운 점이 더 좋은 값을 나타낼 경우, 더 멀리 확장 하여 더 나은 점을 탐색함
  - Contraction
    - 반사를 통해 개선된 점을 찾지 못한 경우, 크기를 수축하여 최소값을 찾음
  - Shrink
    - 수축이 실패할 경우, 심플렉스의 모든 점을 가장 좋은 점에 가까워지도록 축소함
- 초기 추정값으로 시작 --> 지역 최소점을 만날 때 까지 아래로 이동
- 도함수가 아닌 **함수 평가**만을 필요로 함
- 지역 최소점에 갇힐 가능성 존재

### Grnetic Algorithm
- 유전 알고리즘(GA)
  - 각 단계에서 가장 적합한 N개의 가설을 기반으로 선택
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/e950f9f4-e3d7-4cd6-ab7c-1bfd20fa4568)
  - fittest(selection), reproduction(Crossover), mutation이 존재
    - 생존(선택), 번식(교차), 돌연변이
  - Selection
    - 적합도 평가 --> 적합한 해결책 선별
    - 좋은 해결책 강조 + 나쁜 해결책 제거
  - 적합도 평가는 주로 적합도 함수를 사용하여 각 해결책의 성능을 수치적으로 평가하게됨
    - Fitness Function
      - 목표 문제에 대한 해의 최적성을 정량화하는 목적 함수
      - 적함도 함수의 실제 정의는 문제에 따라 달라지게됨
  - 선택 연산
    - 교차에 쓰이는 두 개의 부모해를 고르기 위한 연산
      - 우수한 해가 선택될 확률이 높아야 함
      - 적합도 차이를 조절함으로써 선택 확률 조정 가능
        - 품질 비례 룰렛 휠 선택(Roulette wheel selection)
          - 가장 좋은 해의 적합도가 가장 나쁜 해의 적합도의 k배가되도록 조절
        - 순위 기반 적합도 할당(Rank-based)
          - 품질에 따라 순위를 매기고, 적합도 할당
            - 다양성을 보다 오래 유지할 수 있음
  - Crossover(교차) 연산
    - 일점 교차(point crossover)
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/9590e554-a630-4d81-871a-e1febea51a98)
      - 길이가 n인 일차원 문자열로 된 염색체 상에서 일점 교차로 자른 방식은 총 n-1가지
    - 다점 교차(multipoint corssover)
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/4bc36669-8619-436e-a39d-63b7281b2c23)
        - k점 교차로 자르는 방식 n-1Ck
        - 일점 교차보다 교란 정도가 큼(보다 넓은 공간 탐색)
        - 교란이 강하면 수렴성이 떨어지고, 시간 내에 수행되지 않을 수 있음
    - 균등 교차(uniform crossover)
      - 자름선을 이용하지 않음
      - 각 유전자 위치에서 독립적으로 부모 유전자를 선택할 수 있음
      - 난수(마스크) 설정하여 선택
    - 싸이클 교차(cycle crossover)
    - 순서 교차(cycle crossoer)
      - 위 두개는 순열로 표현되는 경우에 적용 가능함
    - 간선 재조합
      - TSP를 위해 개발된 교차 연산
  - GA가 유용한 문제들
    - deterministic한 방법으로 좋은 해를 잘 구하지 못하는 경우
  - GA가 소용 없는 문제들
    - 크기가 너무 작은 경우
    - 결정론적 알고리즘으로 쉽게 풀리는 문제
- 장점
  - 빠르고 메모리 요구량이 낮음
  - 분석적 작업 없이 해결책을 찾을 수 있음
- 단점
  - complete x, optimal x
  - 지역 최대값에 갇힐 수 있음
### Example
- Non-Derivative Unconstrained Optimizations
  - Downhill simplex Method
  - Genetic Algorithm

-  Deteministic/Optimal search, optimization Search under uncertainty, and optimizations
   - minimax search
   - 우리가 왜 먹어가고 있는지?
   - uncertainty 기반 search 수행은 왜 하는 것?
     - time limit이 있고, search를 다 못하고 evalutaion function이 필요한데 그러면 어떻게 해야 하는가?, evaluation function과의 관계와 필요성
 

 ## Deep Neural Network
 ### Neural Networks(NN)
 - 유닛
   - 신호를 전송
     - 신호는 항상 스칼라임
   - 유닛은 함수 𝜙를 나타냄
   - 스칼라 값(x)가 유닛으로 전송 시, 함수 𝜙가 적용되고, 결과 𝜙(x)가 나가는 화살표로 전송됨
 - 가중치
   - ![image](https://github.com/googoo9918/TIL/assets/102513932/8fc85621-2f45-4789-83d0-713b21265beb)
   - 스칼라 값 x가 입력될 때, 각 화살표는 가중치 w로 간주됨
     - 가중치가 곱해짐
   - f(x) = 𝜙(wx)
 - ![image](https://github.com/googoo9918/TIL/assets/102513932/b24ba699-ae72-467f-928c-d2b13f63128e)
   - 해당 이미지를 잘 이해할 것
 - Feed-Forward Networks
   - 유닛들을 ℒ1, ..., ℒK와 같은 그룹으로 배열할 수 있음
   - 연결은 오직 그룹 ℒK에서 그룹 ℒK+1로만 전달됨
   - 주의점
     - 계층 내에서의 연결은 없음
     - 역방향 연결 없음
     - 계층을 건너뛰는 연결 없음
 - ![image](https://github.com/googoo9918/TIL/assets/102513932/b2576cf4-b96d-4fea-a6f5-abad358f0ebf)
   - 위 그림은 다음과 같이 표현됨
   - ![image](https://github.com/googoo9918/TIL/assets/102513932/5a853338-bd05-4eee-9c22-31f9b4289e31)
   - 벡터화
     - 스칼라 곱을 축약할 수 있음
     - ![image](https://github.com/googoo9918/TIL/assets/102513932/41c0448f-27c4-4c83-ad4e-7884024360e2)
     - ![image](https://github.com/googoo9918/TIL/assets/102513932/d185df2a-da58-4b01-b34f-bedfd7cfc26f)
     - 어떤식으로 축약 되는지 정확하게 이해할 것
 - ![image](https://github.com/googoo9918/TIL/assets/102513932/e60c3865-47e8-48d0-817f-453ab0c19bb6)
   - 각 계층은 함수를 나타냄
   - 상위 노드의 출력값이 y1, y2라고 가정 시
   - 두 번째 계층 f2의 함수는 다음과 같이 정의됨
     - ![image](https://github.com/googoo9918/TIL/assets/102513932/87f2f4e5-abac-4257-94b3-6d7f3f30bce4)
       - 이부분 이해가 잘 안가는듯? 위 슬라이드와 비교했을 때... 달라진 것이 없지 않은가
- Layers and Composition
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/23acbd9f-e4a3-4c49-a800-68c4a9e60af8)
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/b677aafe-2e41-4232-8a43-3b35e7478774)
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/7b11a707-7698-4cc6-8039-b25b773f64a4)
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/8a430412-fa7d-4e0a-8096-c36ad40c7596)
      - feed-forward 네트워크는 여러 함수의 구성으로 하나의 함수를 나타냄
        - 각 함수는 네트워크의 한 계층에 의해 제공됨
  - General feed-forward networks
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/3bdae4e3-9d67-47a8-9793-cf3746e81337)
      - k개의 계층으로 구성된 피드포워드 네트워크는 하나의 함수를 나타냄
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/59677300-6a47-4f91-8953-e719f8503799)
      - 각 계층은 함수 f(k)를 나타냄
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/2adcc0f4-dedc-4949-9b8e-14afcaea21c4)
      - dk는 k번째 계층의 노드 수로, 계층의 너비라고도 함
- Recall: Linear Classification
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/cec26fa2-400e-4765-9e9f-2df963626d18)
    - v(벡터)
      - 분류기의 방향을 나타냄
    - x(데이터 포인트)
      - 임의의 데이터 포인트 x가 벡터로 표현, v에 수직인 선을 따라 투영됨
    - <x,v>/ ||v||
      - 데이터 포인트 x가 분류기 벡터 v에 수직으로 투영된 위치를 나타냄
    - f(x)
      - 함수는 각 데이터 포인트 x에 대해 sgn((x,v)-c)를 계산, 해당 포인트가 어느 클래스에 속하는지 결정
      - c는 임계값, 결정 경계를 조정
- Linear Classifier in R^2 as Two-Layer NN
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/055332d0-4153-43a1-b855-72916e852dd9)
    - 2차원 공간에서의 선형 분류기를 2중 신경망으로 나타내는 구조
    - 입력층에는 두 입력 값 x1, x2 존재
    - 각 입력은 해당 가중치와 곱해지며, 이 결과들은 편향 -c와 함께 합산됨
    - 현재 활성화 함수는 지시 함수
      - 0보다 클 경우 1 출력(작을 경우 0 출력)
    - 출력 함수 f(x)
      - I{v1x1 + v2x2 + -c >0}으로 정의됨
      - 입력 신호의 선형 조합이 편향을 감안한 임계값을 넘으면 1, 그렇지 않으면 0 을 반환
    - sgn(<v,x>-c) = 2f(x) -1
      - f(x)는 0 또는 1을 출력하고, sgn(<v,x>-c)함수는 -1또는 1로 출력을 제공해야하기 떄문
        - 출력을 일치시키기 위해 위와 같은 변환이 사용된다
    - 일반적으로 R^d에서의 선형 이진 분류기를 나타내기 위해서
      - 차원마다 하나의 입력 유닛을 추가해야 함
      - layer function은 2로 동일함
      - ex) 10차원에서의 선형 이진 분류기
        - 10개의 입력 노드와 1개의 편향 노드
        - 단일 출력을 내는 하나의 유닛
        - 계층은 2개로 동일함
- Hidden Layers and Nonlinear Fuinctions
  - 은닉 유닛
    - 네트워크 내의 입력층이나 출력층이 아닌 모든 노드는 은닉 노드임
  - 선형 및 비선형 네트워크
    - 네트워크에 은닉 유닛이 없다면
      - f_i(x) = 𝜙((w_i,x))형태의 선형 함수임
        - 𝜙는 최종적으로 적용되는 비선형 함수일 수 있음
        - 즉, 선형 결정 경계밖에 표현을 못함(기준 선이 한 개)
    - 최소한 하나의 은닉층을 포함해야, 비선형 변환이 가능하게됨
      - 이를 통해 신경망은 비선형 결정 경계를 생성할 수 있게됨
      - 은닉층은 비선혈 활성화 함수를 통해 데이터를 비선형적으로 변환하기 때문
- The XOR Problem
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/829f4b1e-abb6-42f8-9bd6-1cb053030c8b)
  - XOR 문제는 두 개의 이진 입력 값을 받아 출력 값과 입력 값이 서로 다를 때만 1을 반환하는 문제
  - 서로 다른 위치에 있는 Two ridges(두 개의 능선)을 빼서 특정 영역을 생성
    - 은닉층이 입력 데이터를 비선형적으로 변환, 복잡한 결정 경계를 형성하는 것을 보여줌
  - 선형 분류기는 XOR 문제를 해결할 수 없으며, 선형 분류기가 비선형 결정 경계를 표현할 수 없기 때문임
  - 최소 하나의 은닉층을 가진 신경망은 비선형 변환을 통해 XOR 문제를 해결할 수 있음
-  Neural Networks(Summary)
   - ![image](https://github.com/googoo9918/TIL/assets/102513932/8332517a-d57a-4b48-95f9-15777d508ecd)
     - 신경망의 유닛들은, 방향성이 있으며 순환이 없는(유향 비순환 그래프(Directe Acyclic Graph)) 그래프로 연결할 수 있음
     - 신경망의 정보 흐름이 한 방향으로만 진행되고, 순환이 없음
     - 이러한 구조는 Feed-forward 신경망을 형성함
       - 입력층에서 출력층으로 정보가 한 방향으로만 흐름
         - 또한, 유닛들은 레이어로 그룹화되어 있음
   - ![image](https://github.com/googoo9918/TIL/assets/102513932/4010cb95-7039-438c-a9bd-36a4a614495c)
     - ϕ는 활성화 함수
     - W는 가중치 행렬
     - x는 입력 벡터, b는 바이어스
     - 단일 출력 뉴런의 경우, b는 스칼라임
     - 다수의 출력 뉴런인 경우, b는 벡터임
     - 상기 이미지에서 b는 크기가 4인 벡터임
- Importance of Activation Functions(Nonlinearity)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/d520ac1d-1a77-4c8e-a486-651fab40e1be)
    - 선형 레이어의 연속은 단일 선형 레이어로 표현됨
      - 여러 개의 선형 레이어를 연속으로 사용하는 것은 단 하나의 선형 레이어를 사용하는 것과 다를게 없음
    - 깊은 선형 네트워크는 선형 함수만을 표현함
      - 활성화 함수가 없는 깊은 신경만은 선형 함수만을 표현
        - 따라서 선형 회귀와 동일한 표현력을 가짐
    - 따라서 비선형 활성화 함수를 통해 신경망이 복잡한 비선형 패턴을 학습
      - 이러한 신경망은 이론적으로 임의의 함수를 임의의 정확도로 근사할 수 있음
      - 보편 근사 정리
- Width vs Depth
  - 단일 은닉층을 가진 three-layer neural network는 이론적으로 어떤 연속적인 함수도 근사할 수 있음
  - 다만, 정확도를 높이기 위해 은닉층에 많은 유닛이 필요하며, 이는 네트워크가 넓어지는 것을 의미함
  - 최근 연구에 따르면 너비를 제한하고 깊이를 늘리는게 더 좋은 결과를 얻을 수 있음
    - 즉, 많은 유닛을 가진 하나의 은닉층 대신 여러 개의 은닉층을 쌓는 것이 효과적임
  - 다만, 아직 일관된 이론은 아직 존재하지 않음
### Neural Networks for Machine Learning
- Neural Networks for Machine Learning
  - Hypothesis(가설)
    - 신경망은 복잡한 비선형 가설 함수를 구성, 데이터의 패턴을 학습함
  - Loss(손실)
    - 손실 함수는 모델의 성능을 평가, 모델이 잘못된 예측을 수정하는 데 사용
    - ex) 로지스틱, 소프트맥스, 제곱 오차, 절대 오차 등
  - Optimization(최적화)
    - 모델의 성능을 향상시키기 위해 손실 함수를 최소화 하는 방향으로 가중치 조정
    - ex) 경사 하강법, 확률적 경사 하강법 등
- Linear Hypotheses and Feature Learning
  - 선형 가설
    - 입력 데이터를 비선형적으로 변환한 특징 공간에서 선형 결합을 사용하여 모델을 학습하는 방법
  - 특징의 중요성
    - 좋은 특징을 만들어내는 능력이 모델의 성능에 중요한 역할을 함
      - 데이터를 잘 설명할 수 있도록
  - 자동 특징 학습
    - 알고리즘이 스스로 유용한 특집을 학습할 수 있도록 하는 것이 딥러닝의 주요 목표
- Feature Learning
  - Two-stage hypothesis(이단계 가설 클래스)
    - 하나의 선형 함수가 특징을 생성하고, 다른 선형 함수가 최종 가설을 만듬
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/e44109b0-c6d5-4546-9a63-72d2f58c34a2)
      - 이는 여전히 단순한 선형 분류기(linear classifier)와 동일함
        - 즉, 추가된 복잡성은 기본 가설 함수를 실제로 변경하지 않음
        - 두 개의 선형 함수를 사용해도, 이를 조합한 최종 함수는 여전히 선형 함수임
    - 모델의 표현력을 높이기 위해서는 비선형 활성화 함수를 도입해야 함
    - 즉, 단순히 선형 변환을 여러 번 사용한다고 해서 모델의 본질적인 표현력은 향상되지 않으며, 비선형 변환이 필요함
- Neural Networks
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/2a55580e-a912-4df9-b0c6-293307bdeea3)
    - 여기서 f1,f2는 비선형 함수
    - 신경망(Neural Networks)은 각 선형 변환 후에 비선형 함수를 추가로 적용하는 단순 확장임
      - 머신러닝의 특징 변환과는 달리, 각 단계에서 비선형성을 도입함
    - 비선형 신경망을 기본으로 한 특징 변환 학습(We want to learn the feature transformation based on nonlinear neural layers)
      - 신경망은 비선형 신경층을 통해 자동으로 특징 변환을 학습함
      - 사람이 직접 특징을 설계할 필요 없이, 데이터로부터 자동으로 유용한 특징을 학습할 수 있게 함
- Illustrating Neural Networks
  - 신경망은 입력, 은닉, 출력층으로 구성
    - 각 선형 변환 후에 비선형 함수 적용
  - 은닉층은 입력 데이터를 비선형적으로 변환, 고차원적인 특징 학습
  - 은닉층에서 학습된 특징은 알고리즘에 의해 자동으로 결정, 표현 학습(representation learning)의 중요한 개념
- Neural Networks for Machine Learning
  - 단순히 머신 러닝 기법으로 해결할 수 있는 문제는 전체의 45%정도
  - 복잡한 문제는 최신 딥러닝 기술을 필요로 하고, 이는 전체 문제의 5%에 해당함
  - 50%는 현재 기술로 해결할 수 없는 문제들
- Solving Problems with Deep Learning
  - 문제를 맞닦드렸을 때, 먼저 선형 회귀/분류, 비선형 특징을 사용한 선형 회귀/분류, 그래디언트 부스틩 등의 머신러닝 기법을 사용해보고 실패했을 때
  - 혹은 성능을 1~2% 향상시키고 싶은 경우 딥 러닝을 적용하는 것이 좋음
- The Execptions
  - 다만, 구조화된 데이터(이미지, 오디오, 텍스트)에서는 딥 러닝이 뛰어난 성과를 보임
  - 또한, 이미 학습된 네트워크를 사용하여 데이터를 저차원 표현으로 변환하는 특징 추출기로 사용할 수 있음
    - pretrained network를 사용하면 편리하다 정도로 이해할 것

## Backpropagation
### Training Nerual Networks
- Feature Learning
  - 신경망은 데이터를 더 유용한 특징 공간으로 변환하고, 머신 러닝 작업에 도움이 되는 특징을 학습하는 것임
  - 입력 데이터를 선형 분리가 쉬운 새로운 특징 공간으로 매핑하는 것이 목적
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/f886adcb-0f04-4ce2-b058-c47223303bfe)
  - 추상화 수준
    - 신경망 설계 시
      - 네트워크 , 레이어, 벡터화된 연산, 산술 연산의 여러 추상화 수준을 고려해야함
- Training neural Netwokrs
  - 신경망의 구조를 결정하고, 각 유닛의 활성화 함수를 고정함
  - 모든 가중치를 하나의 벡터로 모아, 네트워크의 파라미터로 사용
  - 주어진 데이터를 사용하여 네트워크를 훈련시킴
    - 이 과정에서 가중치 벡터 w를 최적화 함
  - 분류 문제
    - 이진 분류 문제에서는 출력 유닛이 하나인 구조를 사용
      - 데이터를 훈련, 검증, 테스트로 나눠 모델을 평가함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/2a975322-1e03-4554-912a-036798b1f62f)
    - 각 훈련 데이터 포인트 Xi를 신경망 Fw에 통과시키고, 예측된 값 Fw(Xi)를 실제 라벨 Yi와 비교하여 오류를 측정함
    - 경사 하강법
      - 오류를 줄이는 방향으로 가중치를 조금씩 변경하여 최적화
    - 가중치 업데이트 후 오류 재측정
      - 가중치를 변경한 후, 다시 오류를 측정하여 변경된 가중치의 효과를 평가
  - 오류측정
    - 손실 함수, 목적 함수, 오류 함수라고도 불림
    - 네트워크 출력과 정답을 비교, 오류를 측정하는 방법을 정의함
    - 문제에 따라 적절한 오류 측정 함수 선택
  - 일반적 오류 측정법
    - 분류 문제에서는 교차 엔트로피 손실 사용
    - 회귀 문제에서는 MSE 사용
  - 최적화 문제로서의 훈련
    - 훈련 데이터를 기반으로 오류 측정 함수를 사용하여 총 오류를 정의
      - 이를 최소화하는 방향으로 네트워크를 훈련
### Backpropagation Algorithm
- Backpropagation
  - 훈련 문제
    - 신경만 훈련은 최적화 문제를 해결하는 것을 목표로 함
    - 이떄 feed-forward network에서는 경사 하강법을 사용하여 최적화를 수행
    - feed-forward network에서 경사 하강법은 Backpropagaion 형태를 취함
  - 실제 훈련 과정: 확률적 경사 하강법(Stochastic Gradient Descent, SGD);
    - 고차원 가중치 벡터의 그래디언트를 계산하는 것은 계산 비용이 많이 듬
    - 전체 데이터셋을 사용하여 손실 함수를 계산하는게 아닌, 미니배치를 사용하여 계산 비용을 절감함
- Stochastic Gradient Descent
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/f6989fe1-333e-47fb-8b35-5a35c50566dd)
    - 전통적 경사 하강법은 모든 샘플에 대한 손실의 합에 대해 그래디어트를 계산 및 파라미터를 조정함
      - 전체 데이터셋을 기반으로 하는 그래디언트 계산은 비용이 많이 듬
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/d1946ee9-755b-4c35-85ee-1e5419700472)
    - 대안으로, 확률적 경사 하강법은 한 번에 하나의 샘플(또는 미니배치)을 기반으로 파라미터를 조정함
    - 시그마가 사라진 것을 확인할 수 있음
    - 여기서 X(i)와 Y(i)는 단일 샘플 또는 미니배치를 나타냄
      - 매번 전체 데이터셋을 통과하지 않고도 업데이트 수행 가능, 계산 비용을 줄일 수 있음
      - 미니배치를 사용함으로써, 각 반복에서 여러 샘플의 평균 그래디언트를 사용, 파라미터를 업데이트함
  - 반복과 에폭
    - 반복(Iteration)
      - 각 샘플에 대해 파라미터를 한 번 업데이트 하는 과정
    - 에폭(Epoch)
      - 전체 데이터셋을 한 번 통과하는 과정, 여러 번의 반복(iteration)으로 구성됨
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/203931f7-d1f0-45ac-8496-a6292a1cb7d3)
    - 경사 하강법은 매번 미끄러운 경로를 따라 최적화
    - SGD는 경로가 좀 더 불규칙적이고, 지그재그 형태를 보임
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/8ea466a3-bef3-4f96-9629-da1afa7d0c73)
    - 각 반복(iteration)마다 훈련 데이터의 배치를 부분 샘플링 하는 경우
    - x축: 반복 횟수 또는 훈련 시간
    - y축: 정확도
    - full_grad
      - 전체 경사 하강법을 사용, 전체 데이터 셋에 대해 그래디언트 계산
      - 초기에는 느리지만, 점진적으로 높은 정확도에 도달
    - sgd10
      - 배치 크기가 10인 SGD
      - 변동이 크지만 빠르게 수렴
        - 배치 크기가 작으니 계산량이 적겠지만, 안정성은 떨어지겠지
    - sgd100
      - 배치 크기가 100인 sgd
      - 변동성이 적고 안정적으로 높은 정확도에 도달
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/7be4322f-752d-46de-af63-90faaea33f38)
    - 이전 최적화 경로를 상대적 시간에 따라 스케일링
    - 결과 자체는 이전 이미지와 동일
      - 배치 크기의 차이에 따라 속도와 변동성의 차이를 인지할 것
- Chain rule
  - 연쇄 법칙은 합성 함수의 미분을 계산하는 방식임
  - 최적화 문제를 해결하기 위해서는 손실 함수의 미분을 계산해야 하고, 이때 연쇄 법칙을 사용해야 함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/1cffb152-10fd-43be-b984-2da96fab56be)
    - z는 모델 식, y는 활성화 함수, L은 손실 함수
    - 우리는 손실 함수를 미분해야 함
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/23232a0c-fc31-4308-87c9-91bee543f679)
      - 손실 함수 L에 대해 가중치 w와 편향 b에 대한 편미분을 계산해야함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/22fe68d0-1937-42e3-80d3-f0e42642da30)
    - 손실 함수의 y에 대한 편미분 계산
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/1c4881e4-6c01-4485-a65e-4cbd04eaf7b0)
    - 손실 함수의 z에 대한 편미분 계산
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/ad9f6000-d2bc-4952-8d99-6b2d48c9ae25)
        - y는 활성화 함수의 출력이므로, y는 z의 함수임
        - 상기 이미지는 연쇄 법칙을 작용한 것
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/0aaeb373-3073-44ce-81bf-8b5332e9b049)
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/c0244851-1bab-4256-9e19-7ff8b718d7ac)
    - 손실 함수의 w에 대한 편미분 계산
      - z는 w의 함수
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/09e0be44-af1d-40ae-bb24-6acb09ca82d5)
        - 이때 ∂z/∂w = x이므로
        - ![image](https://github.com/googoo9918/TIL/assets/102513932/9d355df2-2a83-4c5a-8e88-d5520685cc28)
    - 손실 함수의 b에 대한 편미분 계산
      - z는 b의 함수
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/e6b307d4-879f-4011-932a-3d66153150c2)
      - 이때 ∂z/∂b = 1이므로
      - ![image](https://github.com/googoo9918/TIL/assets/102513932/492a247b-750b-4730-807a-5ce3a191dec1)
- Backpropagation Algorithm
  - 순전파
    - 입력 데이터
      - 입력 벡터 x를 사용, 각 층의 출력을 계산함
      - 각 층 k에 대해 함수 ![image](https://github.com/googoo9918/TIL/assets/102513932/235af749-9661-4ce2-b881-7409620703d8)를 적용, 출력을 계산
      - f(k)는 층 k에서 사용하는 활성화 함수
      - 이 과정을 모든 층에 대해 반복함
  - 역전파
    - 마지막 층 K부터 시작하여 w(K)를 업데이트함
    - 이때 손실함수 D에 대해 gradient dsecent를 수행
    - 손실 함수 D는 가중치 w(K), 출력 z(K), 그리고 실제 값 y의 함수
    - 업데이트된 가중치를 ~w(K)로 나타냄
    - 이전 층으로 이동
      - 각 층에서 이전 층으로 이동하여 가중치 w(k)를 업데이터
      - 이때 w(K),...,w(k+1)의 업데이트된 값을 사용
  - 반복
    - 모든 층의 가중치를 업데이트한 후, 다시 순전파 단계로 돌아가 z(k) 값을 업데이트된 가중치를 사용하여 재계산
    - 가중치가 수렴할 때까지 신경망을 훈련시킴
### Examples
- ![image](https://github.com/googoo9918/TIL/assets/102513932/5044fd13-f2bf-4c19-a5d3-d7914707bf7c)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/f3dac73d-1d2f-492f-b263-0e1004574869)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/55602e5d-8464-4550-a8ba-6cfb6aa1fbc7)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/13502e51-9260-492b-9d27-e8b9964bd039)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/8e25c02e-b857-45d3-a6ac-d59642778546)
- ![image](https://github.com/googoo9918/TIL/assets/102513932/ae8d7a36-f5c1-413e-82a4-1bd288896598)
- Local descent와 Global descent를 곱해야 함을 명심하라!
- ![image](https://github.com/googoo9918/TIL/assets/102513932/b579b215-12c6-4b54-8d54-597ba72c0042)
  - 이 사진을 정확히 이해하면 문제 없음
### Gradient Vanishing Problem
- 심층 신경망에서 그래디언트가 전달되다가, 점점 0에 가까워지는 현상
- 시그모이드 함수 특성상 아주 큰 양수나 음수가 들어오면 출력이 포화되어 거의 0이 됨
- 이러한 문제를 해결하기 위해 심층 신경망에서는 주로 ReLU 함수를 많이 사용함

## Specialized Architectures
- 여태까지는 fully connected 모델만 살펴봤음
- 이제 CNN, RNN등을 살펴볼 것
### Convolutional Neural Networks
- Overview
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/c157dd04-4bd7-4e86-9a64-4913e3a5a4eb)
  - 입력 크기는 200 * 200 * 3 = 120k
  - 1000개의 은닉 유닛과 연결 시, 120,000,000개의 파라미터가 필요함
  - 계산적으로 비용이 많이 들고, 훈련 데이터가 제한적인 경우 overfitting의 위험이 큼
  - 완전 연결 레이어는 이미지 내 객체의 위치 이동을 잘 처리하지 못함
    - 각 픽셀을 독립적으로 처리하여 공간 배열을 고려하지 않기 때문
    - 일반화 능력이 떨어진다고 생각할 것
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/9b54e871-3316-4eba-add0-d71eff14d7f2)
    - 이미지의 한 부분을 분석하는 데 유용한 특징은 다른 부분을 분석하는 데도 유용할 가능성이 큼
      - 우리는 이미지의 모든 위치에 적용될 수 있는 특징 검출기를 학습할 수 있는 신경망을 원함
    - Fully connected Layers
      - 각 은닉 유닛이 전체 이미지를 봄
      - 이미지의 모든 픽셀을 개별적으로 처리, 이미지 내의 공간적 정보를 고려하지 않음
    - Locally Connected Layers
      - 각 은닉 유닛의 column이 이미지의 작은 영역을 봄
        - 완전 연결된 레이어보다는 공간적 정보를 더 잘 처리하지만
        - 모든 위치에 동일한 특징 검출기를 적용하지는 못함
      - 가중치 공유가 없기 때문에, 여전히 많은 파라미터가 필요함
        - 당연히 공간적 불변성도 갖지 못함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/ad8144d6-b39d-4522-a327-9b655a76ac82)
    - Convolution layers
      - 각 은닉 유닛의 column이 이미지의 작은 영역을 봄
        - 모든 이미지 위치에 동일한 weights를 공유함
          - 따라서 공간적 불변성을 가짐
          - 이를 통해 파라미터 수를 크게 줄일 수 있음
- preliminary: Convolution Operation
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/3724ab0b-ed3f-4549-b0ff-17f0381ef43c)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/260599cc-ae9e-48ee-aed2-7c4bec478468)
- The Problem with Fully-Connected Networks
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/94a3aa98-fc9d-4bdd-b228-ca33dbfd56ef)
    - 매우 많은 파라미터 필요
      - 많은 파라미터는 데이터에 과적합될 가능성이 높음
    - Natural Invariances 포착 불가
      - Natural Invariances는 위치와 크기에 대한 불변성을 의미함
      - 객체가 이미지내에서 위치를 변경하거나 크기가 변하더라도, 이를 동일하게 인식할 수 있어야 함
- Convolution Layer
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/7e3a0999-b064-4f10-8988-38451e4ea01a)
    - Constrain Weights(가중치 제약)
      - 다음 레이어의 활성화 값은 이전 레이어의 local 함수로 제한됨
    - 가중치 공유
      - 모든 위치에 걸쳐 가중치를 공유
        - 동일한 필터(커널)가 이미지의 모든 위치에 적용
        - 파라미터 수가 줄어들고, 공간적 불변성(spatial invariance)을 갖게됨
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/62754ed2-c5a7-4155-be9d-532f12e22dcc)
    - 맥스 풀링 레이어는 특징 맵의 크기를 줄이고, 중요한 특징을 추출하여 효율성을 높임
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/523468f2-73c0-426d-83bf-7149fca0c037)
    - 필터의 깊이는 이미지의 깊이와 동일해야 함
    - 필터는 입력 이미지의 깊이 전체에 걸쳐 적용, 슬라이딩하며 점곱을 계산함
    - 이 과정으로 생성된 출력 특징 맵은 입력 이미지에서 특정 패턴이나 특징을 나타냄
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/34df9121-157f-41a8-bdcc-4ecca6a791b3)
    - 6개의 3 * 5 * 5 필터 사용중
    - 6차원 bias 벡터 사용
      - 각 필터마나 하나의 바이어스 추가
    - 각 필터는 하나의 activation map(활성화 맵)을 생성함
- Zero Padding
  - 입력 이미지의 가장자리에 0으로 채운 픽셀을 추가, 입력 이미지의 크기를 인위적으로 확장
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/651863b0-886c-4880-8cb3-992c105279fe)
    - 입력 이미지 크기 7x7, 필터 크기 3x3, 스트라이드 1, 제로 패딩: 1픽셀
    - 필터가 입력 이미지의 가장자리 부분에서도 동일하게 적용되도록 하기 위함
    - 출력 이미지의 크기를 입력 이미지의 크기와 동일하게 유지할 수 있음
    - 제로 패딩을 1 픽셀로 설정 시, 7x7이 9x9로 확장됨
    - 일반적으로, 필터 크기가 FxF 일 때, 스트라이드 s이고 제로 패딩을 (F-s)/2로 설정하면 출력 크기가 입력 크기와 동일하게 유지됨
      - F=3 이면, 제로 패딩 = 1
      - F=5 이면, 제로 패딩 = 2
      - F=7 이면, 제로 패딩 = 3
- Receptive Fields
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/f7ee0053-ad65-43d4-81a4-f8395efde59f)
    - 수용 영역은 출력 이미지의 각 요소가 입력 이미지의 어느 부분에 의존하는지를 나타냄
      - 기준이 입력이미지임을 명심하라
    - 커널 크기 KxK에 따라 수용 영역이 결정됨
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/f4c613d8-5043-4581-99da-30d97aa17a0e)
    - 수용 영역은, 1 + L*(K-1)로 계산됨
      - L은 레이어, K는 커널 크기(KxK)
    - 첫 번째 레이어의 수용 영역은 3x3
    - 두 번째 레이어의 수용 영역은 5x5
      - 1 + 2*(3-1)
    - 세 번째 레이어의 수용 영역은 7x7
      - 1 + 3*(3-1)
    - 여러 레이어를 거치면, 최종 출력 뉴런은 더 큰 입력 영역에 의존하게 됨
      - 큰 의미지의 경우, 충분히 큰 수용 영역을 갖기 위해 많은 레이어가 필요할 수 있음
        - 따라서 네트워크 내부에서 다운샘플링을 사용, 효율적으로 수용 영역을 확장함
- Solution #1: Strided Convolution
  - 스트라이드는 필터가 입력 이미지 위를 이동할 때 한 번에 이동하는 픽셀 수를 의미함
  - 출력 크기 = ⌊(입력 크기 - 필터 크기)/스트라이드⌋ + 1
    - 스트라이드 2를 위 이미지에 적용해보면, 수용 영역이 확장되는 것을 볼 수 있음
    - 첫 번째 레이어의 수용 영역은 3x3
    - 두 번째 레이어의 수용 영역은 7x7이 됨
  - 수용 영역을 직접적으로 확장하지만, 과적합을 직접적으로 방지하진 않음
- Solution #2: Pooling Layer
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/e0323f60-96c1-4c51-bca0-adf21e9a669c)
    - 특징 맵의 크기를 줄이면서 중요한 특징을 추출하는 연산 수행
    - 계산 효율성을 높이고, 과적합을 방지함
    - 직접적으로 수용 영역을 확장하진 않음
      - 후의 합성곱 레이어는 이전보다 더 큰 영역을 커버하게 되므로, 전체 네트워크 관점에서 보면 수용 영역 확장 효과를 가짐
- Convolutional Neural Networks
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/0f438bff-2c5f-44c8-b7c9-1672ac803b5f)
    - C1에서는 6x3x3 사이즈의 커널이 사용된 것을 알 수 있음
    - S2에서는 풀링이 적용되었음을 알 수 있음
    - C3에서는 16x3x3 사이즈의 커널이 사용된 것을 알 수 있음
    - S4에서는 풀링이 적용
    - C5,F6는 완전 연결 계층임
      - 특징을 결합하여 최종 결정을 내리는 계층
  - 컨볼루션 연산
    - 컨볼루션 연산은 이미지 위를 슬라이딩 윈도우 방식으로 이동하면서 특징을 추출
      - 이 연산은 입력 이미지의 크기와 직접적인 상관이 없고, 따라서 입력 이미지가 크더라도 컨볼루션 연산을 수행할 수 있음
      - 따라서 컨볼루션 계층만을 사용할 경우, 입력 이미지의 크기에 제약을 받지 않음
    - CNN에서 이미지 사이즈는 왜 고정되어야 하는가?
      - 왜 항상 resize를 해서 인풋으로 넣어야 하는지?
      - FC 계층은 고정된 크기의 입력을 필요로 하기 때문
      - FC 계층에 전달되는 텐서의 크기가 달라지면, 연산이 불가능해짐
      - 물론, Global average Pooling활용하면 Fc Layer와 관계가 없어짐
        - 혹은 adaptive pooling을 사용해서 고정된 출력값을 만들 수 있음
- Global average Pooling
  - 네트워크의 마지막 부분에 위치한 특수한 풀링 연산
  - 각 특징 맵의 모든 값을 평균내어, 하나의 값으로 변환
    - ex) 7x7x512 특징 맵을 각 채널별로 1x1x512로 변환함
  - 출력은 항상 고정된 크기이고, 입력 이미지의 크기에 상관없이 각 채널별로 하나의 값만 출력함
- When using Fc layer or Gap layer
  - Is CNN translation invariant(전이 불변성)?
    - FC 사용 시
      - 불가능함
      - FC 계층은 고정된 위치의 특징을 학습하기 때문
        - 입력 이미지가 크게 이동하면 FC 계층의 출력이 크게 달라질 수 있음
    - GAP 사용 시
      - 가능
      - 각 특징 맵의 평균을 계산하므로, 입력 이미지의 위치 변화에 덜 민감함
      - 완전한 전이 불변성을 보장하진 않음
        - 입력 이미지가 크게 이동하면, 여전히 출력이 달라질 수 있음
  - Is CNN rotation invariant(회전 불변성)?
    - FC 사용 시
      - 불가능
      - FC 계층은 고정된 위치의 특징을 학습하기 때문
      - 입력 이미지가 회전하면 출력이 크게 달라짐
    - GAP 사용 시
      - 불가능
        - 덜 민감할 수는 있으나
        - 컨볼루션 계층에서 학습된 필터가 여전히 방향성을 가지므로, 완전히 제공할 수는 없음

## Training the Neural Networks
### Setting hyperparameters
- ![image](https://github.com/googoo9918/TIL/assets/102513932/61dffaa2-1269-4ea6-8e07-08fc25fbb835)
  - 머신러닝에서 하이퍼파라미터를 선택하는 세가지 아이디어
  - 1. 훈련 데이터에서 가장 잘 동작하는 하이퍼파라미터 선택
    - 훈련 데이터에서 항상 완벽하게 동작하지만, 새로운 데이터에 일반화되지 않을 수 있음
    - 즉, 과적합 됨
  - 2. 테스트 데이터에서 가장 잘 작동하는 하이퍼파라미터 선택
    - 새로운 데이터에 대한 모델의 성능을 예측할 수 없음
    - 과적합 + 테스트 데이터에 대한 과도한 낙관
  - 3. 데이터를 훈련, 검증, 테스트 세트로 나누고, 검증 데이터에서 하이퍼파라미터를 선택하고 테스트 데이터에서 평가
    - 새로운 데이터에 대한 성능을 더 잘 일반화할 수 있게 함
- ![image](https://github.com/googoo9918/TIL/assets/102513932/72466729-6205-4771-8792-6a1f83429a72)
  - 4. 교차 검증
    - 데이터를 여러 폴드로 나누고, 각 폴드를 검증 데이터로 사용
    - 모든 폴드가 한 번씩 검증 데이터로 사용
    - 소규모 데이터셋에 유용, 각 데이터 포인트가 훈련과 검증 모두에 사용 --> 데이터의 최대 활용 가능해짐
    - 훈련 시간이 길기 때문에 딥러닝에서는 자주 사용되지 않음
- Dataset Preparation
  - 데이터베이스는 머신러닝 모델의 성공에 매우 중요한 요소임
  - 훈련 데이터
    - 모델 훈련
    - 모델의 가중치와 파라미터를 조정함
  - 검증 데이터
    - 모델의 성능 튜닝, 하이퍼 파라미터 조정, 과적합 방지
    - 하이퍼 파라미터는 학습 과정에서 사전에 설정하는 변수임
      - 학습률, 배치 크기, 은닉층 수, 에포크 수 등
  - 테스트 데이터
    - 모델의 최종 성능 평가
  - 테스트 데이터를 사용해 하이퍼파라미터를 조정하려는 시도는 매우 잘못된 시도임
    - 모델의 최종 평가를 위해 아껴서 사용해야 함
      - 즉, 모델 개발 과정의 마지막 단계에서만 사용해야 함
  - Data augmentation
    - 데이터 증강은 모델의 일반화 성능을 향상시키기 위해 훈련 데이터셋을 확장하는 기술임
### Model selection
- Bias and Variance
  - Bias는 모델의 평균 예측과 실제 값 간의 차이임
  - Variance는 다른 데이터셋에 대한 모델 예측의 변동성임
    - 높은 분산은, 모델의 예측이 다른 훈련 데이터셋에 따라 크게 변하는 것을 의미함
  - 동일한 모델이 데이터셋에 따라 다른 피팅 결과가 나옴
- Bias and Variance for Model Selection
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/199394eb-8fdf-41cb-8397-07b15ec19414)
    - low, low
      - 이상적 모델
    - low Bias, high Variance
      - 참 값에 가깝게 예측 하지만, 데이터셋에 따라 예측이 많이 변동함
    - high, low
      - 모델이 일관되게 참에서 벗어난 예측을 하지만, 예측의 변동성은 적음
    - high, high
      - 참에서 벗어나면서, 예측의 변동성도 큼
- Model Selection(Model Complexity & Regularization)
  - 우리는 주로 복잡한 모델을 사용하여 과소적합을 방지함
  - 가능한 경우 많은 데이터를 사용함
  - 전처리, 정규화 등의 방법을 사용해 데이터나 작업의 복잡성을 줄임
  - 정규화
    - 모델의 과적합을 방지하기 위해 정규화를 사용함
  - Early stopping
    - 검증 손실이 더 이상 감소하지 않을 때 훈련을 중단, 과적합을 방지함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/254eba2a-a594-47bb-ae14-f486233276d4)
    - 에포크가 너무 많아지면 모델이 훈련 데이터에 과적합되어 검증 데이터에 대한 손실이 증가함
    - 따라서 검증 데이터 손실이 더 이상 감소하지 않고 증가하기 시작하는 시점에서 조기 종료할 수 있음
### Activation function
- Sigmoid
  - 1/1+e^-x
  - 입력 값 x를 [0,1] 범위로 압축함
  - 문제점
    - Gradient Vanishing 문제가 있음
      - 출력이 0이나 1에 가까워질 때(입력이 너무 작거나 큰 경우), 기울기가 거의 0이 되어 역전파 과정에서 가중치가 업데이트 되지 않는 문제
    - 시그모이드 출력이 0을 중심으로 하지 않음
      - 출력이 항상 양수이므로, 출력이 0을 중심으로 하지 않아 역전파 과정에서 기울기 값이 모두 같은 방향으로 치우치는 문제가 발생할 수 있음
    - 지수 함수 계산 비용이 비쌈
      - 시그모이드 함수는 e^-x를 계산해야 하므로, 계산 비용이 상대적으로 높음
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/9d462e51-515b-4038-b9fa-0463b6287f04)
    - 입력값에 따라 도함수가 0에 가까워져 역전파 과정에서 그래디언트 소실 문제가 존재
    - 가중치가 아예 업데이트 되지 않을 수 있음
- sigmoid(not zero-centered)
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/8ac6ee00-98be-4e21-88a3-5958acf55595)
  - 뉴런에 입력되는 값이 항상 양수일 때, 가중치 w에 대한 그래디언트는 어떻게 되는가?
    - 시그모이드 함수의 도함수는 항상 양수임
      - 따라서 로컬 그래디언트는 항상 양수
    - x가 양수라면, ∂L/∂w의 부호는 항상 업스트림 스칼라 그래디언트의 부호와 동일함
      - 따라서, 가중치 업데이트의 방향이 항상 동일한 방향으로 치우칠 수 있음
    - 즉, 시그모이드 함수의 출력이 0을 중심으로 하지 않기 때문에 그래디언트의 부호가 입력 값의 부호와 일치하게 됨
      - 이는 가중치가 비대칭적으로 업데이트될 가능성을 증가시킴
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/ce0683bd-54f0-4c22-9058-824bdebe15f5)
      - 도함수는 항상 양수, x도 양수, 가중치 업데이트 ∂L/∂w의 부호는 ∂L/∂σ에 의해 결정되게 됨
    - 정리하자면, 상기 이미지에서 1사분면과 3사분면으로만 가중치 업데이트가 가능하고, 2사분면과 4사분면으로 가중치 업데이트가 불가능한게 문제라는 것임
      - 미니배치를 사용하면 여러 샘플의 평균으로 그래디언트를 계산하기 때문에, 편향된 방향이 상쇄되어 문제를 완화할 수 있음
- Comparision
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/38e55ddd-d5e7-4824-a796-3a9d187428b7)
    - tanh
      - 출력 값의 평균이 0에 가까워짐
      - 입력 값이 매우 크거나 작을 때 그래디언트가 0에 가까워지는 문제를 겪음
        - Gradient Vanishing
    - ReLU
      - 양수 영역에서 그래디언트가 소실되지 않음
      - 계산이 효율적이고, 수렴 속도가 빠름
      - 출력 값이 0 이상이므로, 중심이 0이 아님 --> 업데이트 과정에서 균형을 맞추기 어려울 수 있음
- ReLU
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/4786b089-541c-40aa-a2c5-c47ef31a9377)
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/71823838-1f67-4dd8-9cc5-22215065e817)
    - ∂L/∂x는 손실 L에 대한 입력 x의 그래디언트
    - ∂σ/∂x는 ReLU 함수의 도함수
      - 입력 x가 0보다 작으면 도함수는 0
      - 입력 x가 0보다 크면 도함수는 1
    - ∂L/∂σ는 출력 σ에 대한 손실 L의 그래디언트
    - 입력 값이 음수이면, 그래디언트는 0이 되어 업데이트가 일어나지 않음
      - 죽은 ReLU 문제
    - 입력값이 0이면 그래디언트는 0
    - 입력값이 양수이면, 그래디언트는 그대로 전달되어 가중치가 업데이트됨
- Leaky ReLU
  - f(x) = max(0.01x, x)
    - 입력이 음수일 때 작은 기울기를 유지, 죽은 ReLU 문제를 해결함
    - 계싼이 효율적이며, 빠르게 수렴
  - PReLU
    - f(x) = max(Ax,x)
      - 학습 가능한 파라미터 A를 도입, 더 유연한 모델을 만듬
        - A의 값은 학습 과정에서 데이터에 맞게 최적화됨
- ELU
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/ebed2579-96d7-42b3-b59a-043c855d5275)
    - 평균 출력을 0에 가깝게 유지
    - 음수 입력 값에 대해 지수적으로 감소, 음수 포화 영역을 가짐
    - 다만, 지수 계산 때문에 계산 비용이 높음
### Weight initialization
- 가중치 초기화
  - 가중치 W를 상수 값으로 초기화하면 생기는 문제
  - 모든 가중치를 동일한 상수 값으로 초기화하면, 신경망의 모든 뉴런이 동일한 출력을 생성, 학습이 비효율적이거나 불가능하게 됨
    - 해결 -> 가중치를 무작위로 초기화, 뉴런들이 서로 다른 특성을 학습할 수 있도록 해야 함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/de67dae9-4562-49f5-83de-dd2b8c4ba1ac)
    - 너무 작은 경우
      - 활성화 값이 0에 가까워지고, 기울기도 0에 가까워짐
      - 학습이 거의 이뤄지지 않음 --> 기울기 소실 문제로 이어짐
    - 너무 큰 경우
      - 활성화 함수의 출력이 포화 상태에 이름
      - 기울기가 0에 가까워짐
  - 첫 번째 아이디어
    - 작은 랜덤 숫자 사용
      - 작은 네트워크에서는 잘 동작하나,깊은 네트워크에서는 활성화 값이 0으로 수렴
      - 기울기 ∂L/∂W가 0이됨, 학습이 이뤄지지 않음
    - 표준편차를 0.01에서 0.05로 증가시키면 어떻게 되는가?
      - 모든 활성화 값이 포화 상태에 도달함
      - 마찬가지로 기울기 값이 0에 가까워져 학습이 이뤄지지 않음
  - 두 번째 아이디어
    - Xavier 초기화
      - 활성화 값이 모든 레이어에서 적절히 스케일링 됨
      - 활성화 값이 0에 수렴하거나 포화 상태에 도달하지 않아 기울기 소실 문제를 방지
  - Xavier 초기화가 ReLU와 함께 사용될 떄의 문제점
    - 양수 입력에 대해서만 활성화 하므로, 활성화 값이 0으로 수렴
      - 학습이 이뤄지지 않음
  - Kaiming 초기화가 위 문제를 해결
    - ReLU의 특성을 반영하여 가중치를 초기화
    - 활성화 값이 0으로 수렴하지 않고, 각 층의 평균과 표준편차가 일정하게 유지됨
### Hyperparameter search
- 탐색하게될 파라미터들
  - 네트워크 구조, 학습률, 업데이트 유형, 정규화 등
- 학습률
  - 작은 학습률
    - 파라미터 업데이트가 작은 폭으로 이루어져 탐색이 느리지만 안정적
  - 큰 학습률
    - 파라미터 업데이트가 큰 폭으로 이루어져 탐색이 빠르지만 불안정
- Choosing Hyperparameters
  - 가볍게 읽어볼 것
  - 1. 초기 손실 확인
  - 2. 작은 샘플에 과적합 시도
    - 작은 샘플에 100% 훈련 정확도를 달성하도록 시도
    - 손실이 줄지 않는다면 학습률이 너무 낮거나 초기화가 잘못되었을 수 있음
    - 손실이 무한대 또는 NaN으로 폭팔한다면, 학습률이 너무 높거나 초기화가 잘못됐을 수 있음
  - 3. 손실을 감소시키는 학습률 찾기
  - 4. 대략적인 그리드 탐색, 1~5 에포크 동안 훈련
  - 5. 세부 그리드 탐색, 더 긴 훈련
  - 6. 손실과 정확도 곡선 확인
- Hyperparameter Search
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/e26331f7-4379-42af-ac16-60c54c6a2676)
    - 정확도가 계속 올라가고 있음, 더 오래 훈련시켜야 함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/3642f009-a7e7-446e-a835-af7d1d955e10)
    - 훈련과 검증 데이터 간의 격차가 없음
      - 과소적합을 의미, 더 오래 훈련시키거나, 더 큰 모델을 사용해야 함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/50e4a73f-cc68-4663-8a91-1e7fddf11cce)
    - 훈련 데이터와 검증 데이터 간의 큰 격차가 발생, 과적합을 의미
      - 정규화기법을 사용하거나 더 많은 데이터를 확보해야 함
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/cce12adb-33d4-4973-a13a-826d9a8fa60b)
    - Training Loss
      - 초기 반복에서 손실 값이 넢지만, 반복이 진행됨에 따라 점점 감소
      - 손실 값(실제 - 예측)들이 다소 불규칙하게 분포, 노이즈가 있을 수 있으므로 이평선을 통해 전반적 추세를 확인해야함
    - Train / Val Accuracy
      - 반복이 진행됨에 따라 훈련 데이터는 98%에 도달
      - 검증 데이터는 95%에서 안정화
      - 차이가 존재하며, 과적합 가능성을 나타냄
- Summary
  - 훈련 오류 개선
    - 초기화, 활성화 함수, optimizer
    - 더 큰 모델, 학습률 조정
  - 테스트 오류 개선
    - 일반화, 정규화
    - 모델선택
## Generalization
- Our Goal
  - 과적합을 방지하면서 복잡한 모델을 훈련 하는 것
  - 편향과 분산이 낮은 모델을 동시에 달성할 수 있어야 함
  - 편향-분산 트레이드오프
    - 고복잡성
      - 편향 낮음, 분산 높음
        - 과적합 문제
    - 저복잡성
      - 편향 높음, 분산 낮음
      - 데이터의 구조를 충분히 반영하지 못하여 훈련 데이터와 테스트 데이터 모두에서 높은 오류를 보일 수 있음
        - 과소적합 문제를 일으킴
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/449b0b11-e7b0-4fce-a53f-59e876bc9a6a)
    - 저복잡성 구간
      - 오류가 모두 높음, 높은 현향
    - 중간 복잡성 구간
      - 이상적 상태
    - 고복잡성 구간
      - 훈련 오류는 낮아졌지만, 테스트 오류는 다시 증가
      - 과적합, 높은 분산을 나타냄
        - 훈련 데이터에 지나치게 맞춰짐
- Overfitting and Underfitting
  - 일반화 오류를 최소화하는 것이 목표
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/84a49a08-c45c-41c9-ae26-2d1bce784b78)
    - 모델의 복잡도가 1
      - 빨간색 선은 모델의 예측값, 녹색 곡선은 실제 데이터, 파란색 점은 실제 데이터 포인트를 나타냄
      - 선형 모델은 과소적합 상태를 보임
    - 모델의 복잡도가 3
      - 적절히 학습하여 좋은 일반화 성능을 보임
    - 모델의 복잡도가 9
      - 데이터 포인트에 너무 잘 맞추려고 하다보니, 노이즈까지 학습하게 되어 과적합 상태를 보임
      - 훈련 데이터에 대해서는 잘 맞출 수 있으나
        - 새로운 데이터에 대한 일반화 성능이 떨어짐
- Generalization
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/39a04c3c-134b-4b94-8516-92549061d5fe)
    - 학습 예제 수에 따른 오류 변화
      - 예제 수가 적으면 훈련 오류는 낮고 테스트 오류는 높음
        - 적은 데이터로 과적합되기 때문에
      - 예제 수가 증가하면서 훈련 오류는 서서히 증가
        - 테스트 오류는 감소
        - 일반화 능력 향상
    - 매개변수 수에 따른 오류 변화

### Data Augmentation
- 일반화 성능 향상
  - 모델의 일반화 성능을 향상시키는 최고의 방법은 더 많은 데이터를 수집하는 것임
    - 데이터 증강을 통해 훈련 데이터를 변형시켜 증가시킬 수 있음
    - 이동, 반전, 회전, 왜곡, 노이즈 추가 등
  - 데이터 증강은 오직 훈련 데이터에만 적용, 테스트 데이터에는 적용하지 않음
- Reducing the Number of Parameters
  - 매개변수 수를 줄이는 것은 모델의 복잡도를 낮추고, 과적합을 방지하는 데 도움이 됨
    - 모델의 층 수 줄이기
    - 층당 매개변수 수 줄이기
    - ![image](https://github.com/googoo9918/TIL/assets/102513932/ef367e97-ca98-4857-9b2f-30c5195dfa82)
      - 병목층 추가
      - 첫 번째 네트워크의 매개변수 수는 10,000개
        - 더 표현력이 높음, 과적합의 위험도 증가
      - 두 번째 네트워크의 매개변수 수는 2,000개
        - 표현력이 제한, 과적합의 위험이 낮음
- Early Stopping
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/8533f45c-14fe-4885-83a4-4bb94291157a)
    - 항상 전역 최적점 또는 국소 최적점을 찾는 것이 목표는 아님
    - 검증오류가 더 이상 감소하지 않고 오히려 증가하려고 할 때 조기 종료하는 방법
      - 과적합을 방지함
- Weight Decay
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/293566af-20cb-48ea-bb4a-cc3a8124805e)
    - 가중치 정규화
      - 큰 가중치 값을 패널티하여 가중치의 크기를 작게 만듬
        - 가중치를 작게 유지함으로써 모델의 복잡성을 줄이고, 과적합을 방지함
    - 파란색 다항식은 상대적으로 작은 계수
      - 덜 복잡하고 데이터에 더 일반화된 형태
    - 빨간색 다항식은 큰 계수
      - 매우 복잡하며 데이터에 과적합된 형태를 보임
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/88fb5bc5-8e34-4467-9d71-162dc2a1a4f5)
    - 가중치가 큰 경우, 입력 값이 약간만 달라져도 예측 값이 크게 변함
- Input/Feature Normalization
  - Data preprocessing(데이터 전처리)
    - 입력 데이터 또는 특성을 정규화 하는 과정
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/39d0c511-1776-41c4-be07-47839c571d92)
    - 원본 데이터
      - 좌표 측 기준으로 데이터가 중심에서 벗어나 있음
    - 제로 중심 데이터
      - 데이터가 중심을 기준으로 이동
      - 평균이 0으로 맞춰짐
    - 정규화된 데이터
      - 데이터가 중심을 기준으로 이동, 각 축의 분산이 동일하게 맞춰짐
  - 모든 입력데이터가 양수인 경우를 기억하라
    - 입력 데이터의 평균이 0이 아닌 경우, 가중치 업데이트가 비효율적으로 이루어질 수 있음
  - ![image](https://github.com/googoo9918/TIL/assets/102513932/2212c034-ac3d-4799-afb3-111cfcf395fc)
    - 정규화 전
      - 분류 손실이 매우 민감하여 최적화가 어려움
    - 정규화 후
      - 가중치의 작은 변화에 덜 민감하므로 최적화가 더 쉬워짐
- Batch Normalization
  - 배치 정규화
    - 각 차원을 제로 평균과 단위 분산(unit-variance)으로 맞추기 위함
    - 장점
      - 학습을 안정시키고, 최적화 과정을 더 쉽게 만듬
        - 학습의 안정성과 효율성을 높임
    - 문제
      - 제로평균 및 단위 분산의 제약이 너무 엄격한 경우 모델의 표현력이 제한될 수 있음
      - 평균과 분산은 학습 중 미니배치에 의존하기 때문에, 테스트 단계에서는 사용할 수 없음
        - 테스트 단계에서는 배치 내의 데이터가 없기 때문
        - 따라서 테스트 단계에서는 학습중 계산된 러닝 평균과 분산을 사용함